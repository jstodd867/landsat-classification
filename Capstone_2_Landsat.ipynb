{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b2ae22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "982c652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat.trn sat.tst\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "697588ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.loadtxt('data/sat.trn'), np.loadtxt('data/sat.tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259bcf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92., 115., 120., ..., 113.,  87.,   3.],\n",
       "       [ 84., 102., 106., ..., 104.,  79.,   3.],\n",
       "       [ 84., 102., 102., ..., 104.,  79.,   3.],\n",
       "       ...,\n",
       "       [ 68.,  75., 108., ..., 104.,  85.,   4.],\n",
       "       [ 71.,  87., 108., ..., 104.,  85.,   4.],\n",
       "       [ 71.,  91., 100., ..., 100.,  81.,   4.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caf6ad4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80., 102., 102., ..., 113.,  87.,   3.],\n",
       "       [ 76., 102., 102., ..., 104.,  83.,   3.],\n",
       "       [ 80.,  98., 106., ...,  96.,  75.,   4.],\n",
       "       ...,\n",
       "       [ 56.,  68.,  91., ...,  92.,  74.,   5.],\n",
       "       [ 56.,  68.,  87., ...,  92.,  70.,   5.],\n",
       "       [ 60.,  71.,  91., ..., 108.,  92.,   5.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2abcdab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 37) (2000, 37)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41ceb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels into different vectors\n",
    "y_train, y_test = train[:,-1], test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a8d8a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3., ..., 4., 4., 4.]), array([3., 3., 4., ..., 5., 5., 5.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "242a72e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "265363cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 3x3x4 pixel neighborhood samples into train and test feature samples\n",
    "X_train, X_test = train[:,:-1], test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dab80ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92., 115., 120., ..., 107., 113.,  87.],\n",
       "       [ 84., 102., 106., ...,  99., 104.,  79.],\n",
       "       [ 84., 102., 102., ...,  99., 104.,  79.],\n",
       "       ...,\n",
       "       [ 68.,  75., 108., ..., 100., 104.,  85.],\n",
       "       [ 71.,  87., 108., ...,  91., 104.,  85.],\n",
       "       [ 71.,  91., 100., ...,  91., 100.,  81.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d700c8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97f6b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine class count for each label in training set\n",
    "def class_counts(y):\n",
    "    labels, labels_inverse, label_counts = np.unique(y, return_inverse=True, return_counts=True)\n",
    "    return labels, labels_inverse, label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27caae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, labels_inverse, label_counts = class_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4d62daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-383-33252419d205>:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['','1 - red soil', '2 - cotton crop', '3 - grey soil', '4 - damp grey soil', '5 - soil w/veg.', '6 - mixture', '7 - very damp grey soil'], rotation=45);\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.bar(labels, label_counts)\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "ax.set_title('Occurrences of Each Class in Training Set')\n",
    "ax.set_xticklabels(['','1 - red soil', '2 - cotton crop', '3 - grey soil', '4 - damp grey soil', '5 - soil w/veg.', '6 - mixture', '7 - very damp grey soil'], rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f746fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot mean spectral signature for each class\n",
    "means = []\n",
    "for idx,label in enumerate(labels):\n",
    "    means.append(np.mean(X_train[labels_inverse==idx,16:20], axis=0))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e64d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 62.8255597 ,  95.29384328, 108.12313433,  88.60074627]),\n",
       " array([ 48.83924843,  39.91440501, 113.88935282, 118.31106472]),\n",
       " array([ 87.47866805, 105.49843913, 110.5962539 ,  87.45681582]),\n",
       " array([77.40963855, 90.94457831, 95.61445783, 75.35421687]),\n",
       " array([59.5893617 , 62.26595745, 83.02340426, 69.95319149]),\n",
       " array([69.01252408, 77.42196532, 81.59248555, 64.12524085])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37b21861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity of mean vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "478ae517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Histogram of Pixel Neighborhood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "360561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Average intensity for neighborhood across each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fbf9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of mean vectors for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d817dc",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36ba997a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 115., 120.,  94.,  84., 102., 106.,  79.,  84., 102., 102.,\n",
       "        83., 101., 126., 133., 103.,  92., 112., 118.,  85.,  84., 103.,\n",
       "       104.,  81., 102., 126., 134., 104.,  88., 121., 128., 100.,  84.,\n",
       "       107., 113.,  87.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2ac1e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 112., 118.,  85.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,16:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fe89690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 115., 120.,  94.,  84., 102., 106.,  79.,  84., 102., 102.,\n",
       "        83., 101., 126., 133., 103.,  92., 112., 118.,  85.,  84., 103.,\n",
       "       104.,  81., 102., 126., 134., 104.,  88., 121., 128., 100.,  84.,\n",
       "       107., 113.,  87.,   3.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540df76",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b088f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each sample by closest distance to mean vector\n",
    "mean_dict = {label: means[i] for i,label in enumerate(labels)} # Create dictionary of mean spectral vector per class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "564bca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: array([ 62.8255597 ,  95.29384328, 108.12313433,  88.60074627]),\n",
       " 2.0: array([ 48.83924843,  39.91440501, 113.88935282, 118.31106472]),\n",
       " 3.0: array([ 87.47866805, 105.49843913, 110.5962539 ,  87.45681582]),\n",
       " 4.0: array([77.40963855, 90.94457831, 95.61445783, 75.35421687]),\n",
       " 5.0: array([59.5893617 , 62.26595745, 83.02340426, 69.95319149]),\n",
       " 7.0: array([69.01252408, 77.42196532, 81.59248555, 64.12524085])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae83991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a,b):\n",
    "    return np.sqrt(sum((a-b)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12517a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.776905414321906"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(train[-1,16:20], mean_dict[3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e19dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance_classifier(X, mean_dict,labels):\n",
    "    predicts = []\n",
    "    label_dict = {num:label for num,label in zip(np.arange(len(labels)), labels)}\n",
    "    for sample in X[:,16:20]:\n",
    "        mean_index = np.argmin([euclidean_distance(sample, mean_vector) for mean_vector in mean_dict.values()])\n",
    "        predicts.append(label_dict[mean_index])\n",
    "    return np.array(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4cb86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = min_distance_classifier(X_train, mean_dict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5289f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 4., 4., 4.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26daf042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7641488162344983"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_predict == y_train)/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daea487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = min_distance_classifier(X_test, mean_dict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f538a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_test_predict == y_test)/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd695a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 5., 7., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edc6ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2027a7",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "da4af1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b67daa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "enc.fit(y_train.reshape(-1,1))\n",
    "\n",
    "y_trn_1hot = enc.transform(y_train.reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "75fff3ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-d2fe52736842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_trn_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Scale the training data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_trn_scaled = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "7293d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "hidden_units = 100\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "d1532863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, n_classes, opt='Adam', hidden_units=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_samples, n_feats = X.shape\n",
    "\n",
    "    model = Sequential() # sequence of layers\n",
    "\n",
    "    hidden_layer = Dense(units=hidden_units,\n",
    "                    input_dim=n_feats,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation='softsign')\n",
    "\n",
    "    hidden_layer_2 = Dense(units=hidden_units,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation='softsign')\n",
    "\n",
    "    outputlayer = Dense(units=n_classes,\n",
    "                    input_dim=hidden_units,\n",
    "                    kernel_initializer='uniform',\n",
    "                    activation='softmax')\n",
    "\n",
    "    model.add(hidden_layer)\n",
    "    model.add(hidden_layer_2)\n",
    "    model.add(hidden_layer_2)\n",
    "    model.add(outputlayer)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "702aee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_trn_scaled, n_classes, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "73bcdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "89/89 [==============================] - 1s 2ms/step - loss: 1.6780 - accuracy: 0.2492 - precision_35: 1.0000 - recall_35: 0.0011    \n",
      "Epoch 2/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.3523 - accuracy: 0.3360 - precision_35: 0.7815 - recall_35: 0.1008\n",
      "Epoch 3/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.2868 - accuracy: 0.3517 - precision_35: 0.6700 - recall_35: 0.1057\n",
      "Epoch 4/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.2348 - accuracy: 0.3822 - precision_35: 0.6676 - recall_35: 0.1051\n",
      "Epoch 5/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0392 - accuracy: 0.5880 - precision_35: 0.8495 - recall_35: 0.2902\n",
      "Epoch 6/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.7642 - accuracy: 0.7680 - precision_35: 0.8509 - recall_35: 0.6149\n",
      "Epoch 7/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.7986 - precision_35: 0.8460 - recall_35: 0.7508\n",
      "Epoch 8/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.8072 - precision_35: 0.8485 - recall_35: 0.7777\n",
      "Epoch 9/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8221 - precision_35: 0.8554 - recall_35: 0.7964\n",
      "Epoch 10/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8239 - precision_35: 0.8595 - recall_35: 0.8043\n",
      "Epoch 11/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8239 - precision_35: 0.8599 - recall_35: 0.8041\n",
      "Epoch 12/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.8331 - precision_35: 0.8656 - recall_35: 0.8034\n",
      "Epoch 13/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8368 - precision_35: 0.8699 - recall_35: 0.8099\n",
      "Epoch 14/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8338 - precision_35: 0.8672 - recall_35: 0.8038\n",
      "Epoch 15/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8347 - precision_35: 0.8695 - recall_35: 0.8054\n",
      "Epoch 16/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8462 - precision_35: 0.8754 - recall_35: 0.8063\n",
      "Epoch 17/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8397 - precision_35: 0.8717 - recall_35: 0.8070\n",
      "Epoch 18/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8428 - precision_35: 0.8766 - recall_35: 0.8070\n",
      "Epoch 19/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8464 - precision_35: 0.8743 - recall_35: 0.8110\n",
      "Epoch 20/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8381 - precision_35: 0.8713 - recall_35: 0.8063\n",
      "Epoch 21/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8419 - precision_35: 0.8715 - recall_35: 0.8104\n",
      "Epoch 22/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8480 - precision_35: 0.8721 - recall_35: 0.8147\n",
      "Epoch 23/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8492 - precision_35: 0.8715 - recall_35: 0.8214\n",
      "Epoch 24/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8442 - precision_35: 0.8666 - recall_35: 0.8144\n",
      "Epoch 25/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8489 - precision_35: 0.8727 - recall_35: 0.8221\n",
      "Epoch 26/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8474 - precision_35: 0.8685 - recall_35: 0.8207\n",
      "Epoch 27/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8471 - precision_35: 0.8686 - recall_35: 0.8225\n",
      "Epoch 28/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8480 - precision_35: 0.8662 - recall_35: 0.8221\n",
      "Epoch 29/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8471 - precision_35: 0.8667 - recall_35: 0.8250\n",
      "Epoch 30/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8494 - precision_35: 0.8700 - recall_35: 0.8313\n",
      "Epoch 31/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8512 - precision_35: 0.8684 - recall_35: 0.8284\n",
      "Epoch 32/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8422 - precision_35: 0.8619 - recall_35: 0.8203\n",
      "Epoch 33/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8519 - precision_35: 0.8720 - recall_35: 0.8282\n",
      "Epoch 34/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8505 - precision_35: 0.8717 - recall_35: 0.8271\n",
      "Epoch 35/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8537 - precision_35: 0.8692 - recall_35: 0.8329\n",
      "Epoch 36/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8582 - precision_35: 0.8758 - recall_35: 0.8381\n",
      "Epoch 37/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8532 - precision_35: 0.8704 - recall_35: 0.8347\n",
      "Epoch 38/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8584 - precision_35: 0.8727 - recall_35: 0.8408\n",
      "Epoch 39/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8589 - precision_35: 0.8746 - recall_35: 0.8415\n",
      "Epoch 40/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8564 - precision_35: 0.8730 - recall_35: 0.8413\n",
      "Epoch 41/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8539 - precision_35: 0.8707 - recall_35: 0.8363\n",
      "Epoch 42/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8586 - precision_35: 0.8717 - recall_35: 0.8437\n",
      "Epoch 43/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8613 - precision_35: 0.8743 - recall_35: 0.8435\n",
      "Epoch 44/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8600 - precision_35: 0.8743 - recall_35: 0.8437\n",
      "Epoch 45/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8636 - precision_35: 0.8798 - recall_35: 0.8485\n",
      "Epoch 46/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8645 - precision_35: 0.8802 - recall_35: 0.8464\n",
      "Epoch 47/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8640 - precision_35: 0.8828 - recall_35: 0.8496\n",
      "Epoch 48/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8629 - precision_35: 0.8799 - recall_35: 0.8492\n",
      "Epoch 49/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8647 - precision_35: 0.8816 - recall_35: 0.8483\n",
      "Epoch 50/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8672 - precision_35: 0.8832 - recall_35: 0.8525\n",
      "Epoch 51/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8679 - precision_35: 0.8794 - recall_35: 0.8534\n",
      "Epoch 52/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8733 - precision_35: 0.8859 - recall_35: 0.8557\n",
      "Epoch 53/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8685 - precision_35: 0.8823 - recall_35: 0.8532\n",
      "Epoch 54/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8688 - precision_35: 0.8852 - recall_35: 0.8557\n",
      "Epoch 55/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8708 - precision_35: 0.8886 - recall_35: 0.8582\n",
      "Epoch 56/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8701 - precision_35: 0.8857 - recall_35: 0.8575\n",
      "Epoch 57/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8681 - precision_35: 0.8864 - recall_35: 0.8552\n",
      "Epoch 58/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8672 - precision_35: 0.8829 - recall_35: 0.8552\n",
      "Epoch 59/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8706 - precision_35: 0.8884 - recall_35: 0.8528\n",
      "Epoch 60/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8681 - precision_35: 0.8836 - recall_35: 0.8523\n",
      "Epoch 61/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8719 - precision_35: 0.8873 - recall_35: 0.8573\n",
      "Epoch 62/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8742 - precision_35: 0.8893 - recall_35: 0.8604\n",
      "Epoch 63/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8728 - precision_35: 0.8866 - recall_35: 0.8607\n",
      "Epoch 64/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8719 - precision_35: 0.8872 - recall_35: 0.8600\n",
      "Epoch 65/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.8758 - precision_35: 0.8901 - recall_35: 0.8640\n",
      "Epoch 66/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8701 - precision_35: 0.8857 - recall_35: 0.8546\n",
      "Epoch 67/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8742 - precision_35: 0.8896 - recall_35: 0.8573\n",
      "Epoch 68/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8764 - precision_35: 0.8925 - recall_35: 0.8647\n",
      "Epoch 69/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8778 - precision_35: 0.8946 - recall_35: 0.8629\n",
      "Epoch 70/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8782 - precision_35: 0.8887 - recall_35: 0.8645\n",
      "Epoch 71/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8724 - precision_35: 0.8915 - recall_35: 0.8598\n",
      "Epoch 72/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.8744 - precision_35: 0.8893 - recall_35: 0.8584\n",
      "Epoch 73/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8762 - precision_35: 0.8914 - recall_35: 0.8589\n",
      "Epoch 74/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8758 - precision_35: 0.8906 - recall_35: 0.8591\n",
      "Epoch 75/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8794 - precision_35: 0.8955 - recall_35: 0.8636\n",
      "Epoch 76/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8737 - precision_35: 0.8881 - recall_35: 0.8586\n",
      "Epoch 77/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8760 - precision_35: 0.8928 - recall_35: 0.8584\n",
      "Epoch 78/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8751 - precision_35: 0.8921 - recall_35: 0.8629\n",
      "Epoch 79/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8728 - precision_35: 0.8924 - recall_35: 0.8568\n",
      "Epoch 80/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8764 - precision_35: 0.8945 - recall_35: 0.8607\n",
      "Epoch 81/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8760 - precision_35: 0.8921 - recall_35: 0.8616\n",
      "Epoch 82/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8773 - precision_35: 0.8962 - recall_35: 0.8607\n",
      "Epoch 83/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.8787 - precision_35: 0.8958 - recall_35: 0.8625\n",
      "Epoch 84/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8785 - precision_35: 0.8960 - recall_35: 0.8622\n",
      "Epoch 85/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8812 - precision_35: 0.8964 - recall_35: 0.8663\n",
      "Epoch 86/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8773 - precision_35: 0.8944 - recall_35: 0.8636\n",
      "Epoch 87/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8809 - precision_35: 0.8984 - recall_35: 0.8609\n",
      "Epoch 88/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8769 - precision_35: 0.8937 - recall_35: 0.8586\n",
      "Epoch 89/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3023 - accuracy: 0.8800 - precision_35: 0.8958 - recall_35: 0.8649\n",
      "Epoch 90/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8758 - precision_35: 0.8946 - recall_35: 0.8613\n",
      "Epoch 91/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8791 - precision_35: 0.8964 - recall_35: 0.8658\n",
      "Epoch 92/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8798 - precision_35: 0.8936 - recall_35: 0.8658\n",
      "Epoch 93/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8767 - precision_35: 0.8955 - recall_35: 0.8582\n",
      "Epoch 94/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8791 - precision_35: 0.8966 - recall_35: 0.8638\n",
      "Epoch 95/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.8780 - precision_35: 0.8944 - recall_35: 0.8629\n",
      "Epoch 96/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8782 - precision_35: 0.8942 - recall_35: 0.8649\n",
      "Epoch 97/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8803 - precision_35: 0.8970 - recall_35: 0.8620\n",
      "Epoch 98/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8780 - precision_35: 0.8965 - recall_35: 0.8631\n",
      "Epoch 99/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8787 - precision_35: 0.8961 - recall_35: 0.8616\n",
      "Epoch 100/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8780 - precision_35: 0.8943 - recall_35: 0.8620\n",
      "Epoch 101/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8769 - precision_35: 0.8950 - recall_35: 0.8609\n",
      "Epoch 102/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8807 - precision_35: 0.8982 - recall_35: 0.8652\n",
      "Epoch 103/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8846 - precision_35: 0.9015 - recall_35: 0.8663\n",
      "Epoch 104/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8803 - precision_35: 0.8962 - recall_35: 0.8627\n",
      "Epoch 105/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2949 - accuracy: 0.8859 - precision_35: 0.9021 - recall_35: 0.8703\n",
      "Epoch 106/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8758 - precision_35: 0.8946 - recall_35: 0.8589\n",
      "Epoch 107/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8816 - precision_35: 0.8984 - recall_35: 0.8656\n",
      "Epoch 108/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8814 - precision_35: 0.8980 - recall_35: 0.8616\n",
      "Epoch 109/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.8841 - precision_35: 0.8982 - recall_35: 0.8697\n",
      "Epoch 110/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8796 - precision_35: 0.8975 - recall_35: 0.8649\n",
      "Epoch 111/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8823 - precision_35: 0.8978 - recall_35: 0.8654\n",
      "Epoch 112/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8852 - precision_35: 0.9020 - recall_35: 0.8694\n",
      "Epoch 113/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8866 - precision_35: 0.9017 - recall_35: 0.8708\n",
      "Epoch 114/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.8830 - precision_35: 0.8986 - recall_35: 0.8674\n",
      "Epoch 115/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8764 - precision_35: 0.8948 - recall_35: 0.8609\n",
      "Epoch 116/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8843 - precision_35: 0.8984 - recall_35: 0.8710\n",
      "Epoch 117/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8852 - precision_35: 0.8992 - recall_35: 0.8670\n",
      "Epoch 118/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8773 - precision_35: 0.8935 - recall_35: 0.8625\n",
      "Epoch 119/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8857 - precision_35: 0.9015 - recall_35: 0.8710\n",
      "Epoch 120/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8848 - precision_35: 0.8991 - recall_35: 0.8679\n",
      "Epoch 121/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8823 - precision_35: 0.8978 - recall_35: 0.8658\n",
      "Epoch 122/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8850 - precision_35: 0.9039 - recall_35: 0.8674\n",
      "Epoch 123/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8868 - precision_35: 0.9019 - recall_35: 0.8688\n",
      "Epoch 124/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8832 - precision_35: 0.9025 - recall_35: 0.8645\n",
      "Epoch 125/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8895 - precision_35: 0.9026 - recall_35: 0.8694\n",
      "Epoch 126/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8803 - precision_35: 0.8977 - recall_35: 0.8665\n",
      "Epoch 127/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.8837 - precision_35: 0.9036 - recall_35: 0.8683\n",
      "Epoch 128/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8870 - precision_35: 0.9033 - recall_35: 0.8697\n",
      "Epoch 129/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8879 - precision_35: 0.9002 - recall_35: 0.8742\n",
      "Epoch 130/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8843 - precision_35: 0.9004 - recall_35: 0.8679\n",
      "Epoch 131/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8830 - precision_35: 0.8973 - recall_35: 0.8703\n",
      "Epoch 132/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8866 - precision_35: 0.8990 - recall_35: 0.8708\n",
      "Epoch 133/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8864 - precision_35: 0.9008 - recall_35: 0.8719\n",
      "Epoch 134/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8873 - precision_35: 0.9022 - recall_35: 0.8715\n",
      "Epoch 135/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8803 - precision_35: 0.8959 - recall_35: 0.8656\n",
      "Epoch 136/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8882 - precision_35: 0.9034 - recall_35: 0.8690\n",
      "Epoch 137/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8906 - precision_35: 0.9038 - recall_35: 0.8767\n",
      "Epoch 138/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8868 - precision_35: 0.9037 - recall_35: 0.8737\n",
      "Epoch 139/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8902 - precision_35: 0.9046 - recall_35: 0.8769\n",
      "Epoch 140/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8868 - precision_35: 0.9034 - recall_35: 0.8728\n",
      "Epoch 141/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8882 - precision_35: 0.8995 - recall_35: 0.8722\n",
      "Epoch 142/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8884 - precision_35: 0.9010 - recall_35: 0.8717\n",
      "Epoch 143/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8911 - precision_35: 0.9046 - recall_35: 0.8764\n",
      "Epoch 144/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8897 - precision_35: 0.9028 - recall_35: 0.8735\n",
      "Epoch 145/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8864 - precision_35: 0.9021 - recall_35: 0.8708\n",
      "Epoch 146/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.8888 - precision_35: 0.9034 - recall_35: 0.8771\n",
      "Epoch 147/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.8891 - precision_35: 0.9053 - recall_35: 0.8746\n",
      "Epoch 148/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.8859 - precision_35: 0.9018 - recall_35: 0.8715\n",
      "Epoch 149/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.8875 - precision_35: 0.9020 - recall_35: 0.8755\n",
      "Epoch 150/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.8859 - precision_35: 0.9001 - recall_35: 0.8733\n",
      "Epoch 151/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.8924 - precision_35: 0.9041 - recall_35: 0.8755\n",
      "Epoch 152/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8911 - precision_35: 0.9040 - recall_35: 0.8749\n",
      "Epoch 153/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.8893 - precision_35: 0.9041 - recall_35: 0.8758\n",
      "Epoch 154/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8868 - precision_35: 0.9032 - recall_35: 0.8733\n",
      "Epoch 155/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8909 - precision_35: 0.9050 - recall_35: 0.8785\n",
      "Epoch 156/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8875 - precision_35: 0.9025 - recall_35: 0.8726\n",
      "Epoch 157/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.8875 - precision_35: 0.9039 - recall_35: 0.8762\n",
      "Epoch 158/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8879 - precision_35: 0.9022 - recall_35: 0.8697\n",
      "Epoch 159/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8904 - precision_35: 0.9033 - recall_35: 0.8780\n",
      "Epoch 160/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8848 - precision_35: 0.9008 - recall_35: 0.8699\n",
      "Epoch 161/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.8911 - precision_35: 0.9081 - recall_35: 0.8780\n",
      "Epoch 162/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8915 - precision_35: 0.9053 - recall_35: 0.8778\n",
      "Epoch 163/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8920 - precision_35: 0.9052 - recall_35: 0.8803\n",
      "Epoch 164/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.8931 - precision_35: 0.9082 - recall_35: 0.8812\n",
      "Epoch 165/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8888 - precision_35: 0.9040 - recall_35: 0.8749\n",
      "Epoch 166/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8952 - precision_35: 0.9079 - recall_35: 0.8800\n",
      "Epoch 167/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.8922 - precision_35: 0.9064 - recall_35: 0.8796\n",
      "Epoch 168/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8956 - precision_35: 0.9087 - recall_35: 0.8821\n",
      "Epoch 169/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8976 - precision_35: 0.9097 - recall_35: 0.8864\n",
      "Epoch 170/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8933 - precision_35: 0.9072 - recall_35: 0.8798\n",
      "Epoch 171/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.8954 - precision_35: 0.9081 - recall_35: 0.8825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8967 - precision_35: 0.9111 - recall_35: 0.8823\n",
      "Epoch 173/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8945 - precision_35: 0.9066 - recall_35: 0.8839\n",
      "Epoch 174/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8938 - precision_35: 0.9072 - recall_35: 0.8791\n",
      "Epoch 175/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8979 - precision_35: 0.9109 - recall_35: 0.8855\n",
      "Epoch 176/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8945 - precision_35: 0.9092 - recall_35: 0.8830\n",
      "Epoch 177/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8933 - precision_35: 0.9081 - recall_35: 0.8803\n",
      "Epoch 178/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.8927 - precision_35: 0.9051 - recall_35: 0.8798\n",
      "Epoch 179/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.8904 - precision_35: 0.9066 - recall_35: 0.8816\n",
      "Epoch 180/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8893 - precision_35: 0.9073 - recall_35: 0.8780\n",
      "Epoch 181/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8954 - precision_35: 0.9105 - recall_35: 0.8807\n",
      "Epoch 182/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.8958 - precision_35: 0.9076 - recall_35: 0.8841\n",
      "Epoch 183/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.9024 - precision_35: 0.9137 - recall_35: 0.8855\n",
      "Epoch 184/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.8965 - precision_35: 0.9076 - recall_35: 0.8839\n",
      "Epoch 185/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8945 - precision_35: 0.9088 - recall_35: 0.8807\n",
      "Epoch 186/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8956 - precision_35: 0.9107 - recall_35: 0.8825\n",
      "Epoch 187/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8958 - precision_35: 0.9065 - recall_35: 0.8791\n",
      "Epoch 188/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.9015 - precision_35: 0.9118 - recall_35: 0.8857\n",
      "Epoch 189/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.9010 - precision_35: 0.9122 - recall_35: 0.8882\n",
      "Epoch 190/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9015 - precision_35: 0.9145 - recall_35: 0.8873\n",
      "Epoch 191/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.9010 - precision_35: 0.9135 - recall_35: 0.8861\n",
      "Epoch 192/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.8999 - precision_35: 0.9121 - recall_35: 0.8895\n",
      "Epoch 193/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.8985 - precision_35: 0.9101 - recall_35: 0.8839\n",
      "Epoch 194/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8985 - precision_35: 0.9103 - recall_35: 0.8857\n",
      "Epoch 195/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.8981 - precision_35: 0.9124 - recall_35: 0.8875\n",
      "Epoch 196/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8967 - precision_35: 0.9093 - recall_35: 0.8866\n",
      "Epoch 197/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8985 - precision_35: 0.9107 - recall_35: 0.8848\n",
      "Epoch 198/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.8963 - precision_35: 0.9106 - recall_35: 0.8870\n",
      "Epoch 199/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8979 - precision_35: 0.9166 - recall_35: 0.8852\n",
      "Epoch 200/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8983 - precision_35: 0.9101 - recall_35: 0.8882\n",
      "Epoch 201/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8990 - precision_35: 0.9135 - recall_35: 0.8864\n",
      "Epoch 202/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9026 - precision_35: 0.9138 - recall_35: 0.8913\n",
      "Epoch 203/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.9033 - precision_35: 0.9152 - recall_35: 0.8904\n",
      "Epoch 204/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.9028 - precision_35: 0.9137 - recall_35: 0.8882\n",
      "Epoch 205/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.8999 - precision_35: 0.9132 - recall_35: 0.8870\n",
      "Epoch 206/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9055 - precision_35: 0.9175 - recall_35: 0.8927\n",
      "Epoch 207/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.9044 - precision_35: 0.9140 - recall_35: 0.8940\n",
      "Epoch 208/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.9030 - precision_35: 0.9153 - recall_35: 0.8915\n",
      "Epoch 209/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9028 - precision_35: 0.9147 - recall_35: 0.8947\n",
      "Epoch 210/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9048 - precision_35: 0.9160 - recall_35: 0.8954\n",
      "Epoch 211/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.9024 - precision_35: 0.9156 - recall_35: 0.8906\n",
      "Epoch 212/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9082 - precision_35: 0.9177 - recall_35: 0.8931\n",
      "Epoch 213/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.9057 - precision_35: 0.9170 - recall_35: 0.8945\n",
      "Epoch 214/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.8972 - precision_35: 0.9107 - recall_35: 0.8850\n",
      "Epoch 215/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9067 - precision_35: 0.9201 - recall_35: 0.8938\n",
      "Epoch 216/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.9010 - precision_35: 0.9130 - recall_35: 0.8895\n",
      "Epoch 217/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.9046 - precision_35: 0.9162 - recall_35: 0.8952\n",
      "Epoch 218/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9046 - precision_35: 0.9151 - recall_35: 0.8943\n",
      "Epoch 219/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9053 - precision_35: 0.9155 - recall_35: 0.8938\n",
      "Epoch 220/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9039 - precision_35: 0.9162 - recall_35: 0.8947\n",
      "Epoch 221/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9051 - precision_35: 0.9158 - recall_35: 0.8924\n",
      "Epoch 222/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9105 - precision_35: 0.9211 - recall_35: 0.8997\n",
      "Epoch 223/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8990 - precision_35: 0.9104 - recall_35: 0.8866\n",
      "Epoch 224/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.8994 - precision_35: 0.9127 - recall_35: 0.8886\n",
      "Epoch 225/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9037 - precision_35: 0.9154 - recall_35: 0.8909\n",
      "Epoch 226/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9051 - precision_35: 0.9160 - recall_35: 0.8947\n",
      "Epoch 227/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9064 - precision_35: 0.9179 - recall_35: 0.8952\n",
      "Epoch 228/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9064 - precision_35: 0.9182 - recall_35: 0.8963\n",
      "Epoch 229/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9091 - precision_35: 0.9175 - recall_35: 0.8981\n",
      "Epoch 230/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.9033 - precision_35: 0.9148 - recall_35: 0.8931\n",
      "Epoch 231/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9114 - precision_35: 0.9199 - recall_35: 0.9006\n",
      "Epoch 232/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9057 - precision_35: 0.9163 - recall_35: 0.8958\n",
      "Epoch 233/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9055 - precision_35: 0.9153 - recall_35: 0.8945\n",
      "Epoch 234/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.9064 - precision_35: 0.9170 - recall_35: 0.8938\n",
      "Epoch 235/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2380 - accuracy: 0.9091 - precision_35: 0.9183 - recall_35: 0.8970\n",
      "Epoch 236/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9082 - precision_35: 0.9170 - recall_35: 0.8972\n",
      "Epoch 237/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9076 - precision_35: 0.9179 - recall_35: 0.8976\n",
      "Epoch 238/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9046 - precision_35: 0.9158 - recall_35: 0.8952\n",
      "Epoch 239/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9071 - precision_35: 0.9173 - recall_35: 0.8974\n",
      "Epoch 240/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9076 - precision_35: 0.9180 - recall_35: 0.8983\n",
      "Epoch 241/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9076 - precision_35: 0.9178 - recall_35: 0.8965\n",
      "Epoch 242/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9100 - precision_35: 0.9202 - recall_35: 0.9017\n",
      "Epoch 243/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9080 - precision_35: 0.9198 - recall_35: 0.9003\n",
      "Epoch 244/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9109 - precision_35: 0.9197 - recall_35: 0.8983\n",
      "Epoch 245/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9071 - precision_35: 0.9162 - recall_35: 0.8972\n",
      "Epoch 246/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9121 - precision_35: 0.9217 - recall_35: 0.9026\n",
      "Epoch 247/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9073 - precision_35: 0.9186 - recall_35: 0.8979\n",
      "Epoch 248/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9121 - precision_35: 0.9201 - recall_35: 0.9010\n",
      "Epoch 249/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9103 - precision_35: 0.9201 - recall_35: 0.9015\n",
      "Epoch 250/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9105 - precision_35: 0.9213 - recall_35: 0.9021\n",
      "Epoch 251/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9125 - precision_35: 0.9215 - recall_35: 0.9021\n",
      "Epoch 252/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9114 - precision_35: 0.9208 - recall_35: 0.9017\n",
      "Epoch 253/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9114 - precision_35: 0.9194 - recall_35: 0.9024\n",
      "Epoch 254/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9112 - precision_35: 0.9197 - recall_35: 0.9035\n",
      "Epoch 255/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9109 - precision_35: 0.9219 - recall_35: 0.9021\n",
      "Epoch 256/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9121 - precision_35: 0.9211 - recall_35: 0.9026\n",
      "Epoch 257/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9116 - precision_35: 0.9218 - recall_35: 0.9010\n",
      "Epoch 258/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9091 - precision_35: 0.9186 - recall_35: 0.9008\n",
      "Epoch 259/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9136 - precision_35: 0.9225 - recall_35: 0.9039\n",
      "Epoch 260/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9161 - precision_35: 0.9261 - recall_35: 0.9042\n",
      "Epoch 261/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.9123 - precision_35: 0.9194 - recall_35: 0.9030\n",
      "Epoch 262/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9118 - precision_35: 0.9217 - recall_35: 0.9026\n",
      "Epoch 263/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9109 - precision_35: 0.9218 - recall_35: 0.9008\n",
      "Epoch 264/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9148 - precision_35: 0.9226 - recall_35: 0.9053\n",
      "Epoch 265/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9132 - precision_35: 0.9242 - recall_35: 0.9051\n",
      "Epoch 266/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9118 - precision_35: 0.9211 - recall_35: 0.9030\n",
      "Epoch 267/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9096 - precision_35: 0.9190 - recall_35: 0.8999\n",
      "Epoch 268/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9123 - precision_35: 0.9216 - recall_35: 0.9037\n",
      "Epoch 269/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9172 - precision_35: 0.9263 - recall_35: 0.9069\n",
      "Epoch 270/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9145 - precision_35: 0.9241 - recall_35: 0.9053\n",
      "Epoch 271/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9076 - precision_35: 0.9157 - recall_35: 0.8994\n",
      "Epoch 272/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9150 - precision_35: 0.9220 - recall_35: 0.9060\n",
      "Epoch 273/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9098 - precision_35: 0.9193 - recall_35: 0.9012\n",
      "Epoch 274/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9145 - precision_35: 0.9242 - recall_35: 0.9067\n",
      "Epoch 275/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9166 - precision_35: 0.9242 - recall_35: 0.9094\n",
      "Epoch 276/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9132 - precision_35: 0.9230 - recall_35: 0.9057\n",
      "Epoch 277/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9184 - precision_35: 0.9278 - recall_35: 0.9098\n",
      "Epoch 278/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9130 - precision_35: 0.9241 - recall_35: 0.9055\n",
      "Epoch 279/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9175 - precision_35: 0.9258 - recall_35: 0.9085\n",
      "Epoch 280/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9143 - precision_35: 0.9236 - recall_35: 0.9071\n",
      "Epoch 281/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9157 - precision_35: 0.9243 - recall_35: 0.9060\n",
      "Epoch 282/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9177 - precision_35: 0.9244 - recall_35: 0.9096\n",
      "Epoch 283/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9118 - precision_35: 0.9225 - recall_35: 0.9046\n",
      "Epoch 284/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9123 - precision_35: 0.9217 - recall_35: 0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9161 - precision_35: 0.9251 - recall_35: 0.9055\n",
      "Epoch 286/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9127 - precision_35: 0.9218 - recall_35: 0.9037\n",
      "Epoch 287/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9150 - precision_35: 0.9243 - recall_35: 0.9055\n",
      "Epoch 288/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9143 - precision_35: 0.9246 - recall_35: 0.9064\n",
      "Epoch 289/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9179 - precision_35: 0.9276 - recall_35: 0.9098\n",
      "Epoch 290/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9182 - precision_35: 0.9253 - recall_35: 0.9078\n",
      "Epoch 291/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.9166 - precision_35: 0.9257 - recall_35: 0.9076\n",
      "Epoch 292/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.9152 - precision_35: 0.9259 - recall_35: 0.9069\n",
      "Epoch 293/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9159 - precision_35: 0.9234 - recall_35: 0.9082\n",
      "Epoch 294/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9188 - precision_35: 0.9289 - recall_35: 0.9076\n",
      "Epoch 295/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9134 - precision_35: 0.9230 - recall_35: 0.9030\n",
      "Epoch 296/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9080 - precision_35: 0.9178 - recall_35: 0.8983\n",
      "Epoch 297/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9166 - precision_35: 0.9260 - recall_35: 0.9089\n",
      "Epoch 298/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9157 - precision_35: 0.9255 - recall_35: 0.9078\n",
      "Epoch 299/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9163 - precision_35: 0.9253 - recall_35: 0.9100\n",
      "Epoch 300/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9177 - precision_35: 0.9255 - recall_35: 0.9073\n",
      "Epoch 301/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9130 - precision_35: 0.9227 - recall_35: 0.9046\n",
      "Epoch 302/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9193 - precision_35: 0.9273 - recall_35: 0.9112\n",
      "Epoch 303/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9168 - precision_35: 0.9262 - recall_35: 0.9107\n",
      "Epoch 304/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9184 - precision_35: 0.9253 - recall_35: 0.9105\n",
      "Epoch 305/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9197 - precision_35: 0.9284 - recall_35: 0.9118\n",
      "Epoch 306/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9222 - precision_35: 0.9278 - recall_35: 0.9123\n",
      "Epoch 307/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9191 - precision_35: 0.9267 - recall_35: 0.9098\n",
      "Epoch 308/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9179 - precision_35: 0.9242 - recall_35: 0.9078\n",
      "Epoch 309/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9166 - precision_35: 0.9246 - recall_35: 0.9094\n",
      "Epoch 310/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9191 - precision_35: 0.9280 - recall_35: 0.9125\n",
      "Epoch 311/350\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9200 - precision_35: 0.9272 - recall_35: 0.912 - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9202 - precision_35: 0.9273 - recall_35: 0.9114\n",
      "Epoch 312/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9166 - precision_35: 0.9239 - recall_35: 0.9109\n",
      "Epoch 313/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2111 - accuracy: 0.9166 - precision_35: 0.9252 - recall_35: 0.9060\n",
      "Epoch 314/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9200 - precision_35: 0.9257 - recall_35: 0.9105\n",
      "Epoch 315/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9191 - precision_35: 0.9267 - recall_35: 0.9121\n",
      "Epoch 316/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9218 - precision_35: 0.9289 - recall_35: 0.9132\n",
      "Epoch 317/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9184 - precision_35: 0.9274 - recall_35: 0.9127\n",
      "Epoch 318/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9206 - precision_35: 0.9270 - recall_35: 0.9130\n",
      "Epoch 319/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9182 - precision_35: 0.9275 - recall_35: 0.9112\n",
      "Epoch 320/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9227 - precision_35: 0.9304 - recall_35: 0.9132\n",
      "Epoch 321/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9227 - precision_35: 0.9303 - recall_35: 0.9150\n",
      "Epoch 322/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9204 - precision_35: 0.9295 - recall_35: 0.9127\n",
      "Epoch 323/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9177 - precision_35: 0.9245 - recall_35: 0.9116\n",
      "Epoch 324/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9231 - precision_35: 0.9301 - recall_35: 0.9150\n",
      "Epoch 325/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9182 - precision_35: 0.9259 - recall_35: 0.9100\n",
      "Epoch 326/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9182 - precision_35: 0.9268 - recall_35: 0.9100\n",
      "Epoch 327/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9213 - precision_35: 0.9297 - recall_35: 0.9152\n",
      "Epoch 328/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9254 - precision_35: 0.9324 - recall_35: 0.9177\n",
      "Epoch 329/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9195 - precision_35: 0.9271 - recall_35: 0.9123\n",
      "Epoch 330/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9204 - precision_35: 0.9278 - recall_35: 0.9123\n",
      "Epoch 331/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9218 - precision_35: 0.9298 - recall_35: 0.9136\n",
      "Epoch 332/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9209 - precision_35: 0.9290 - recall_35: 0.9112\n",
      "Epoch 333/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9191 - precision_35: 0.9256 - recall_35: 0.9114\n",
      "Epoch 334/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9215 - precision_35: 0.9289 - recall_35: 0.9163\n",
      "Epoch 335/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9193 - precision_35: 0.9272 - recall_35: 0.9130\n",
      "Epoch 336/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9251 - precision_35: 0.9326 - recall_35: 0.9170\n",
      "Epoch 337/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9215 - precision_35: 0.9305 - recall_35: 0.9148\n",
      "Epoch 338/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9245 - precision_35: 0.9329 - recall_35: 0.9184\n",
      "Epoch 339/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9161 - precision_35: 0.9250 - recall_35: 0.9096\n",
      "Epoch 340/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9240 - precision_35: 0.9317 - recall_35: 0.9172\n",
      "Epoch 341/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9209 - precision_35: 0.9295 - recall_35: 0.9150\n",
      "Epoch 342/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9269 - precision_35: 0.9338 - recall_35: 0.9186\n",
      "Epoch 343/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9213 - precision_35: 0.9290 - recall_35: 0.9141\n",
      "Epoch 344/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9251 - precision_35: 0.9320 - recall_35: 0.9179\n",
      "Epoch 345/350\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9240 - precision_35: 0.9307 - recall_35: 0.9175\n",
      "Epoch 346/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9227 - precision_35: 0.9303 - recall_35: 0.9172\n",
      "Epoch 347/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9231 - precision_35: 0.9299 - recall_35: 0.9157\n",
      "Epoch 348/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9231 - precision_35: 0.9299 - recall_35: 0.9152\n",
      "Epoch 349/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9247 - precision_35: 0.9299 - recall_35: 0.9188\n",
      "Epoch 350/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9236 - precision_35: 0.9305 - recall_35: 0.9152\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trn_scaled, y_trn_1hot, epochs=350, batch_size=50, verbose=1, validation_split=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2e54478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3052085340023041,\n",
       "  0.2963157594203949,\n",
       "  0.3032892346382141,\n",
       "  0.30303138494491577,\n",
       "  0.296730101108551,\n",
       "  0.2979796230792999,\n",
       "  0.3015426993370056,\n",
       "  0.2961179316043854,\n",
       "  0.29113855957984924,\n",
       "  0.29213887453079224,\n",
       "  0.30815356969833374,\n",
       "  0.28868579864501953,\n",
       "  0.2939971387386322,\n",
       "  0.2841227948665619,\n",
       "  0.28662359714508057,\n",
       "  0.2972811162471771,\n",
       "  0.2941512167453766,\n",
       "  0.2943926751613617,\n",
       "  0.2906618118286133,\n",
       "  0.29063040018081665,\n",
       "  0.28554269671440125,\n",
       "  0.28373661637306213,\n",
       "  0.2890125513076782,\n",
       "  0.2789667546749115,\n",
       "  0.2806715965270996,\n",
       "  0.28155645728111267,\n",
       "  0.28527697920799255,\n",
       "  0.27810341119766235,\n",
       "  0.28052330017089844,\n",
       "  0.2757915258407593,\n",
       "  0.28586089611053467,\n",
       "  0.2735039293766022,\n",
       "  0.2725268304347992,\n",
       "  0.276482492685318,\n",
       "  0.27836647629737854,\n",
       "  0.27129024267196655,\n",
       "  0.27246764302253723,\n",
       "  0.27131426334381104,\n",
       "  0.2772705554962158,\n",
       "  0.2822965085506439,\n",
       "  0.27032461762428284,\n",
       "  0.27262523770332336,\n",
       "  0.274924635887146,\n",
       "  0.2640242874622345,\n",
       "  0.2713399827480316,\n",
       "  0.26556289196014404,\n",
       "  0.26213929057121277,\n",
       "  0.2653021812438965,\n",
       "  0.2654353082180023,\n",
       "  0.26485684514045715,\n",
       "  0.2607778012752533,\n",
       "  0.2541238069534302,\n",
       "  0.25898265838623047,\n",
       "  0.26182273030281067,\n",
       "  0.2610514461994171,\n",
       "  0.2590852677822113,\n",
       "  0.263381689786911,\n",
       "  0.25417622923851013,\n",
       "  0.26278603076934814,\n",
       "  0.253071665763855,\n",
       "  0.25162264704704285,\n",
       "  0.25042596459388733,\n",
       "  0.2660711407661438,\n",
       "  0.24795827269554138,\n",
       "  0.25377875566482544,\n",
       "  0.25385570526123047,\n",
       "  0.2507060766220093,\n",
       "  0.24804025888442993,\n",
       "  0.24337871372699738,\n",
       "  0.25101399421691895,\n",
       "  0.25258493423461914,\n",
       "  0.24666902422904968,\n",
       "  0.24538388848304749,\n",
       "  0.25168606638908386,\n",
       "  0.24428655207157135],\n",
       " 'accuracy': [0.8827361464500427,\n",
       "  0.8817338943481445,\n",
       "  0.8797293901443481,\n",
       "  0.8829867243766785,\n",
       "  0.8802305459976196,\n",
       "  0.8802305459976196,\n",
       "  0.8784765601158142,\n",
       "  0.8797293901443481,\n",
       "  0.8857429027557373,\n",
       "  0.8847406506538391,\n",
       "  0.8777248859405518,\n",
       "  0.8852418065071106,\n",
       "  0.8799799680709839,\n",
       "  0.8905036449432373,\n",
       "  0.885993480682373,\n",
       "  0.8819844722747803,\n",
       "  0.8829867243766785,\n",
       "  0.8829867243766785,\n",
       "  0.8884991407394409,\n",
       "  0.8837383985519409,\n",
       "  0.8864946365356445,\n",
       "  0.887246310710907,\n",
       "  0.8854923844337463,\n",
       "  0.8915058970451355,\n",
       "  0.8890002369880676,\n",
       "  0.8847406506538391,\n",
       "  0.8847406506538391,\n",
       "  0.8895013928413391,\n",
       "  0.8857429027557373,\n",
       "  0.8947632312774658,\n",
       "  0.8912553191184998,\n",
       "  0.8925081491470337,\n",
       "  0.8920069932937622,\n",
       "  0.8930092453956604,\n",
       "  0.882485568523407,\n",
       "  0.892257571220398,\n",
       "  0.8905036449432373,\n",
       "  0.8915058970451355,\n",
       "  0.8905036449432373,\n",
       "  0.8895013928413391,\n",
       "  0.8905036449432373,\n",
       "  0.8962665796279907,\n",
       "  0.8935104012489319,\n",
       "  0.8955149054527283,\n",
       "  0.8937609791755676,\n",
       "  0.8985216617584229,\n",
       "  0.8992733359336853,\n",
       "  0.895765483379364,\n",
       "  0.897018313407898,\n",
       "  0.8932598233222961,\n",
       "  0.9010273218154907,\n",
       "  0.9022801518440247,\n",
       "  0.8980205655097961,\n",
       "  0.900776743888855,\n",
       "  0.9000250697135925,\n",
       "  0.8977699875831604,\n",
       "  0.897018313407898,\n",
       "  0.8997744917869568,\n",
       "  0.8930092453956604,\n",
       "  0.9025306701660156,\n",
       "  0.9050363302230835,\n",
       "  0.904284656047821,\n",
       "  0.8962665796279907,\n",
       "  0.904284656047821,\n",
       "  0.9030318260192871,\n",
       "  0.904284656047821,\n",
       "  0.9027812480926514,\n",
       "  0.9080430865287781,\n",
       "  0.9052869081497192,\n",
       "  0.9030318260192871,\n",
       "  0.8987722396850586,\n",
       "  0.9027812480926514,\n",
       "  0.9040340781211853,\n",
       "  0.9010273218154907,\n",
       "  0.9025306701660156],\n",
       " 'precision_15': [0.8947232365608215,\n",
       "  0.8949134945869446,\n",
       "  0.8961039185523987,\n",
       "  0.8966321349143982,\n",
       "  0.8949275612831116,\n",
       "  0.8946549296379089,\n",
       "  0.894203245639801,\n",
       "  0.894627571105957,\n",
       "  0.9008350968360901,\n",
       "  0.8981601595878601,\n",
       "  0.8949843049049377,\n",
       "  0.9044502377510071,\n",
       "  0.8926905393600464,\n",
       "  0.903158962726593,\n",
       "  0.9009079337120056,\n",
       "  0.8943970799446106,\n",
       "  0.8981024026870728,\n",
       "  0.9010443687438965,\n",
       "  0.9021232724189758,\n",
       "  0.8985469937324524,\n",
       "  0.9019250869750977,\n",
       "  0.9029000401496887,\n",
       "  0.8986852169036865,\n",
       "  0.9067290425300598,\n",
       "  0.9029579758644104,\n",
       "  0.8988326787948608,\n",
       "  0.8995351195335388,\n",
       "  0.9012632369995117,\n",
       "  0.9022049307823181,\n",
       "  0.9076129198074341,\n",
       "  0.9034678936004639,\n",
       "  0.903450071811676,\n",
       "  0.9054854512214661,\n",
       "  0.907565176486969,\n",
       "  0.8968274593353271,\n",
       "  0.9055871963500977,\n",
       "  0.9031758308410645,\n",
       "  0.9063873887062073,\n",
       "  0.9032008051872253,\n",
       "  0.9049223065376282,\n",
       "  0.9078913331031799,\n",
       "  0.9083161354064941,\n",
       "  0.9089494347572327,\n",
       "  0.907216489315033,\n",
       "  0.9049214124679565,\n",
       "  0.9076170921325684,\n",
       "  0.9105398654937744,\n",
       "  0.9093725681304932,\n",
       "  0.9113173484802246,\n",
       "  0.9055970907211304,\n",
       "  0.9127516746520996,\n",
       "  0.9148224592208862,\n",
       "  0.9109853506088257,\n",
       "  0.9112654328346252,\n",
       "  0.9129987359046936,\n",
       "  0.9083654880523682,\n",
       "  0.9080873131752014,\n",
       "  0.9097667336463928,\n",
       "  0.9037131667137146,\n",
       "  0.9131328463554382,\n",
       "  0.9149154424667358,\n",
       "  0.9143589735031128,\n",
       "  0.9038363099098206,\n",
       "  0.9167740345001221,\n",
       "  0.9144618511199951,\n",
       "  0.9136340618133545,\n",
       "  0.9129877090454102,\n",
       "  0.9203084707260132,\n",
       "  0.9172449111938477,\n",
       "  0.9131659865379333,\n",
       "  0.9116207361221313,\n",
       "  0.9133333563804626,\n",
       "  0.9161108136177063,\n",
       "  0.9111623167991638,\n",
       "  0.916344940662384],\n",
       " 'recall_15': [0.8667000532150269,\n",
       "  0.8684540390968323,\n",
       "  0.8644450306892395,\n",
       "  0.8672012090682983,\n",
       "  0.8664495348930359,\n",
       "  0.863943874835968,\n",
       "  0.8619393706321716,\n",
       "  0.8636932969093323,\n",
       "  0.8649461269378662,\n",
       "  0.8684540390968323,\n",
       "  0.8584314584732056,\n",
       "  0.8656978011131287,\n",
       "  0.8629416227340698,\n",
       "  0.87396639585495,\n",
       "  0.8702079653739929,\n",
       "  0.8679528832435608,\n",
       "  0.8656978011131287,\n",
       "  0.8646955490112305,\n",
       "  0.8729641437530518,\n",
       "  0.867702305316925,\n",
       "  0.8687045574188232,\n",
       "  0.873715877532959,\n",
       "  0.8734652996063232,\n",
       "  0.8744675517082214,\n",
       "  0.8719618916511536,\n",
       "  0.8682034611701965,\n",
       "  0.8727136254310608,\n",
       "  0.8759709596633911,\n",
       "  0.8714607954025269,\n",
       "  0.8812327980995178,\n",
       "  0.8747181296348572,\n",
       "  0.8792282342910767,\n",
       "  0.8809822201728821,\n",
       "  0.8807316422462463,\n",
       "  0.8712102174758911,\n",
       "  0.8772237300872803,\n",
       "  0.8764720559120178,\n",
       "  0.8782259821891785,\n",
       "  0.8767226338386536,\n",
       "  0.8752192258834839,\n",
       "  0.8792282342910767,\n",
       "  0.8812327980995178,\n",
       "  0.8779754638671875,\n",
       "  0.8819844722747803,\n",
       "  0.8799799680709839,\n",
       "  0.8837383985519409,\n",
       "  0.8874968886375427,\n",
       "  0.882485568523407,\n",
       "  0.8857429027557373,\n",
       "  0.8797293901443481,\n",
       "  0.885993480682373,\n",
       "  0.890754222869873,\n",
       "  0.887246310710907,\n",
       "  0.8877474069595337,\n",
       "  0.8887496590614319,\n",
       "  0.8842395544052124,\n",
       "  0.8862440586090088,\n",
       "  0.8892508149147034,\n",
       "  0.8842395544052124,\n",
       "  0.8902530670166016,\n",
       "  0.8945126533508301,\n",
       "  0.8935104012489319,\n",
       "  0.8854923844337463,\n",
       "  0.8915058970451355,\n",
       "  0.8920069932937622,\n",
       "  0.8932598233222961,\n",
       "  0.8912553191184998,\n",
       "  0.897018313407898,\n",
       "  0.8942620754241943,\n",
       "  0.8932598233222961,\n",
       "  0.8864946365356445,\n",
       "  0.8925081491470337,\n",
       "  0.8947632312774658,\n",
       "  0.8917564749717712,\n",
       "  0.8920069932937622],\n",
       " 'val_loss': [0.3133304715156555,\n",
       "  0.36854055523872375,\n",
       "  0.45471659302711487,\n",
       "  0.34569892287254333,\n",
       "  0.345788836479187,\n",
       "  0.37052297592163086,\n",
       "  0.35904544591903687,\n",
       "  0.3510362207889557,\n",
       "  0.34355324506759644,\n",
       "  0.40197134017944336,\n",
       "  0.46440738439559937,\n",
       "  0.5356548428535461,\n",
       "  0.3939882516860962,\n",
       "  0.3923134207725525,\n",
       "  0.39501580595970154,\n",
       "  0.32086312770843506,\n",
       "  0.3788822889328003,\n",
       "  0.47015005350112915,\n",
       "  0.367767870426178,\n",
       "  0.39111119508743286,\n",
       "  0.35852643847465515,\n",
       "  0.47210171818733215,\n",
       "  0.515354573726654,\n",
       "  0.44149407744407654,\n",
       "  0.3960842490196228,\n",
       "  0.35373035073280334,\n",
       "  0.3779298961162567,\n",
       "  0.4451768696308136,\n",
       "  0.5008931756019592,\n",
       "  0.42513638734817505,\n",
       "  0.4340148866176605,\n",
       "  0.5567432045936584,\n",
       "  0.5735694169998169,\n",
       "  0.35161569714546204,\n",
       "  0.5362085103988647,\n",
       "  0.42407652735710144,\n",
       "  0.42631399631500244,\n",
       "  0.43040400743484497,\n",
       "  0.41772663593292236,\n",
       "  0.3592323064804077,\n",
       "  0.475341260433197,\n",
       "  0.33926254510879517,\n",
       "  0.48906210064888,\n",
       "  0.39608249068260193,\n",
       "  0.5626710653305054,\n",
       "  0.5092341303825378,\n",
       "  0.6102778315544128,\n",
       "  0.39150166511535645,\n",
       "  0.45318061113357544,\n",
       "  0.5487402081489563,\n",
       "  0.4230518639087677,\n",
       "  0.5184968709945679,\n",
       "  0.5998991131782532,\n",
       "  0.4498295187950134,\n",
       "  0.5179529190063477,\n",
       "  0.46593180298805237,\n",
       "  0.4443766176700592,\n",
       "  0.4721912145614624,\n",
       "  0.5620666146278381,\n",
       "  0.48815393447875977,\n",
       "  0.49279358983039856,\n",
       "  0.49072402715682983,\n",
       "  0.4070642590522766,\n",
       "  0.4597392678260803,\n",
       "  0.602830708026886,\n",
       "  0.5497646927833557,\n",
       "  0.5501085519790649,\n",
       "  0.5056753158569336,\n",
       "  0.5150079131126404,\n",
       "  0.534068763256073,\n",
       "  0.529334306716919,\n",
       "  0.5041351914405823,\n",
       "  0.5828525424003601,\n",
       "  0.45103582739830017,\n",
       "  0.5573601126670837],\n",
       " 'val_accuracy': [0.8648648858070374,\n",
       "  0.8490990996360779,\n",
       "  0.8265765905380249,\n",
       "  0.8603603839874268,\n",
       "  0.8648648858070374,\n",
       "  0.8536036014556885,\n",
       "  0.8581081032752991,\n",
       "  0.8400900959968567,\n",
       "  0.8671171069145203,\n",
       "  0.8310810923576355,\n",
       "  0.815315306186676,\n",
       "  0.8040540814399719,\n",
       "  0.8468468189239502,\n",
       "  0.8513513803482056,\n",
       "  0.837837815284729,\n",
       "  0.8671171069145203,\n",
       "  0.8536036014556885,\n",
       "  0.815315306186676,\n",
       "  0.8536036014556885,\n",
       "  0.8400900959968567,\n",
       "  0.8581081032752991,\n",
       "  0.8310810923576355,\n",
       "  0.7995495200157166,\n",
       "  0.8423423171043396,\n",
       "  0.8513513803482056,\n",
       "  0.8603603839874268,\n",
       "  0.837837815284729,\n",
       "  0.8243243098258972,\n",
       "  0.8220720887184143,\n",
       "  0.8400900959968567,\n",
       "  0.8445945978164673,\n",
       "  0.7860360145568848,\n",
       "  0.7995495200157166,\n",
       "  0.8648648858070374,\n",
       "  0.7995495200157166,\n",
       "  0.8400900959968567,\n",
       "  0.8288288116455078,\n",
       "  0.837837815284729,\n",
       "  0.8333333134651184,\n",
       "  0.8445945978164673,\n",
       "  0.8198198080062866,\n",
       "  0.8558558821678162,\n",
       "  0.815315306186676,\n",
       "  0.8513513803482056,\n",
       "  0.7837837934494019,\n",
       "  0.8085585832595825,\n",
       "  0.7815315127372742,\n",
       "  0.8423423171043396,\n",
       "  0.8288288116455078,\n",
       "  0.7905405163764954,\n",
       "  0.8288288116455078,\n",
       "  0.8108108043670654,\n",
       "  0.7837837934494019,\n",
       "  0.8243243098258972,\n",
       "  0.8108108043670654,\n",
       "  0.8288288116455078,\n",
       "  0.8355855941772461,\n",
       "  0.8130630850791931,\n",
       "  0.7792792916297913,\n",
       "  0.8243243098258972,\n",
       "  0.8198198080062866,\n",
       "  0.8130630850791931,\n",
       "  0.8310810923576355,\n",
       "  0.8130630850791931,\n",
       "  0.7815315127372742,\n",
       "  0.8085585832595825,\n",
       "  0.8130630850791931,\n",
       "  0.8265765905380249,\n",
       "  0.8175675868988037,\n",
       "  0.795045018196106,\n",
       "  0.8018018007278442,\n",
       "  0.815315306186676,\n",
       "  0.7860360145568848,\n",
       "  0.815315306186676,\n",
       "  0.795045018196106],\n",
       " 'val_precision_15': [0.88758784532547,\n",
       "  0.8655660152435303,\n",
       "  0.8651960492134094,\n",
       "  0.8711943626403809,\n",
       "  0.8845265507698059,\n",
       "  0.8651162981987,\n",
       "  0.881118893623352,\n",
       "  0.8505747318267822,\n",
       "  0.8849765062332153,\n",
       "  0.8465116024017334,\n",
       "  0.858208954334259,\n",
       "  0.8316831588745117,\n",
       "  0.8674418330192566,\n",
       "  0.8691588640213013,\n",
       "  0.8531468510627747,\n",
       "  0.8819444179534912,\n",
       "  0.8702830076217651,\n",
       "  0.8454106450080872,\n",
       "  0.8638497591018677,\n",
       "  0.8693586587905884,\n",
       "  0.874709963798523,\n",
       "  0.8544152975082397,\n",
       "  0.8321343064308167,\n",
       "  0.8646080493927002,\n",
       "  0.8634259104728699,\n",
       "  0.8782201409339905,\n",
       "  0.8541666865348816,\n",
       "  0.8348837494850159,\n",
       "  0.8484107851982117,\n",
       "  0.8531468510627747,\n",
       "  0.8574766516685486,\n",
       "  0.8142856955528259,\n",
       "  0.8253588676452637,\n",
       "  0.8799076080322266,\n",
       "  0.8333333134651184,\n",
       "  0.8584686517715454,\n",
       "  0.839907169342041,\n",
       "  0.8488371968269348,\n",
       "  0.8498845100402832,\n",
       "  0.8568129539489746,\n",
       "  0.8472553491592407,\n",
       "  0.8640552759170532,\n",
       "  0.8365384340286255,\n",
       "  0.8741092681884766,\n",
       "  0.8164251446723938,\n",
       "  0.8465228080749512,\n",
       "  0.8062953948974609,\n",
       "  0.8581395149230957,\n",
       "  0.8588516712188721,\n",
       "  0.8218527436256409,\n",
       "  0.8564705848693848,\n",
       "  0.8274231553077698,\n",
       "  0.8062953948974609,\n",
       "  0.84112149477005,\n",
       "  0.8207547068595886,\n",
       "  0.8557919859886169,\n",
       "  0.8474178314208984,\n",
       "  0.8301886916160583,\n",
       "  0.8062201142311096,\n",
       "  0.8452380895614624,\n",
       "  0.836448609828949,\n",
       "  0.8465228080749512,\n",
       "  0.8457943797111511,\n",
       "  0.8387850522994995,\n",
       "  0.8066037893295288,\n",
       "  0.8377088308334351,\n",
       "  0.8416075706481934,\n",
       "  0.8407494425773621,\n",
       "  0.8428571224212646,\n",
       "  0.8169013857841492,\n",
       "  0.824355959892273,\n",
       "  0.8321512937545776,\n",
       "  0.8023529648780823,\n",
       "  0.8305882215499878,\n",
       "  0.8074246048927307],\n",
       " 'val_recall_15': [0.8536036014556885,\n",
       "  0.8265765905380249,\n",
       "  0.795045018196106,\n",
       "  0.837837815284729,\n",
       "  0.8626126050949097,\n",
       "  0.837837815284729,\n",
       "  0.8513513803482056,\n",
       "  0.8333333134651184,\n",
       "  0.8490990996360779,\n",
       "  0.8198198080062866,\n",
       "  0.7770270109176636,\n",
       "  0.7567567825317383,\n",
       "  0.8400900959968567,\n",
       "  0.837837815284729,\n",
       "  0.8243243098258972,\n",
       "  0.8581081032752991,\n",
       "  0.8310810923576355,\n",
       "  0.7882882952690125,\n",
       "  0.8288288116455078,\n",
       "  0.8243243098258972,\n",
       "  0.8490990996360779,\n",
       "  0.8063063025474548,\n",
       "  0.7815315127372742,\n",
       "  0.8198198080062866,\n",
       "  0.8400900959968567,\n",
       "  0.8445945978164673,\n",
       "  0.8310810923576355,\n",
       "  0.8085585832595825,\n",
       "  0.7815315127372742,\n",
       "  0.8243243098258972,\n",
       "  0.8265765905380249,\n",
       "  0.7702702879905701,\n",
       "  0.7770270109176636,\n",
       "  0.8581081032752991,\n",
       "  0.7770270109176636,\n",
       "  0.8333333134651184,\n",
       "  0.815315306186676,\n",
       "  0.8220720887184143,\n",
       "  0.8288288116455078,\n",
       "  0.8355855941772461,\n",
       "  0.7995495200157166,\n",
       "  0.8445945978164673,\n",
       "  0.7837837934494019,\n",
       "  0.8288288116455078,\n",
       "  0.7612612843513489,\n",
       "  0.795045018196106,\n",
       "  0.75,\n",
       "  0.8310810923576355,\n",
       "  0.8085585832595825,\n",
       "  0.7792792916297913,\n",
       "  0.8198198080062866,\n",
       "  0.7882882952690125,\n",
       "  0.75,\n",
       "  0.8108108043670654,\n",
       "  0.7837837934494019,\n",
       "  0.815315306186676,\n",
       "  0.8130630850791931,\n",
       "  0.792792797088623,\n",
       "  0.7590090036392212,\n",
       "  0.7995495200157166,\n",
       "  0.8063063025474548,\n",
       "  0.795045018196106,\n",
       "  0.815315306186676,\n",
       "  0.8085585832595825,\n",
       "  0.7702702879905701,\n",
       "  0.7905405163764954,\n",
       "  0.8018018007278442,\n",
       "  0.8085585832595825,\n",
       "  0.7972972989082336,\n",
       "  0.7837837934494019,\n",
       "  0.792792797088623,\n",
       "  0.792792797088623,\n",
       "  0.7680180072784424,\n",
       "  0.795045018196106,\n",
       "  0.7837837934494019]}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "87ef9488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcf436208b0>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyh0lEQVR4nO3deXxV1bn/8c+TOSFAwqSBAEFQ5lEk4oCIA6iodahDbUXUerFq1V5ba6+/aodbW6u2taiIitSK2qtVS5WKoiIOzMg8SJjDGAIhAwmZ1u+PvRNOkpMQkJOB832/Xud19nT2fs4h7GevtfZey5xziIhI+Ipo7ABERKRxKRGIiIQ5JQIRkTCnRCAiEuaUCEREwpwSgYhImFMiEJFamdmjZvZqY8choaVEIA3GzGab2X4zi23sWJojM7vFzMrMLL/aq2NjxybNmxKBNAgzSwPOBRxwRQMfO6ohj3c81BHzXOdcYrXXjgYNTk44SgTSUG4G5gFTgXGBK8yss5m9bWZZZpZtZhMD1v3QzNaYWZ6ZrTazIf5yZ2Y9Arabama/9adHmlmmmT1oZruAl80s2cze84+x359ODfh8GzN72cx2+Ovf9ZevNLPLA7aLNrO9Zjao+hcMOO4v/G02m9lNAetjzewJM9tqZrvNbJKZxdcW89H+wP7xHvJ/p/3+94mr9ltmmNk+M5seWJIws75m9pG/breZ/SJg1zFm9or/b7DKzIYebWzStCkRSEO5GZjmv0ab2UkAZhYJvAdsAdKATsAb/rrvAo/6n22FV5LIrufxTgbaAF2BO/D+1l/257sAhcDEgO3/DiQAfYEOwJ/85a8A3w/Y7lJgp3NuaR3Hbed/j3HAZDPr6a/7A3AaMAjo4W/zyzpiPhY3AaOB7v6xHgYws1HAY8B1QAre713xO7cEZgEfAB392D4O2OcV/rZJwHSq/m5yInDO6aVXSF/AOUAJ0M6fXwvc708PB7KAqCCfmwncW8s+HdAjYH4q8Ft/eiRQDMTVEdMgYL8/nQKUA8lBtusI5AGt/Pm3gJ/Vss+RQCnQImDZ/wH/DzCgAOgesG44sOkoYr7F339OwGtDwPrNwISA+Usr1gMvAY8HrEv0/03SgBuBr2s55qPArID5PkBhY/9N6XV8XyoRSEMYB3zonNvrz7/G4eqhzsAW51xpkM91BjYc4zGznHNFFTNmlmBmz5vZFjPLBeYASX6JpDOwzzm3v/pOnFf//iVwjZklAZfglWpqs985VxAwvwUvmbTHK3EsNrMcM8vBuwJvX1vMtZjnnEsKeHWvtn5bkGPjv28J+F75eKWrThz5d94VMH0QiGuO7S5SO/1jSkj5deDXAZF+3TdALN5JeCDeiauLmUUFSQbb8Ko4gjmId2KtcDKQGTBfvVvd/wZ6AunOuV1+Hf/XeFfq24A2ZpbknMsJcqy/Abfj/X+Z65zbXtv3BZLNrEVAMugCrAT24lVH9a3j88ejK+DOAdNdgIqG5B14VU4AmFkLoC2wHe/733gcji3NlEoEEmrfAcrwqhQG+a/ewOd4df8LgJ3A782shZnFmdnZ/mdfBB4ws9PN08PMKk5mS4HvmVmkmY0BzjtCHC3xTsQ5ZtYGeKRihXNuJ/Af4Fm/UTnazEYEfPZdYAhwL16bwZH8ysxizOxcYCzwpnOuHHgB+JOZdQAws05mNroe+zsad5lZqv8dfwH8w1/+GjDezAaZd/vu74D5zrnNeG00J5vZfX6DdkszSz/OcUkTpkQgoTYOeNk5t9U5t6vihdfgeBPeFfnleA2UW/Gu6q8HcM69Cfwv3kksD++E3Mbf773+53L8/bx7hDj+DMTjXZnPw6uWCfQDvDrztcAe4L6KFc65QuCfQDfg7SMcZxewH+8KfBpenf1af92DQAYwz6+emoVXSjkaw63mcwRnBKx/DfgQ2Oi/fut/h4/x2ir+iZd4uwM3+OvygIvwfs9dwHrg/KOMS5oxc04D04gciZn9EjjNOff9OrYZCbzqnEutbZtQMrPNwO3OuVmNcXxpvtRGIHIEfjXLbXilBpETjqqGROpgZj/Ea0z9j3NuTmPHIxIKqhoSEQlzKhGIiIS5ZtdG0K5dO5eWltbYYYiINCuLFy/e65xrH2xds0sEaWlpLFq0qLHDEBFpVsxsS23rVDUkIhLmlAhERMJcyBKBmU0xsz1mtrKW9WZmT/v9oy83v595ERFpWKFsI5iK141AbX2zXAKc6r/Sgef896NWUlJCZmYmRUVH6rhRpHZxcXGkpqYSHR3d2KGINKiQJQLn3BzzhieszZXAK857kGGemSWZWYrfAdhRyczMpGXLlqSlpWFmxxqyhDHnHNnZ2WRmZtKtW7fGDkekQTVmG0Enqvadnukvq8HM7jCzRWa2KCsrq8b6oqIi2rZtqyQgx8zMaNu2rUqVEpYaMxEEO2sHfczZOTfZOTfUOTe0ffugt8EqCci3pr8hCVeNmQgyqTqIRiqHB9EQETkhrd+dR8aePMrLHfsLioNuM29jNou3VB0wb/qyHazblReSmBozEUwHbvbvHjoTOHAs7QNNQVFREcOGDWPgwIH07duXRx55JOh2t9xyC2+99VaN5Tt27ODaa68N+pmRI0cGfYBu6tSp3H333d8ucF9aWhp79+498oaNZOrUqezYcfTXCJMmTeKVV+ozjozI0SssLqucfvHzjTz54Tpyi0oql/3po28Y/tjHVT5zqLSMi/40hwufmsPZf/iEwb/5iPTfzeKht1fwr6XbeW3+Vn7w0nxumDyPa577imdnZ/CvpdsZ9eRsfvz61/xraV2D4x27kDUWm9nreANytzOzTLwRoaIBnHOTgBl4g2tn4A07OD5UsYRabGwsn3zyCYmJiZSUlHDOOedwySWXcOaZZ9br8x07dgyaIE4UZWVlREZGHvPnp06dSr9+/ejYsWONdXXte8KECcd8TDmxrMg8QLlz9O3Yiqc/Xs/IXh0oK3e0T4zlN++tZmhaG15fsJVnbxrC83M2ktY2gdvO6UZSQgwAU77YxIasfG5K78raXbn8bsYa9uYX89495/DZN1n8ceY6AOas30tqcjzvLz98TZv28/cxg5axUeQWHR6NdecBrz1qd+4hXl+wldcXbK0R9+MfrKsy36VNQo1tjodQ3jVU5xio/t1Cd4Xq+A3JzEhMTAS8W1lLSkpqrW+eM2cOTz31FLt27eLxxx/n2muvZfPmzYwdO5aVK1dSWFjI+PHjWb16Nb1796awsLDysy+//DKPPfYYKSkpnHbaacTGxgKQlZXFhAkT2LrV+0P685//zNlnn82jjz7K1q1b2bhxI1u3buW+++7jxz/+cZ3f5Tvf+Q7btm2jqKiIe++9lzvuuIOXXnqJlStX8qc//QmAF154gTVr1vDUU0/x6quv8vTTT1NcXEx6ejrPPvsskZGRJCYm8pOf/ISZM2fy5JNP8t577zF9+nSioqK4+OKLeeKJJ+r127711lssWrSIm266ifj4eObOnUvv3r259dZb+fDDD7n77rvJy8tj8uTJFBcX06NHD/7+97+TkJDAo48+SmJiIg888AAjR44kPT2dTz/9lJycHF566SXOPffcesUgDWPBpn20iI2kb8fWNdYVlZQRF3044b/79XY6tIpl8pyNPHp5X9okxnDgYAmpyfHM3ZjNR6t388uxfXjiw3UszzzA5+urlnif/iSjyvzHa/cAMPavX1Qu+6u/zXmnteezb7ybVKbNr3qy/t2MNXy1IRuAMX1P5oNVu1i2LadG/M5B/iEvCZzSrgUdk+L5IiN4KXxUrw7ER0fy/oqaFSTNLhE0ll/9exWrd+Qe13326diKRy7vW+c2ZWVlnH766WRkZHDXXXeRnh78kYidO3fyxRdfsHbtWq644ooaVULPPfccCQkJLF++nOXLlzNkyJDKzz3yyCMsXryY1q1bc/755zN48GAA7r33Xu6//37OOecctm7dyujRo1mzZg0Aa9eu5dNPPyUvL4+ePXty55131nmf/JQpU2jTpg2FhYWcccYZXHPNNdxwww0MGDCAxx9/nOjoaF5++WWef/551qxZwz/+8Q++/PJLoqOj+dGPfsS0adO4+eabKSgooF+/fvz6179m37593HbbbaxduxYzIycnp74/Pddeey0TJ07kiSeeYOjQoZXL4+Li+OIL7z9tdnY2P/zhDwF4+OGHeemll7jnnntq7Ku0tJQFCxYwY8YMfvWrXzFrlgbyaihzN2TTvX0LOrSKA7wTe2FxGa3io9m27yATXl3MWr/+e/PvL2Nv/iH+PncL6ae04YmZ61iyNYfkhGgeuqQ3Q7omc98/llbue+S62ZXTvU5uWbmfV+Zuoaz86LvZn3LLUHbkFPHwu96zsBVJ4LUfpvOfFbvYkVNI+5axvLFwW2USePW2dLq0SeCDVbsq9zO4SxLLMw8QFxXBB/eNID4mktbx0USY8fXW/TUSwX/uPZcX5mzkd1f3Jy46kj8Wl/LqvC2UlcPaXbn8a+kOOisRNG2RkZEsXbqUnJwcrrrqKlauXEm/fv1qbPed73yHiIgI+vTpw+7du2usnzNnTuVV+4ABAxgwYAAA8+fPZ+TIkVTcNXX99dfzzTffADBr1ixWr15duY/c3Fzy8rz/DJdddhmxsbHExsbSoUMHdu/eTWpq7SMpPv3007zzzjsAbNu2jfXr13PmmWcyatQo3nvvPXr37k1JSQn9+/dn4sSJLF68mDPO8IbMLSwspEOHDpW/xzXXXANAq1atiIuL4/bbb+eyyy5j7NixR/HLBnf99ddXTq9cuZKHH36YnJwc8vPzGT06+HjwV199NQCnn346mzdv/tYxiOdQaRkfrd7Nhb1PIi46kpKycr7M2Mt5p7Vnd+4h8opKuPGFeXRv34Krh6RSXu74fP1eFmzeF3R/fX/5AQUV9e9+FfuVgzqyMauAn/1zeZ2xrA1oTE1Njic7v7jySvym9C7M3ZjNxqyCKp+55aw0Plq9m74dW3HnyO4M7pIMeCfyy572LjbGn53G8FPaclb3dpWfa9MihmdnbwCgU3I8XdoePknPfmAkae1aUFJWTmmZIz6mavXlwM5JtI6PJjoygmm3pxMZYfTokMhT1w+q3CYhJoo7RnQHvMT53dM7KxHU15Gu3EMtKSmJkSNH8sEHHwRNBBXVOeA9xBRMbdVKtS0vLy9n7ty5xMfH13m8yMhISktLa2xTYfbs2cyaNYu5c+eSkJDAyJEjK++rv/322/nd735Hr169GD9+fGX848aN47HHHquxr7i4uMq6+6ioKBYsWMDHH3/MG2+8wcSJE/nkk0+qbD969Gh2797N0KFDefHFF2uNsUKLFi0qp2+55RbeffddBg4cyNSpU5k9e3bQz1T8Fkf6HcKdc45lmQfYdaCIMf1Orlw+b2M2BmQXFPPJ2j3ERkXQt2Nrdh4o5K+fZHDnyO4MS2vD+KkLg+53Q1ZBZV16XQoCGmHHDe/Kf4/uSau4aLZkF3DeH2cD8ItLe/G7GWsrtxtxWntSk+N5za+6+b//Gs6wbm0oLC6j9y8/4L/OO4WHLukNeI28ry/YyrVDU3n36+1c1j+FB8f0IiYqgsiIw//H+nZszTs/Oov4mEh6ndyqRpw/G9OrMhGktPZKOjN+fC7b9h8krZ339xkdGUF0kCas6MgIFv7PhQDERB35np246EjOObXdEbc7VidcImgMWVlZREdHk5SURGFhIbNmzeLBBx88pn2NGDGCadOmcf7557Ny5UqWL/eugNLT07n33nvJzs6mVatWvPnmmwwcOBCAiy++mIkTJ/LTn/4UgKVLlzJo0KCjPvaBAwdITk4mISGBtWvXMm/evMp16enpbNu2jSVLllTGdMEFF3DllVdy//3306FDB/bt20deXh5du3atst/8/HwOHjzIpZdeyplnnkmPHj1qHHvmzJm1xtWyZcvKEk4weXl5pKSkUFJSwrRp0+jUKehziWFrY1Y+/1ySyR0jutMqLor8Q6Vc//w8Vu/M5b9GnMKDY3rx+sKtrMg8QMaefLq1a8GbizMB74S7J/cQL36xqdb9pyZ7FyDPzd7Ac2yoM5b2LWO5cmBHNu0tqKyXr3Dr2d1YnpnDoi37eeq6gVw9pGrJtWvbgOR/Vjc27CngpjO70LVtC2KjIoiLjuRno3vy4ardnJHmXdXHx0Sy7rdjiI06fDaOj4nk1nO8p8dvHp5WZ7wVpYPa/Pvuc/hyw97K9os+HVvRp2PNpBFMfRJAQ1EiOA527tzJuHHjKCsro7y8nOuuu+6Yqz/uvPNOxo8fz4ABAxg0aBDDhg0DICUlhUcffZThw4eTkpLCkCFDKCvzrpyefvpp7rrrLgYMGEBpaSkjRoxg0qRJR33sMWPGMGnSJAYMGEDPnj1r3PV03XXXsXTpUpKTvf8cffr04be//S0XX3wx5eXlREdH88wzz9RIBHl5eVx55ZUUFRXhnKtsdK6vW265hQkTJlQ2Flf3m9/8hvT0dLp27Ur//v3rTBonupe/3ERK6zjS2rVg8pyNtEv0GlTBa4xduLnqvenPz9nI0m05zN90uJpmUcD964FX3bXJ3F/ISa1i2Z17qMryHh0SmX732Tz+wTpmrNhJy7go3v/xuZUnzZyDxczbuI8Jry4G4L6LTqW0zJGxJ59h3doEPdbDl/Umc38hMVER/OHaATXWJyXEcN0ZnassC0wCx1v/1Nb0T63ZuN3cNLsxi4cOHeqq31e/Zs0aevfu3UgRhY+xY8dy//33c8EFFzR2KCHTmH9Lzjmy8g/RPjGWsnJHVOThK8aKxsIpX2zie+ldeHBML6Yv20G7xBhe+mITX2ZkH/d47rvwVP48az3gNaB2Tk7gjYXbeOmLTbx719kkxkbyztfeve9vThjOjpwizkhrw+2vLMQwXr29fn1I9v5/H1BYUsamxy7V090hZGaLnXNDg65TIpAjycnJqXxg7s0332zscEIqFH9LBYdKmbcxmwt6n1TrNhl78rn/H0tZsf0ACTGRxEZF8NItZ/Dyl5uZuyGbvflVr7YHpLZmeeaBGvvpdXJL2ibGsHzbAfL8RtJL+p3Mx2v3UFxazqDOSSzdlsMZackcLC5j1Y5cxg5IoVu7FpW3SwKc1CqW+b+4EOcce/IOcZJ/t095uSO7oJj2Lb32FuccxWXl3+qqe2v2Qb7ZnceFfWr/feTbqysRqGpIjigpKanyDiUJLq+ohJZx0fxj4VY6JsXz8Lsr+fut6Szeuo+3l2zn8/V7mXnfCGat2U1cdCS3nJXGFxl7KS4tp11iDFc9+1Xlvg4Wl3GwuIyrA5ZVVz0JPHxZb0b3PbnKXSV/+2ozj0xfxf0XncbYAR353/dX88drB/DgP5fzy7F96Z/amv0FxSQlRHOotJykhBgu65/CodIyEmO9U4OZVSYBgIgIq0wCFeu/bdVLl7YJVe64kYZ3wpQIevXqpWKlfCvOOdauXXvUJYIvM/Zy04vzefzaAfzsrbpvb6wQExlBcVl5lWV3n9+Dz77JYsX2qif5V29LJyUpjgWb9vHQ2yuqrLu0/8mckdaG8WfX7DrbOceOA0V0Sqp5N5mEnxO+RBAXF0d2dra6opZjVjEeQVxcHDdMnsvA1CQeGN2T6MgI3lqcycRP1vPwZX1YtzuPxVv2c6CwhMVb9tO5TTzb9nlPf/+i2kkaoF1ibGW1Tvf2LYiNimT1zlyKy8q59exuvLl4G3lFpYw/O43/Ou8U1u3OY8X2A3z6wEi+/+J8Tu+aXHnbYPf2iZzSrgX7DxYz4dUl3jEv7U1qcvCraTNTEpB6OSFKBBqhTL4N56CotAwXEU3Hjp0Y/vhnlet+cGZX/j5vyxH3MaRLEku25lRZdkGvDjx6RV/25h+idXw0p7T3uiHZkl3A5+v3clN6Fw6VlrM5u6DyPvW9+YfI2JPPmae0pbSsnAgzIiJqXtyc/8RsNu0tqHFrpEhtTvjGYpG6bM8p5H/fX82QLsncfu4pvDBnIweLy7hjxCn89K1lvLf823V6+8R3B3L5wBQmfpLBweIyLujdgUgz0k9pe5y+QU178opYtT2X83t1CNkx5MSiRCAnhN25RWzMKmB498Mn2Ky8Q5Q7x/demMe4s9K4anAn/jJrPSe3jiMywth1oIjn/fvoAU7vmlyjn3eAi/qcROb+Qtbs9PqpWvPrMWTuP8iHq3eTlBDN/7yzsnLbv944mDH9Tmbmql1c2i8l6BW7SFOjRCDN1p68Itq2iKXcOc79w6fsyi1i5n0j+CJjL1uyC3hl7pGrberSJ6UVv7+mf2WPl1/5T4mekXb4gaacg8UM+vVHlfMv3DyUi3SrozQzSgTSZK3cfoC46Eh6dEisXPaXWetZlpnDuLPSGDdlQeW970ejdXw0Bwq9QULOPbUdD13Sm6lfbeKqwansPFDIqF4dyNiTT1q7FrRLjD3C3rwuhPOLSvnLx+t55PI+VbpEFmkOlAikwZWVO7buO8iW7AJG9uxASVk5W/cdZNHmfUSYsW3fQRyH+3w/99R2XD6gI/+3aFuVLg5qY+Y18vZJacXqnbmce2o7RvXqwGvzt/LrK/sxvHtbDhws4V/LtnNTetcqnYmJhCMlAgm5LzP2crC4jH6dWrFtXyHXPX+4T6AxfU9mc3ZBlS6Cj0ZK6zj+dusw/vbVZr4zuBMdWsYSHxNJflEpXdokVOmKQUSCUyKQY7Z6Ry4t46Iqn1gtL3fsO1jMrNW7KXOOrLxDfL01p3LwjiOJiYrgnvN7MH/TPh69og/JCTHkHyrlyQ+/4UBhCV3aJLB2Vy7Tbj+T0x7+DwCfPjCSbu1aHGHPIlKXE/6BMjn+nHNMnrORx/6zls5t4pl53wgmvLqEOfU84Vd3/dDOPDy2N6VljuQWMQSOH9Y2MZanbxxc4zPn92zPp+uyODmgiwMROf5UIhA2ZOUTExlBxp58cotKuHxARy586jM27i0Iun1K6zhKysrZm18MQHq3NszftI/LBqSQue8gAzsn0T4xls3ZB2kVH8WE87pX6a+mvgoOlbJpbwH9OjX/bn5FGptKBMJHq3cTYVT2gLnzQCEJMVHM3ZBd2R98hXvfWFrnvub87Hxem7+VR6avYvIPTueC3ieFpDG2RWyUkoBIA1AiOAEdLC7ll/9axYTzTmHF9gM8N3sD3+zOB+DZm4bwx5nr2FTL1X6gi/ucxPfP7EpyQgwl5eXMXLmLM7u3JToygpuHd2VoWnLl/fci0nypaugEsjf/EBv25PPpuiwmfVb3kIHV/fySXtxyVhrPf7aRHwzvSpsWMSGKUkQag6qGThAbs/JJaR1PfIz3MFNJWTmfrcvi/RU7mbshm45JcTU6PgumRUwkz37/dF78fCOfr9/LT0f35LZzuhEdGcG9F54a4m8hIk2NEkEzcbC4lFFPfsbInu2ZMu4MducV8Yu3V/DpusN38ezKPdz76l9vHMw9r38NwD/vHM69byzl6sGdyC0q5TuDOzGocxKnd01m14GiKk/1ikj4UdVQE/f11v3c9rdF7CsorlzWt2MrVu3IrbJdanI8mfsL+c2VfWnfMpbRfU/2hz2M0oleRFQ11JyUlpXzzKcbuHZoKimt4qoMYVhh1Y5c+nZsRWFxGef36sD9F51Gi5hIlm7LYWBqUmVvmANSkxo4ehFpjkKaCMxsDPAXIBJ40Tn3+2rrk4EpQHegCLjVObeyxo7CyNtfb+dPs77h38t3EOyOzAcuPo3BXZI5q3vN0dgGd0luoChF5EQSskRgZpHAM8BFQCaw0MymO+dWB2z2C2Cpc+4qM+vlb39BqGJqqvIPlXL3a0u4fmhnHpuxBoCMPd7tnv97VT+uH9qZtbvymPrVZu4c2UMdqInIcRXKEsEwIMM5txHAzN4ArgQCE0Ef4DEA59xaM0szs5Occ7tDGFeTsfNAIQcKS7ht6iK25xQye10WibFRlT1qAtyU3hWAfp1a88R3BzZmuCJyggplIugEbAuYzwTSq22zDLga+MLMhgFdgVSgSiIwszuAOwC6dOkSqngbTM7BYpZlHmDclAU11t0zqgd3jPAGMY/TWLQi0gBCmQiC1V9Uv0Xp98BfzGwpsAL4Giit8SHnJgOTwbtr6PiGGXoZe/JpFRdFh1ZxTJu/pcqwhxVuHt6VmMgIbhjWBTOrHMxcRCTUQpkIMoHOAfOpwI7ADZxzucB4APNaPjf5rxPCnG+y6JgUz4VPfUZUhDHurDRe+uLw1xuQ2ppRvTpw3mnt1dArIo0mlIlgIXCqmXUDtgM3AN8L3MDMkoCDzrli4HZgjp8cmq3i0nIKi8uY8uUm/vLx+srlpeWuMgm0S4zltnO6Mf7sNA15KCKNLmSJwDlXamZ3AzPxbh+d4pxbZWYT/PWTgN7AK2ZWhteIfFuo4gm11Ttyufu1JUG7bm4VF0Vu0eEar08fOI+WcdENGZ6ISK1C+hyBc24GMKPaskkB03OBZt+5zdbsg1z69Oc1lr96Wzo7cgq5sM9JfJmxl2c+zSCvqFRJQESaFD1ZfBScc5UPcf3srWVsyT5Iv06tq9T7A/zkotMYNzyN1gmHT/iXD+zI2AEpDRqviEh9KBHUoqzc8dbibVzSP4U3F2Xyt682U1pWzo4DRVW2m79pHwBPfncg//3mMgB+fEHwQk71J4FFRJoCJYIg9hUU8/aSTH77/hrmfLOX91fsrHP7136Yzlnd25GRlc85Pdo1UJQiIseHEkE1by/J5IE3l1HuP63w/oqdmMF/X3QaT3z4DQB/uKY/PTq05NpJX5GaHM9Z3b2T/4NjejVW2CIix0yJwLcjp5BX523h2dkb6NImgUv7pzCsWzIvzNnEOae2467ze3DbOafw0ZrdXD4gBTNj0f9cWDlIjIhIcxXWiaCkrJyH3l7Bu19vp7T88APL94zqwXeHes/Cjep1UuXy+JhIrhjYsXK+bWJswwUrIhIiYZ0I3li4jbcWZ1ZZ9vwPTuei3ifV8gkRkRNPWCaCQ6VlPDFzHS98volOSfF8eP8IlmceIK1dAimt4xs7PBGRBhWWiWDGip288Ll373+3di1oERvF8O5tGzkqEZHGEdHYATSG/QUlAHRKiuexq/s3cjQiIo0r7EoEpWXlTJ6zEYAvHjxfD3mJSNgLuxLBy19uZleu93SwkoCISBgmguXbDwDeIPAiIhKGiSA7/xBDuyZz96hm3+mpiMhxEYaJoJi2iTGNHYaISJMRfomg4JCeCBYRCRBWiaCopIx9BcW0baESgYhIhbBKBB+s3EW5g/RuenhMRKRCWCWCjVn5mMFZeopYRKRSWCWC3KJSEmOjiIjQ8wMiIhXCLBGU0EoDx4uIVBFeiaCwlFbxSgQiIoHCKhHkFZXQMi7sulcSEalTWCWC3KJSVQ2JiFQTXomgsIRWKhGIiFQRVomgpKyc2Oiw+soiIkcUVmdFd+RNRETCTkgTgZmNMbN1ZpZhZj8Psr61mf3bzJaZ2SozGx/KeJwD0DMEIiKBQpYIzCwSeAa4BOgD3Ghmfaptdhew2jk3EBgJPGlmIewIyKGxaEREqgpliWAYkOGc2+icKwbeAK6sto0DWpo3VFgisA8oDVVAzqk8ICJSXSgTQSdgW8B8pr8s0ESgN7ADWAHc65wrr74jM7vDzBaZ2aKsrKxjDsiBSgQiItWEMhEEO+VWb68dDSwFOgKDgIlm1qrGh5yb7Jwb6pwb2r59+28ZlDKBiEigUCaCTKBzwHwq3pV/oPHA286TAWwCeoUqIOd035CISHWhTAQLgVPNrJvfAHwDML3aNluBCwDM7CSgJ7AxVAGpakhEpKaQPWbrnCs1s7uBmUAkMMU5t8rMJvjrJwG/Aaaa2Qq8qqQHnXN7QxeTGotFRKoLaX8LzrkZwIxqyyYFTO8ALg5lDNWOjalIICJShZ4sFhEJc2GVCEBtBCIi1YVXIlCRQESkhrBKBA49RyAiUt0RE4GZjTWzEyJheI3FjR2FiEjTUp8T/A3AejN73Mx6hzqgUPJKBCIiEuiIicA5931gMLABeNnM5vp9/7QMeXTHmXNqLBYRqa5eVT7OuVzgn3g9iKYAVwFLzOyeEMZ23Dn0HIGISHX1aSO43MzeAT4BooFhzrlLgIHAAyGOT0REQqw+TxZ/F/iTc25O4ELn3EEzuzU0YYWGupgQEampPongEWBnxYyZxQMnOec2O+c+DllkIaCRKkVEaqpPG8GbQOBgMWX+subH6TkCEZHq6pMIovyhJgHwp0M4rnDoOI1ZLCJSQ30SQZaZXVExY2ZXAiHrKjqU1EYgIlJTfdoIJgDTzGwi3nl0G3BzSKMKIZUIRESqOmIicM5tAM40s0TAnHN5oQ8rNNTnnIhITfUamMbMLgP6AnEVD2Q5534dwrhCwjmnxmIRkWrq80DZJOB64B68qqHvAl1DHFdIaMxiEZGa6tNYfJZz7mZgv3PuV8BwoHNowwoNNRaLiNRUn0RQ5L8fNLOOQAnQLXQhhZiKBCIiVdSnjeDfZpYE/BFYglfD8kIogwolpQERkarqTAT+gDQfO+dygH+a2XtAnHPuQEMEdzw5p3uGRESCqbNqyDlXDjwZMH+oOSYB8NoHQDVDIiLV1aeN4EMzu8aaeUf+FeUB3T4qIlJVfdoIfgK0AErNrAivmt0551qFNLLjrKJqqHmnMxGR468+TxY3uyEpgzlcIhARkUBHTARmNiLY8uoD1TQXKhGIiFRVn6qhnwZMxwHDgMXAqCN90MzGAH8BIoEXnXO/r7b+p8BNAbH0Bto75/bVI66jopuGRESCq0/V0OWB82bWGXj8SJ8zs0jgGeAiIBNYaGbTnXOrA/b9R7znEzCzy4H7Q5EEwBuLwD9OKHYvItJs1eeuoeoygX712G4YkOGc2+gPZvMGcGUd298IvH4M8dSLSgQiIsHVp43grxxua40ABgHL6rHvTnhjF1TIBNJrOUYCMAa4u5b1dwB3AHTp0qUeh66dCgQiIlXVp41gUcB0KfC6c+7Lenwu2Cm3tuvyy4Eva6sWcs5NBiYDDB069Jiu7SsfKNN9QyIiVdQnEbwFFDnnysCr+zezBOfcwSN8LpOqvZSmAjtq2fYGQlgtFEglAhGRqurTRvAxEB8wHw/MqsfnFgKnmlk3M4vBO9lPr76RmbUGzgP+VY99HjOn8clERIKqT4kgzjmXXzHjnMv36/Tr5JwrNbO7gZl4t49Occ6tMrMJ/vpJ/qZXAR865wqOPvz6O1w1JCIigeqTCArMbIhzbgmAmZ0OFNZn5865GcCMassmVZufCkytz/6+jconi5UJRESqqE8iuA9408wq6vdT8IaubFYq+xpSmUBEpIr6PFC20Mx6AT3xalbWOudKQh7ZcaYSgYhIcPUZvP4uoIVzbqVzbgWQaGY/Cn1ox5ceKBMRCa4+dw390B+hDADn3H7ghyGLSEREGlR9EkFE4KA0fh9CMaELKUQqRyhT3ZCISKD6NBbPBP7PzCbhnU4nAP8JaVQhUNnpXCPHISLS1NQnETyI18/PnXjn0a/x7hxqVjRmsYhIcEesGvIHsJ8HbASGAhcAa0Ic13GnEcpERIKrtURgZqfhdQtxI5AN/APAOXd+w4R2fB0es1ipQEQkUF1VQ2uBz4HLnXMZAGZ2f4NEFULKAyIiVdVVNXQNsAv41MxeMLMLaMY1K3qMQEQkuFoTgXPuHefc9UAvYDZwP3CSmT1nZhc3UHzHjTqdExEJrj6NxQXOuWnOubF4YwosBX4e6sCON4duGxIRCeaoxix2zu1zzj3vnBsVqoBCRiUCEZGgjmXw+mZJnc6JiAQXNomggrqhFhGpKmwSgXofFREJLnwSQUVfQyoQiIhUET6JQI3FIiJBhU8i8N9VIhARqSp8EoHGLBYRCSpsEkEl5QERkSrCJhHoriERkeDCJhFUUIFARKSqsEkETmMWi4gEFT6JQGMWi4gEFT6JQJ2PiogEFdJEYGZjzGydmWWYWdCuq81spJktNbNVZvZZKOPxjhfqI4iINC91DVX5rZhZJPAMcBGQCSw0s+nOudUB2yQBzwJjnHNbzaxDqOLRTUMiIsGFskQwDMhwzm10zhUDbwBXVtvme8DbzrmtAM65PaEKRg+UiYgEF8pE0AnYFjCf6S8LdBqQbGazzWyxmd0cbEdmdoeZLTKzRVlZWccUjLqYEBEJLpSJINgpt3oNTRRwOnAZMBr4f2Z2Wo0POTfZOTfUOTe0ffv2xxSMHigTEQkuZG0EeCWAzgHzqcCOINvsdc4VAAVmNgcYCHxz/MOp6IZaRQIRkUChLBEsBE41s25mFgPcAEyvts2/gHPNLMrMEoB0YE0oglE31CIiwYWsROCcKzWzu4GZQCQwxTm3yswm+OsnOefWmNkHwHKgHHjRObcyVDGJiEhNoawawjk3A5hRbdmkavN/BP4YyjhAjcUiIrUJvyeLVTkkIlJF+CQCjVksIhJU+CQCNRaLiAQVfolAmUBEpIqwSQSHKROIiAQKm0Tg1O2ciEhQ4ZMIVDUkIhJU2CSCCsoDIiJVhU0i0JjFIiLBhU8i0JjFIiJBhU0iqKACgYhIVWGTCDQegYhIcOGTCPx3lQhERKoKn0SgMYtFRIIKn0RQMaE8ICJSRfgkAnU6JyISVNgkggp6jkBEpKowSgS6bUhEJJiwSQSqGhIRCS58EoH/rpohEZGqwicRaMxiEZGgwigRaMxiEZFgwiYRVFAeEBGpKmwSge4ZEhEJLnwSQWVrcaOGISLS5IRPIkB9DYmIBBM2iQCNWSwiElRIE4GZjTGzdWaWYWY/D7J+pJkdMLOl/uuXoYpFNUMiIsFFhWrHZhYJPANcBGQCC81sunNudbVNP3fOjQ1VHEHiaqhDiYg0C6EsEQwDMpxzG51zxcAbwJUhPF6dNEKZiEhwoUwEnYBtAfOZ/rLqhpvZMjP7j5n1DbYjM7vDzBaZ2aKsrKxjCqaysVgFAhGRKkKZCIKdcqtfly8BujrnBgJ/Bd4NtiPn3GTn3FDn3ND27dsfUzDqdE5EJLhQJoJMoHPAfCqwI3AD51yucy7fn54BRJtZu1AEo07nRESCC2UiWAicambdzCwGuAGYHriBmZ1sfuutmQ3z48kORTBOT5SJiAQVsruGnHOlZnY3MBOIBKY451aZ2QR//STgWuBOMysFCoEbnAtNs65KBCIiwYUsEUBldc+MassmBUxPBCaGMobqlAdERKoKuyeLRUSkqrBJBIdvH1WZQEQkUPgkAt0+KiISVPglAmUCEZEqwicR+O/qhlpEpKqwSQQVVCIQEakqbBJBiB5PEBFp9sInETR2ACIiTVT4JAI1FouIBBU2iQCNWSwiElTYJAKVCEREggubRFBBiUBEpKqwSQRqLBYRCS58EkFlFxMqEoiIBAqfRKAxi0VEggqbRJDSOo7L+qfQMi6kQzCIiDQ7YXNWPL1rG07v2qaxwxARaXLCpkQgIiLBKRGIiIQ5JQIRkTCnRCAiEuaUCEREwpwSgYhImFMiEBEJc0oEIiJhzprbEI5mlgVsOcaPtwP2HsdwQk3xhk5zihWaV7zNKVZoXvF+m1i7OufaB1vR7BLBt2Fmi5xzQxs7jvpSvKHTnGKF5hVvc4oVmle8oYpVVUMiImFOiUBEJMyFWyKY3NgBHCXFGzrNKVZoXvE2p1ihecUbkljDqo1ARERqCrcSgYiIVKNEICIS5sImEZjZGDNbZ2YZZvbzxo4HwMymmNkeM1sZsKyNmX1kZuv99+SAdQ/58a8zs9ENHGtnM/vUzNaY2Sozu7epxmtmcWa2wMyW+bH+qqnGGnD8SDP72szeawaxbjazFWa21MwWNYN4k8zsLTNb6//9Dm+K8ZpZT/83rXjlmtl9DRKrc+6EfwGRwAbgFCAGWAb0aQJxjQCGACsDlj0O/Nyf/jnwB3+6jx93LNDN/z6RDRhrCjDEn24JfOPH1OTiBQxI9KejgfnAmU0x1oCYfwK8BrzXlP8O/Bg2A+2qLWvK8f4NuN2fjgGSmnK8fhyRwC6ga0PE2qBfrrFewHBgZsD8Q8BDjR2XH0saVRPBOiDFn04B1gWLGZgJDG/EuP8FXNTU4wUSgCVAelONFUgFPgZGBSSCJhmrf8xgiaBJxgu0Ajbh3xjT1OMNOO7FwJcNFWu4VA11ArYFzGf6y5qik5xzOwH89w7+8ibzHcwsDRiMd6XdJOP1q1qWAnuAj5xzTTZW4M/Az4DygGVNNVYAB3xoZovN7A5/WVON9xQgC3jZr3p70cxaNOF4K9wAvO5PhzzWcEkEFmRZc7tvtkl8BzNLBP4J3Oecy61r0yDLGixe51yZc24Q3tX2MDPrV8fmjRarmY0F9jjnFtf3I0GWNfTfwdnOuSHAJcBdZjaijm0bO94ovOrX55xzg4ECvOqV2jR2vJhZDHAF8OaRNg2y7JhiDZdEkAl0DphPBXY0UixHstvMUgD89z3+8kb/DmYWjZcEpjnn3vYXN9l4AZxzOcBsYAxNM9azgSvMbDPwBjDKzF5torEC4Jzb4b/vAd4BhtF0480EMv0SIcBbeImhqcYLXoJd4pzb7c+HPNZwSQQLgVPNrJufbW8ApjdyTLWZDozzp8fh1cVXLL/BzGLNrBtwKrCgoYIyMwNeAtY4555qyvGaWXszS/Kn44ELgbVNMVbn3EPOuVTnXBre3+UnzrnvN8VYAcyshZm1rJjGq8te2VTjdc7tAraZWU9/0QXA6qYar+9GDlcLVcQU2lgbuhGksV7ApXh3umwA/qex4/Fjeh3YCZTgZffbgLZ4DYfr/fc2Adv/jx//OuCSBo71HLxi53Jgqf+6tCnGCwwAvvZjXQn80l/e5GKtFvdIDjcWN8lY8ercl/mvVRX/l5pqvP7xBwGL/L+Hd4Hkphov3s0N2UDrgGUhj1VdTIiIhLlwqRoSEZFaKBGIiIQ5JQIRkTCnRCAiEuaUCEREwpwSgUg1ZlZWrRfI49ZbrZmlWUBvsyJNQVRjByDSBBU6r3sKkbCgEoFIPfn98P/BvLEOFphZD395VzP72MyW++9d/OUnmdk75o2LsMzMzvJ3FWlmL5g3VsKH/tPPIo1GiUCkpvhqVUPXB6zLdc4NAybi9RqKP/2Kc24AMA142l/+NPCZc24gXv82q/zlpwLPOOf6AjnANSH9NiJHoCeLRaoxs3znXGKQ5ZuBUc65jX4HfLucc23NbC9ef/El/vKdzrl2ZpYFpDrnDgXsIw2vW+xT/fkHgWjn3G8b4KuJBKUSgcjRcbVM17ZNMIcCpstQW500MiUCkaNzfcD7XH/6K7yeQwFuAr7wpz8G7oTKgXJaNVSQIkdDVyIiNcX7o5tV+MA5V3ELaayZzce7iLrRX/ZjYIqZ/RRvNKzx/vJ7gclmdhvelf+deL3NijQpaiMQqSe/jWCoc25vY8cicjypakhEJMypRCAiEuZUIhARCXNKBCIiYU6JQEQkzCkRiIiEOSUCEZEw9/8BkPDHpFYR6jAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.epoch, history.history['accuracy'], label = '3 hidden layers - train')\n",
    "#ax.plot(history.epoch, history.history['val_accuracy'], label = '3 hidden layers - val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy per Epoch')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6170870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 746us/step - loss: 0.2546 - accuracy: 0.9035 - precision_34: 0.9110 - recall_34: 0.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2546454668045044,\n",
       " 0.9035000205039978,\n",
       " 0.9110320210456848,\n",
       " 0.8960000276565552]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaler.transform(X_test), enc.transform(y_test.reshape(-1,1)).toarray())  # Calculate performance metrics on unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_train[:,16:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cdb72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat_trn = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, yhat_trn))\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train.shape, y_predict.shape)\n",
    "print(accuracy_score(y_train,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "857fd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713641488162345\n",
      "0.903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_trn_rf = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_trn_rf))\n",
    "y_rf = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe6633",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3e29e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, X=X_trn_scaled, n_classes=6, opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "823c47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "111/111 [==============================] - 0s 918us/step - loss: 1.4218 - accuracy: 0.3193\n",
      "Epoch 2/350\n",
      "111/111 [==============================] - 0s 885us/step - loss: 0.9668 - accuracy: 0.6304\n",
      "Epoch 3/350\n",
      "111/111 [==============================] - 0s 883us/step - loss: 0.6198 - accuracy: 0.7957\n",
      "Epoch 4/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.5157 - accuracy: 0.8176\n",
      "Epoch 5/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.4674 - accuracy: 0.8262\n",
      "Epoch 6/350\n",
      "111/111 [==============================] - 0s 929us/step - loss: 0.4468 - accuracy: 0.8340\n",
      "Epoch 7/350\n",
      "111/111 [==============================] - 0s 948us/step - loss: 0.4370 - accuracy: 0.8325\n",
      "Epoch 8/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.4243 - accuracy: 0.8381\n",
      "Epoch 9/350\n",
      "111/111 [==============================] - 0s 924us/step - loss: 0.4267 - accuracy: 0.8383\n",
      "Epoch 10/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.4054 - accuracy: 0.8435\n",
      "Epoch 11/350\n",
      "111/111 [==============================] - 0s 945us/step - loss: 0.4022 - accuracy: 0.8444\n",
      "Epoch 12/350\n",
      "111/111 [==============================] - 0s 928us/step - loss: 0.3984 - accuracy: 0.8453\n",
      "Epoch 13/350\n",
      "111/111 [==============================] - 0s 895us/step - loss: 0.3963 - accuracy: 0.8437\n",
      "Epoch 14/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.3966 - accuracy: 0.8437\n",
      "Epoch 15/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.3865 - accuracy: 0.8496\n",
      "Epoch 16/350\n",
      "111/111 [==============================] - 0s 891us/step - loss: 0.3903 - accuracy: 0.8476\n",
      "Epoch 17/350\n",
      "111/111 [==============================] - 0s 876us/step - loss: 0.3798 - accuracy: 0.8492\n",
      "Epoch 18/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.3848 - accuracy: 0.8496\n",
      "Epoch 19/350\n",
      "111/111 [==============================] - 0s 878us/step - loss: 0.3816 - accuracy: 0.8462\n",
      "Epoch 20/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.3764 - accuracy: 0.8512\n",
      "Epoch 21/350\n",
      "111/111 [==============================] - 0s 939us/step - loss: 0.3780 - accuracy: 0.8519\n",
      "Epoch 22/350\n",
      "111/111 [==============================] - 0s 889us/step - loss: 0.3766 - accuracy: 0.8496\n",
      "Epoch 23/350\n",
      "111/111 [==============================] - 0s 923us/step - loss: 0.3709 - accuracy: 0.8541\n",
      "Epoch 24/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8552\n",
      "Epoch 25/350\n",
      "111/111 [==============================] - 0s 956us/step - loss: 0.3662 - accuracy: 0.8579\n",
      "Epoch 26/350\n",
      "111/111 [==============================] - 0s 994us/step - loss: 0.3687 - accuracy: 0.8548\n",
      "Epoch 27/350\n",
      "111/111 [==============================] - 0s 970us/step - loss: 0.3708 - accuracy: 0.8494\n",
      "Epoch 28/350\n",
      "111/111 [==============================] - 0s 941us/step - loss: 0.3597 - accuracy: 0.8575\n",
      "Epoch 29/350\n",
      "111/111 [==============================] - 0s 934us/step - loss: 0.3602 - accuracy: 0.8573\n",
      "Epoch 30/350\n",
      "111/111 [==============================] - 0s 920us/step - loss: 0.3617 - accuracy: 0.8559\n",
      "Epoch 31/350\n",
      "111/111 [==============================] - 0s 958us/step - loss: 0.3611 - accuracy: 0.8548\n",
      "Epoch 32/350\n",
      "111/111 [==============================] - 0s 945us/step - loss: 0.3567 - accuracy: 0.8532\n",
      "Epoch 33/350\n",
      "111/111 [==============================] - 0s 913us/step - loss: 0.3502 - accuracy: 0.8591\n",
      "Epoch 34/350\n",
      "111/111 [==============================] - 0s 892us/step - loss: 0.3562 - accuracy: 0.8573\n",
      "Epoch 35/350\n",
      "111/111 [==============================] - 0s 885us/step - loss: 0.3523 - accuracy: 0.8575\n",
      "Epoch 36/350\n",
      "111/111 [==============================] - 0s 985us/step - loss: 0.3495 - accuracy: 0.8591\n",
      "Epoch 37/350\n",
      "111/111 [==============================] - 0s 942us/step - loss: 0.3512 - accuracy: 0.8582\n",
      "Epoch 38/350\n",
      "111/111 [==============================] - 0s 957us/step - loss: 0.3516 - accuracy: 0.8555\n",
      "Epoch 39/350\n",
      "111/111 [==============================] - 0s 902us/step - loss: 0.3440 - accuracy: 0.8643\n",
      "Epoch 40/350\n",
      "111/111 [==============================] - 0s 918us/step - loss: 0.3492 - accuracy: 0.8575\n",
      "Epoch 41/350\n",
      "111/111 [==============================] - 0s 908us/step - loss: 0.3439 - accuracy: 0.8622\n",
      "Epoch 42/350\n",
      "111/111 [==============================] - 0s 870us/step - loss: 0.3422 - accuracy: 0.8609\n",
      "Epoch 43/350\n",
      "111/111 [==============================] - 0s 874us/step - loss: 0.3373 - accuracy: 0.8634\n",
      "Epoch 44/350\n",
      "111/111 [==============================] - 0s 830us/step - loss: 0.3390 - accuracy: 0.8622\n",
      "Epoch 45/350\n",
      "111/111 [==============================] - 0s 870us/step - loss: 0.3394 - accuracy: 0.8586\n",
      "Epoch 46/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.3355 - accuracy: 0.8670\n",
      "Epoch 47/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.3339 - accuracy: 0.8647\n",
      "Epoch 48/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8620\n",
      "Epoch 49/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8643\n",
      "Epoch 50/350\n",
      "111/111 [==============================] - 0s 909us/step - loss: 0.3318 - accuracy: 0.8663\n",
      "Epoch 51/350\n",
      "111/111 [==============================] - 0s 990us/step - loss: 0.3431 - accuracy: 0.8625\n",
      "Epoch 52/350\n",
      "111/111 [==============================] - 0s 931us/step - loss: 0.3288 - accuracy: 0.8692\n",
      "Epoch 53/350\n",
      "111/111 [==============================] - 0s 869us/step - loss: 0.3253 - accuracy: 0.8661\n",
      "Epoch 54/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.3235 - accuracy: 0.8676\n",
      "Epoch 55/350\n",
      "111/111 [==============================] - 0s 871us/step - loss: 0.3251 - accuracy: 0.8694\n",
      "Epoch 56/350\n",
      "111/111 [==============================] - 0s 955us/step - loss: 0.3238 - accuracy: 0.8683\n",
      "Epoch 57/350\n",
      "111/111 [==============================] - 0s 964us/step - loss: 0.3194 - accuracy: 0.8710\n",
      "Epoch 58/350\n",
      "111/111 [==============================] - 0s 971us/step - loss: 0.3168 - accuracy: 0.8762\n",
      "Epoch 59/350\n",
      "111/111 [==============================] - 0s 927us/step - loss: 0.3173 - accuracy: 0.8722\n",
      "Epoch 60/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.3212 - accuracy: 0.8694\n",
      "Epoch 61/350\n",
      "111/111 [==============================] - 0s 846us/step - loss: 0.3174 - accuracy: 0.8713\n",
      "Epoch 62/350\n",
      "111/111 [==============================] - 0s 859us/step - loss: 0.3138 - accuracy: 0.8728\n",
      "Epoch 63/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.3210 - accuracy: 0.8694\n",
      "Epoch 64/350\n",
      "111/111 [==============================] - 0s 838us/step - loss: 0.3107 - accuracy: 0.8744\n",
      "Epoch 65/350\n",
      "111/111 [==============================] - 0s 912us/step - loss: 0.3108 - accuracy: 0.8755\n",
      "Epoch 66/350\n",
      "111/111 [==============================] - 0s 889us/step - loss: 0.3125 - accuracy: 0.8753\n",
      "Epoch 67/350\n",
      "111/111 [==============================] - 0s 928us/step - loss: 0.3129 - accuracy: 0.8776\n",
      "Epoch 68/350\n",
      "111/111 [==============================] - 0s 753us/step - loss: 0.3089 - accuracy: 0.8749\n",
      "Epoch 69/350\n",
      "111/111 [==============================] - 0s 982us/step - loss: 0.3107 - accuracy: 0.8773\n",
      "Epoch 70/350\n",
      "111/111 [==============================] - 0s 896us/step - loss: 0.3047 - accuracy: 0.8769\n",
      "Epoch 71/350\n",
      "111/111 [==============================] - 0s 850us/step - loss: 0.3114 - accuracy: 0.8753\n",
      "Epoch 72/350\n",
      "111/111 [==============================] - 0s 971us/step - loss: 0.3097 - accuracy: 0.8755\n",
      "Epoch 73/350\n",
      "111/111 [==============================] - 0s 924us/step - loss: 0.3086 - accuracy: 0.8751\n",
      "Epoch 74/350\n",
      "111/111 [==============================] - 0s 869us/step - loss: 0.3077 - accuracy: 0.8773\n",
      "Epoch 75/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.3028 - accuracy: 0.8785\n",
      "Epoch 76/350\n",
      "111/111 [==============================] - 0s 863us/step - loss: 0.3056 - accuracy: 0.8767\n",
      "Epoch 77/350\n",
      "111/111 [==============================] - 0s 913us/step - loss: 0.3052 - accuracy: 0.8751\n",
      "Epoch 78/350\n",
      "111/111 [==============================] - 0s 908us/step - loss: 0.3056 - accuracy: 0.8746\n",
      "Epoch 79/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 869us/step - loss: 0.3083 - accuracy: 0.8744\n",
      "Epoch 80/350\n",
      "111/111 [==============================] - 0s 870us/step - loss: 0.3022 - accuracy: 0.8818\n",
      "Epoch 81/350\n",
      "111/111 [==============================] - 0s 798us/step - loss: 0.3052 - accuracy: 0.8834\n",
      "Epoch 82/350\n",
      "111/111 [==============================] - 0s 895us/step - loss: 0.2992 - accuracy: 0.8816\n",
      "Epoch 83/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.3014 - accuracy: 0.8794\n",
      "Epoch 84/350\n",
      "111/111 [==============================] - 0s 856us/step - loss: 0.2987 - accuracy: 0.8814\n",
      "Epoch 85/350\n",
      "111/111 [==============================] - 0s 853us/step - loss: 0.2964 - accuracy: 0.8800\n",
      "Epoch 86/350\n",
      "111/111 [==============================] - 0s 831us/step - loss: 0.2957 - accuracy: 0.8841\n",
      "Epoch 87/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.2992 - accuracy: 0.8818\n",
      "Epoch 88/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.2965 - accuracy: 0.8803\n",
      "Epoch 89/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.2948 - accuracy: 0.8818\n",
      "Epoch 90/350\n",
      "111/111 [==============================] - 0s 847us/step - loss: 0.2957 - accuracy: 0.8812\n",
      "Epoch 91/350\n",
      "111/111 [==============================] - 0s 900us/step - loss: 0.2941 - accuracy: 0.8861\n",
      "Epoch 92/350\n",
      "111/111 [==============================] - 0s 941us/step - loss: 0.2971 - accuracy: 0.8868\n",
      "Epoch 93/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.2936 - accuracy: 0.8800\n",
      "Epoch 94/350\n",
      "111/111 [==============================] - 0s 875us/step - loss: 0.2990 - accuracy: 0.8814\n",
      "Epoch 95/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.2988 - accuracy: 0.8807\n",
      "Epoch 96/350\n",
      "111/111 [==============================] - 0s 871us/step - loss: 0.2888 - accuracy: 0.8859\n",
      "Epoch 97/350\n",
      "111/111 [==============================] - 0s 939us/step - loss: 0.2849 - accuracy: 0.8870\n",
      "Epoch 98/350\n",
      "111/111 [==============================] - 0s 829us/step - loss: 0.2904 - accuracy: 0.8855\n",
      "Epoch 99/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.2923 - accuracy: 0.8791\n",
      "Epoch 100/350\n",
      "111/111 [==============================] - 0s 904us/step - loss: 0.2885 - accuracy: 0.8843\n",
      "Epoch 101/350\n",
      "111/111 [==============================] - 0s 913us/step - loss: 0.2885 - accuracy: 0.8846\n",
      "Epoch 102/350\n",
      "111/111 [==============================] - 0s 840us/step - loss: 0.2839 - accuracy: 0.8843\n",
      "Epoch 103/350\n",
      "111/111 [==============================] - 0s 972us/step - loss: 0.2859 - accuracy: 0.8864\n",
      "Epoch 104/350\n",
      "111/111 [==============================] - 0s 873us/step - loss: 0.2836 - accuracy: 0.8861\n",
      "Epoch 105/350\n",
      "111/111 [==============================] - 0s 848us/step - loss: 0.2851 - accuracy: 0.8868\n",
      "Epoch 106/350\n",
      "111/111 [==============================] - 0s 896us/step - loss: 0.2841 - accuracy: 0.8866\n",
      "Epoch 107/350\n",
      "111/111 [==============================] - 0s 933us/step - loss: 0.2854 - accuracy: 0.8884\n",
      "Epoch 108/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.2829 - accuracy: 0.8848\n",
      "Epoch 109/350\n",
      "111/111 [==============================] - 0s 856us/step - loss: 0.2796 - accuracy: 0.8895\n",
      "Epoch 110/350\n",
      "111/111 [==============================] - 0s 963us/step - loss: 0.2878 - accuracy: 0.8830\n",
      "Epoch 111/350\n",
      "111/111 [==============================] - 0s 948us/step - loss: 0.2860 - accuracy: 0.8891\n",
      "Epoch 112/350\n",
      "111/111 [==============================] - 0s 918us/step - loss: 0.2815 - accuracy: 0.8875\n",
      "Epoch 113/350\n",
      "111/111 [==============================] - 0s 902us/step - loss: 0.2825 - accuracy: 0.8875\n",
      "Epoch 114/350\n",
      "111/111 [==============================] - 0s 864us/step - loss: 0.2778 - accuracy: 0.8864\n",
      "Epoch 115/350\n",
      "111/111 [==============================] - 0s 925us/step - loss: 0.2833 - accuracy: 0.8859\n",
      "Epoch 116/350\n",
      "111/111 [==============================] - 0s 852us/step - loss: 0.2751 - accuracy: 0.8902\n",
      "Epoch 117/350\n",
      "111/111 [==============================] - 0s 880us/step - loss: 0.2796 - accuracy: 0.8877\n",
      "Epoch 118/350\n",
      "111/111 [==============================] - 0s 964us/step - loss: 0.2773 - accuracy: 0.8888\n",
      "Epoch 119/350\n",
      "111/111 [==============================] - 0s 828us/step - loss: 0.2743 - accuracy: 0.8927\n",
      "Epoch 120/350\n",
      "111/111 [==============================] - 0s 925us/step - loss: 0.2780 - accuracy: 0.8902\n",
      "Epoch 121/350\n",
      "111/111 [==============================] - 0s 813us/step - loss: 0.2743 - accuracy: 0.8906\n",
      "Epoch 122/350\n",
      "111/111 [==============================] - 0s 901us/step - loss: 0.2728 - accuracy: 0.8924\n",
      "Epoch 123/350\n",
      "111/111 [==============================] - 0s 861us/step - loss: 0.2748 - accuracy: 0.8884\n",
      "Epoch 124/350\n",
      "111/111 [==============================] - 0s 895us/step - loss: 0.2736 - accuracy: 0.8927\n",
      "Epoch 125/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.2807 - accuracy: 0.8922\n",
      "Epoch 126/350\n",
      "111/111 [==============================] - 0s 861us/step - loss: 0.2740 - accuracy: 0.8945\n",
      "Epoch 127/350\n",
      "111/111 [==============================] - 0s 842us/step - loss: 0.2737 - accuracy: 0.8886\n",
      "Epoch 128/350\n",
      "111/111 [==============================] - 0s 856us/step - loss: 0.2715 - accuracy: 0.8929\n",
      "Epoch 129/350\n",
      "111/111 [==============================] - 0s 882us/step - loss: 0.2690 - accuracy: 0.8931\n",
      "Epoch 130/350\n",
      "111/111 [==============================] - 0s 905us/step - loss: 0.2712 - accuracy: 0.8918\n",
      "Epoch 131/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.2661 - accuracy: 0.8940\n",
      "Epoch 132/350\n",
      "111/111 [==============================] - 0s 926us/step - loss: 0.2729 - accuracy: 0.8893\n",
      "Epoch 133/350\n",
      "111/111 [==============================] - 0s 842us/step - loss: 0.2687 - accuracy: 0.8954\n",
      "Epoch 134/350\n",
      "111/111 [==============================] - 0s 960us/step - loss: 0.2633 - accuracy: 0.8970\n",
      "Epoch 135/350\n",
      "111/111 [==============================] - 0s 952us/step - loss: 0.2719 - accuracy: 0.8924\n",
      "Epoch 136/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.2639 - accuracy: 0.8961\n",
      "Epoch 137/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.2630 - accuracy: 0.8990\n",
      "Epoch 138/350\n",
      "111/111 [==============================] - 0s 853us/step - loss: 0.2627 - accuracy: 0.8938\n",
      "Epoch 139/350\n",
      "111/111 [==============================] - 0s 847us/step - loss: 0.2636 - accuracy: 0.8920\n",
      "Epoch 140/350\n",
      "111/111 [==============================] - 0s 890us/step - loss: 0.2620 - accuracy: 0.8979\n",
      "Epoch 141/350\n",
      "111/111 [==============================] - 0s 968us/step - loss: 0.2632 - accuracy: 0.8979\n",
      "Epoch 142/350\n",
      "111/111 [==============================] - 0s 965us/step - loss: 0.2577 - accuracy: 0.8997\n",
      "Epoch 143/350\n",
      "111/111 [==============================] - 0s 912us/step - loss: 0.2593 - accuracy: 0.8972\n",
      "Epoch 144/350\n",
      "111/111 [==============================] - 0s 863us/step - loss: 0.2587 - accuracy: 0.8997\n",
      "Epoch 145/350\n",
      "111/111 [==============================] - 0s 866us/step - loss: 0.2592 - accuracy: 0.9001\n",
      "Epoch 146/350\n",
      "111/111 [==============================] - 0s 846us/step - loss: 0.2610 - accuracy: 0.8988\n",
      "Epoch 147/350\n",
      "111/111 [==============================] - 0s 891us/step - loss: 0.2563 - accuracy: 0.9039\n",
      "Epoch 148/350\n",
      "111/111 [==============================] - 0s 822us/step - loss: 0.2506 - accuracy: 0.9033\n",
      "Epoch 149/350\n",
      "111/111 [==============================] - 0s 884us/step - loss: 0.2578 - accuracy: 0.8985\n",
      "Epoch 150/350\n",
      "111/111 [==============================] - 0s 856us/step - loss: 0.2560 - accuracy: 0.9033\n",
      "Epoch 151/350\n",
      "111/111 [==============================] - 0s 869us/step - loss: 0.2534 - accuracy: 0.9008\n",
      "Epoch 152/350\n",
      "111/111 [==============================] - 0s 881us/step - loss: 0.2572 - accuracy: 0.8976\n",
      "Epoch 153/350\n",
      "111/111 [==============================] - 0s 902us/step - loss: 0.2521 - accuracy: 0.9037\n",
      "Epoch 154/350\n",
      "111/111 [==============================] - 0s 841us/step - loss: 0.2497 - accuracy: 0.9012\n",
      "Epoch 155/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.2539 - accuracy: 0.8956\n",
      "Epoch 156/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.2527 - accuracy: 0.9015\n",
      "Epoch 157/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 1ms/step - loss: 0.2512 - accuracy: 0.9044\n",
      "Epoch 158/350\n",
      "111/111 [==============================] - 0s 976us/step - loss: 0.2537 - accuracy: 0.9015\n",
      "Epoch 159/350\n",
      "111/111 [==============================] - 0s 890us/step - loss: 0.2453 - accuracy: 0.9051\n",
      "Epoch 160/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.2497 - accuracy: 0.8992\n",
      "Epoch 161/350\n",
      "111/111 [==============================] - 0s 843us/step - loss: 0.2460 - accuracy: 0.9028\n",
      "Epoch 162/350\n",
      "111/111 [==============================] - 0s 886us/step - loss: 0.2540 - accuracy: 0.9012\n",
      "Epoch 163/350\n",
      "111/111 [==============================] - 0s 876us/step - loss: 0.2469 - accuracy: 0.9037\n",
      "Epoch 164/350\n",
      "111/111 [==============================] - 0s 867us/step - loss: 0.2454 - accuracy: 0.9010\n",
      "Epoch 165/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.2404 - accuracy: 0.9057\n",
      "Epoch 166/350\n",
      "111/111 [==============================] - 0s 859us/step - loss: 0.2462 - accuracy: 0.9042\n",
      "Epoch 167/350\n",
      "111/111 [==============================] - 0s 843us/step - loss: 0.2425 - accuracy: 0.9073\n",
      "Epoch 168/350\n",
      "111/111 [==============================] - 0s 890us/step - loss: 0.2437 - accuracy: 0.9003\n",
      "Epoch 169/350\n",
      "111/111 [==============================] - 0s 867us/step - loss: 0.2397 - accuracy: 0.9057\n",
      "Epoch 170/350\n",
      "111/111 [==============================] - 0s 878us/step - loss: 0.2423 - accuracy: 0.9035\n",
      "Epoch 171/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.2400 - accuracy: 0.9048\n",
      "Epoch 172/350\n",
      "111/111 [==============================] - 0s 963us/step - loss: 0.2399 - accuracy: 0.9057\n",
      "Epoch 173/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.2444 - accuracy: 0.9051\n",
      "Epoch 174/350\n",
      "111/111 [==============================] - 0s 857us/step - loss: 0.2351 - accuracy: 0.9044\n",
      "Epoch 175/350\n",
      "111/111 [==============================] - 0s 881us/step - loss: 0.2382 - accuracy: 0.9085\n",
      "Epoch 176/350\n",
      "111/111 [==============================] - 0s 866us/step - loss: 0.2335 - accuracy: 0.9082\n",
      "Epoch 177/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.2412 - accuracy: 0.9085\n",
      "Epoch 178/350\n",
      "111/111 [==============================] - 0s 832us/step - loss: 0.2342 - accuracy: 0.9096\n",
      "Epoch 179/350\n",
      "111/111 [==============================] - 0s 966us/step - loss: 0.2353 - accuracy: 0.9069\n",
      "Epoch 180/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.2345 - accuracy: 0.9057\n",
      "Epoch 181/350\n",
      "111/111 [==============================] - 0s 917us/step - loss: 0.2419 - accuracy: 0.9026\n",
      "Epoch 182/350\n",
      "111/111 [==============================] - 0s 911us/step - loss: 0.2339 - accuracy: 0.9112\n",
      "Epoch 183/350\n",
      "111/111 [==============================] - 0s 788us/step - loss: 0.2345 - accuracy: 0.9069\n",
      "Epoch 184/350\n",
      "111/111 [==============================] - 0s 895us/step - loss: 0.2340 - accuracy: 0.9087\n",
      "Epoch 185/350\n",
      "111/111 [==============================] - 0s 844us/step - loss: 0.2342 - accuracy: 0.9085\n",
      "Epoch 186/350\n",
      "111/111 [==============================] - 0s 920us/step - loss: 0.2361 - accuracy: 0.9085\n",
      "Epoch 187/350\n",
      "111/111 [==============================] - 0s 895us/step - loss: 0.2316 - accuracy: 0.9127\n",
      "Epoch 188/350\n",
      "111/111 [==============================] - 0s 783us/step - loss: 0.2292 - accuracy: 0.9125\n",
      "Epoch 189/350\n",
      "111/111 [==============================] - 0s 886us/step - loss: 0.2358 - accuracy: 0.9064\n",
      "Epoch 190/350\n",
      "111/111 [==============================] - 0s 848us/step - loss: 0.2284 - accuracy: 0.9105\n",
      "Epoch 191/350\n",
      "111/111 [==============================] - 0s 873us/step - loss: 0.2257 - accuracy: 0.9139\n",
      "Epoch 192/350\n",
      "111/111 [==============================] - 0s 893us/step - loss: 0.2263 - accuracy: 0.9112\n",
      "Epoch 193/350\n",
      "111/111 [==============================] - 0s 865us/step - loss: 0.2355 - accuracy: 0.9048\n",
      "Epoch 194/350\n",
      "111/111 [==============================] - 0s 967us/step - loss: 0.2343 - accuracy: 0.9067\n",
      "Epoch 195/350\n",
      "111/111 [==============================] - 0s 859us/step - loss: 0.2280 - accuracy: 0.9076\n",
      "Epoch 196/350\n",
      "111/111 [==============================] - 0s 844us/step - loss: 0.2278 - accuracy: 0.9094\n",
      "Epoch 197/350\n",
      "111/111 [==============================] - 0s 928us/step - loss: 0.2299 - accuracy: 0.9157\n",
      "Epoch 198/350\n",
      "111/111 [==============================] - 0s 850us/step - loss: 0.2341 - accuracy: 0.9103\n",
      "Epoch 199/350\n",
      "111/111 [==============================] - 0s 904us/step - loss: 0.2339 - accuracy: 0.9089\n",
      "Epoch 200/350\n",
      "111/111 [==============================] - 0s 913us/step - loss: 0.2229 - accuracy: 0.9130\n",
      "Epoch 201/350\n",
      "111/111 [==============================] - 0s 851us/step - loss: 0.2221 - accuracy: 0.9125\n",
      "Epoch 202/350\n",
      "111/111 [==============================] - 0s 920us/step - loss: 0.2296 - accuracy: 0.9087\n",
      "Epoch 203/350\n",
      "111/111 [==============================] - 0s 921us/step - loss: 0.2260 - accuracy: 0.9136\n",
      "Epoch 204/350\n",
      "111/111 [==============================] - 0s 863us/step - loss: 0.2222 - accuracy: 0.9139\n",
      "Epoch 205/350\n",
      "111/111 [==============================] - 0s 874us/step - loss: 0.2278 - accuracy: 0.9094\n",
      "Epoch 206/350\n",
      "111/111 [==============================] - 0s 928us/step - loss: 0.2192 - accuracy: 0.9150\n",
      "Epoch 207/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.2220 - accuracy: 0.9136\n",
      "Epoch 208/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9161\n",
      "Epoch 209/350\n",
      "111/111 [==============================] - 0s 930us/step - loss: 0.2227 - accuracy: 0.9121\n",
      "Epoch 210/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.2172 - accuracy: 0.9143\n",
      "Epoch 211/350\n",
      "111/111 [==============================] - 0s 910us/step - loss: 0.2226 - accuracy: 0.9152\n",
      "Epoch 212/350\n",
      "111/111 [==============================] - 0s 892us/step - loss: 0.2205 - accuracy: 0.9163\n",
      "Epoch 213/350\n",
      "111/111 [==============================] - 0s 850us/step - loss: 0.2220 - accuracy: 0.9141\n",
      "Epoch 214/350\n",
      "111/111 [==============================] - 0s 849us/step - loss: 0.2228 - accuracy: 0.9130\n",
      "Epoch 215/350\n",
      "111/111 [==============================] - 0s 897us/step - loss: 0.2282 - accuracy: 0.9145\n",
      "Epoch 216/350\n",
      "111/111 [==============================] - 0s 887us/step - loss: 0.2183 - accuracy: 0.9132\n",
      "Epoch 217/350\n",
      "111/111 [==============================] - 0s 936us/step - loss: 0.2177 - accuracy: 0.9136\n",
      "Epoch 218/350\n",
      "111/111 [==============================] - 0s 843us/step - loss: 0.2229 - accuracy: 0.9143\n",
      "Epoch 219/350\n",
      "111/111 [==============================] - 0s 933us/step - loss: 0.2165 - accuracy: 0.9179\n",
      "Epoch 220/350\n",
      "111/111 [==============================] - 0s 947us/step - loss: 0.2141 - accuracy: 0.9157\n",
      "Epoch 221/350\n",
      "111/111 [==============================] - 0s 897us/step - loss: 0.2150 - accuracy: 0.9175\n",
      "Epoch 222/350\n",
      "111/111 [==============================] - 0s 874us/step - loss: 0.2157 - accuracy: 0.9161\n",
      "Epoch 223/350\n",
      "111/111 [==============================] - 0s 867us/step - loss: 0.2167 - accuracy: 0.9163\n",
      "Epoch 224/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.2182 - accuracy: 0.9127\n",
      "Epoch 225/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.2142 - accuracy: 0.9163\n",
      "Epoch 226/350\n",
      "111/111 [==============================] - 0s 852us/step - loss: 0.2144 - accuracy: 0.9170\n",
      "Epoch 227/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.2111 - accuracy: 0.9177\n",
      "Epoch 228/350\n",
      "111/111 [==============================] - 0s 889us/step - loss: 0.2140 - accuracy: 0.9150\n",
      "Epoch 229/350\n",
      "111/111 [==============================] - 0s 843us/step - loss: 0.2125 - accuracy: 0.9177\n",
      "Epoch 230/350\n",
      "111/111 [==============================] - 0s 837us/step - loss: 0.2126 - accuracy: 0.9182\n",
      "Epoch 231/350\n",
      "111/111 [==============================] - 0s 834us/step - loss: 0.2113 - accuracy: 0.9179\n",
      "Epoch 232/350\n",
      "111/111 [==============================] - 0s 850us/step - loss: 0.2207 - accuracy: 0.9141\n",
      "Epoch 233/350\n",
      "111/111 [==============================] - 0s 957us/step - loss: 0.2119 - accuracy: 0.9206\n",
      "Epoch 234/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.2071 - accuracy: 0.9177\n",
      "Epoch 235/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 846us/step - loss: 0.2109 - accuracy: 0.9163\n",
      "Epoch 236/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.2159 - accuracy: 0.9143\n",
      "Epoch 237/350\n",
      "111/111 [==============================] - 0s 886us/step - loss: 0.2135 - accuracy: 0.9159\n",
      "Epoch 238/350\n",
      "111/111 [==============================] - 0s 769us/step - loss: 0.2098 - accuracy: 0.9175\n",
      "Epoch 239/350\n",
      "111/111 [==============================] - 0s 962us/step - loss: 0.2152 - accuracy: 0.9177\n",
      "Epoch 240/350\n",
      "111/111 [==============================] - 0s 948us/step - loss: 0.2095 - accuracy: 0.9224\n",
      "Epoch 241/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.2074 - accuracy: 0.9213\n",
      "Epoch 242/350\n",
      "111/111 [==============================] - 0s 838us/step - loss: 0.2051 - accuracy: 0.9206\n",
      "Epoch 243/350\n",
      "111/111 [==============================] - 0s 815us/step - loss: 0.2100 - accuracy: 0.9159\n",
      "Epoch 244/350\n",
      "111/111 [==============================] - 0s 896us/step - loss: 0.2054 - accuracy: 0.9206\n",
      "Epoch 245/350\n",
      "111/111 [==============================] - 0s 838us/step - loss: 0.2055 - accuracy: 0.9193\n",
      "Epoch 246/350\n",
      "111/111 [==============================] - 0s 851us/step - loss: 0.2063 - accuracy: 0.9193\n",
      "Epoch 247/350\n",
      "111/111 [==============================] - 0s 813us/step - loss: 0.2080 - accuracy: 0.9175\n",
      "Epoch 248/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.2050 - accuracy: 0.9200\n",
      "Epoch 249/350\n",
      "111/111 [==============================] - 0s 863us/step - loss: 0.2028 - accuracy: 0.9218\n",
      "Epoch 250/350\n",
      "111/111 [==============================] - 0s 835us/step - loss: 0.2016 - accuracy: 0.9245\n",
      "Epoch 251/350\n",
      "111/111 [==============================] - 0s 819us/step - loss: 0.2073 - accuracy: 0.9218\n",
      "Epoch 252/350\n",
      "111/111 [==============================] - 0s 863us/step - loss: 0.2064 - accuracy: 0.9204\n",
      "Epoch 253/350\n",
      "111/111 [==============================] - 0s 930us/step - loss: 0.2075 - accuracy: 0.9166\n",
      "Epoch 254/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.2014 - accuracy: 0.9202\n",
      "Epoch 255/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.1998 - accuracy: 0.9222\n",
      "Epoch 256/350\n",
      "111/111 [==============================] - 0s 927us/step - loss: 0.2021 - accuracy: 0.9233\n",
      "Epoch 257/350\n",
      "111/111 [==============================] - 0s 788us/step - loss: 0.2060 - accuracy: 0.9175\n",
      "Epoch 258/350\n",
      "111/111 [==============================] - 0s 846us/step - loss: 0.1997 - accuracy: 0.9256\n",
      "Epoch 259/350\n",
      "111/111 [==============================] - 0s 809us/step - loss: 0.2054 - accuracy: 0.9193\n",
      "Epoch 260/350\n",
      "111/111 [==============================] - 0s 825us/step - loss: 0.1994 - accuracy: 0.9238\n",
      "Epoch 261/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.2017 - accuracy: 0.9224\n",
      "Epoch 262/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.1972 - accuracy: 0.9238\n",
      "Epoch 263/350\n",
      "111/111 [==============================] - 0s 806us/step - loss: 0.1985 - accuracy: 0.9218\n",
      "Epoch 264/350\n",
      "111/111 [==============================] - 0s 826us/step - loss: 0.1988 - accuracy: 0.9211\n",
      "Epoch 265/350\n",
      "111/111 [==============================] - 0s 890us/step - loss: 0.1974 - accuracy: 0.9249\n",
      "Epoch 266/350\n",
      "111/111 [==============================] - 0s 838us/step - loss: 0.1968 - accuracy: 0.9238\n",
      "Epoch 267/350\n",
      "111/111 [==============================] - 0s 834us/step - loss: 0.2065 - accuracy: 0.9220\n",
      "Epoch 268/350\n",
      "111/111 [==============================] - 0s 885us/step - loss: 0.2011 - accuracy: 0.9227\n",
      "Epoch 269/350\n",
      "111/111 [==============================] - 0s 754us/step - loss: 0.2012 - accuracy: 0.9218\n",
      "Epoch 270/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.1965 - accuracy: 0.9233\n",
      "Epoch 271/350\n",
      "111/111 [==============================] - 0s 820us/step - loss: 0.1988 - accuracy: 0.9251\n",
      "Epoch 272/350\n",
      "111/111 [==============================] - 0s 906us/step - loss: 0.1948 - accuracy: 0.9274\n",
      "Epoch 273/350\n",
      "111/111 [==============================] - 0s 887us/step - loss: 0.1923 - accuracy: 0.9260\n",
      "Epoch 274/350\n",
      "111/111 [==============================] - 0s 839us/step - loss: 0.1948 - accuracy: 0.9213\n",
      "Epoch 275/350\n",
      "111/111 [==============================] - 0s 815us/step - loss: 0.1951 - accuracy: 0.9263\n",
      "Epoch 276/350\n",
      "111/111 [==============================] - 0s 876us/step - loss: 0.1989 - accuracy: 0.9227\n",
      "Epoch 277/350\n",
      "111/111 [==============================] - 0s 888us/step - loss: 0.1924 - accuracy: 0.9240\n",
      "Epoch 278/350\n",
      "111/111 [==============================] - 0s 851us/step - loss: 0.1964 - accuracy: 0.9227\n",
      "Epoch 279/350\n",
      "111/111 [==============================] - 0s 848us/step - loss: 0.1966 - accuracy: 0.9215\n",
      "Epoch 280/350\n",
      "111/111 [==============================] - 0s 842us/step - loss: 0.1987 - accuracy: 0.9202\n",
      "Epoch 281/350\n",
      "111/111 [==============================] - 0s 883us/step - loss: 0.1901 - accuracy: 0.9276\n",
      "Epoch 282/350\n",
      "111/111 [==============================] - 0s 807us/step - loss: 0.1917 - accuracy: 0.9290\n",
      "Epoch 283/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.1946 - accuracy: 0.9227\n",
      "Epoch 284/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.1901 - accuracy: 0.9272\n",
      "Epoch 285/350\n",
      "111/111 [==============================] - 0s 827us/step - loss: 0.1874 - accuracy: 0.9287\n",
      "Epoch 286/350\n",
      "111/111 [==============================] - 0s 875us/step - loss: 0.1900 - accuracy: 0.9245\n",
      "Epoch 287/350\n",
      "111/111 [==============================] - 0s 884us/step - loss: 0.1921 - accuracy: 0.9281\n",
      "Epoch 288/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.1838 - accuracy: 0.9267\n",
      "Epoch 289/350\n",
      "111/111 [==============================] - 0s 908us/step - loss: 0.1898 - accuracy: 0.9281\n",
      "Epoch 290/350\n",
      "111/111 [==============================] - 0s 864us/step - loss: 0.1942 - accuracy: 0.9242\n",
      "Epoch 291/350\n",
      "111/111 [==============================] - 0s 906us/step - loss: 0.1938 - accuracy: 0.9200\n",
      "Epoch 292/350\n",
      "111/111 [==============================] - 0s 875us/step - loss: 0.1924 - accuracy: 0.9254\n",
      "Epoch 293/350\n",
      "111/111 [==============================] - 0s 908us/step - loss: 0.1889 - accuracy: 0.9240\n",
      "Epoch 294/350\n",
      "111/111 [==============================] - 0s 865us/step - loss: 0.1926 - accuracy: 0.9222\n",
      "Epoch 295/350\n",
      "111/111 [==============================] - 0s 909us/step - loss: 0.1852 - accuracy: 0.9267\n",
      "Epoch 296/350\n",
      "111/111 [==============================] - 0s 935us/step - loss: 0.1869 - accuracy: 0.9260\n",
      "Epoch 297/350\n",
      "111/111 [==============================] - 0s 851us/step - loss: 0.1904 - accuracy: 0.9251\n",
      "Epoch 298/350\n",
      "111/111 [==============================] - 0s 859us/step - loss: 0.1865 - accuracy: 0.9292\n",
      "Epoch 299/350\n",
      "111/111 [==============================] - 0s 894us/step - loss: 0.1893 - accuracy: 0.9240\n",
      "Epoch 300/350\n",
      "111/111 [==============================] - 0s 835us/step - loss: 0.1881 - accuracy: 0.9269\n",
      "Epoch 301/350\n",
      "111/111 [==============================] - 0s 897us/step - loss: 0.1844 - accuracy: 0.9310\n",
      "Epoch 302/350\n",
      "111/111 [==============================] - 0s 905us/step - loss: 0.1838 - accuracy: 0.9283\n",
      "Epoch 303/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.1838 - accuracy: 0.9297\n",
      "Epoch 304/350\n",
      "111/111 [==============================] - 0s 873us/step - loss: 0.1868 - accuracy: 0.9254\n",
      "Epoch 305/350\n",
      "111/111 [==============================] - 0s 843us/step - loss: 0.1858 - accuracy: 0.9258\n",
      "Epoch 306/350\n",
      "111/111 [==============================] - 0s 853us/step - loss: 0.1843 - accuracy: 0.9269\n",
      "Epoch 307/350\n",
      "111/111 [==============================] - 0s 930us/step - loss: 0.1803 - accuracy: 0.9285\n",
      "Epoch 308/350\n",
      "111/111 [==============================] - 0s 920us/step - loss: 0.1896 - accuracy: 0.9263\n",
      "Epoch 309/350\n",
      "111/111 [==============================] - 0s 951us/step - loss: 0.1863 - accuracy: 0.9272\n",
      "Epoch 310/350\n",
      "111/111 [==============================] - 0s 971us/step - loss: 0.1811 - accuracy: 0.9274\n",
      "Epoch 311/350\n",
      "111/111 [==============================] - 0s 860us/step - loss: 0.1796 - accuracy: 0.9342\n",
      "Epoch 312/350\n",
      "111/111 [==============================] - 0s 830us/step - loss: 0.1891 - accuracy: 0.9274\n",
      "Epoch 313/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 823us/step - loss: 0.1828 - accuracy: 0.9265\n",
      "Epoch 314/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9290\n",
      "Epoch 315/350\n",
      "111/111 [==============================] - 0s 889us/step - loss: 0.1777 - accuracy: 0.9290\n",
      "Epoch 316/350\n",
      "111/111 [==============================] - 0s 884us/step - loss: 0.1779 - accuracy: 0.9317\n",
      "Epoch 317/350\n",
      "111/111 [==============================] - 0s 893us/step - loss: 0.1883 - accuracy: 0.9267\n",
      "Epoch 318/350\n",
      "111/111 [==============================] - 0s 898us/step - loss: 0.1752 - accuracy: 0.9283\n",
      "Epoch 319/350\n",
      "111/111 [==============================] - 0s 954us/step - loss: 0.1810 - accuracy: 0.9299\n",
      "Epoch 320/350\n",
      "111/111 [==============================] - 0s 896us/step - loss: 0.1778 - accuracy: 0.9312\n",
      "Epoch 321/350\n",
      "111/111 [==============================] - 0s 899us/step - loss: 0.1824 - accuracy: 0.9247\n",
      "Epoch 322/350\n",
      "111/111 [==============================] - 0s 995us/step - loss: 0.1789 - accuracy: 0.9306\n",
      "Epoch 323/350\n",
      "111/111 [==============================] - 0s 967us/step - loss: 0.1786 - accuracy: 0.9324\n",
      "Epoch 324/350\n",
      "111/111 [==============================] - 0s 869us/step - loss: 0.1777 - accuracy: 0.9328\n",
      "Epoch 325/350\n",
      "111/111 [==============================] - 0s 834us/step - loss: 0.1763 - accuracy: 0.9306\n",
      "Epoch 326/350\n",
      "111/111 [==============================] - 0s 896us/step - loss: 0.1752 - accuracy: 0.9330\n",
      "Epoch 327/350\n",
      "111/111 [==============================] - 0s 841us/step - loss: 0.1772 - accuracy: 0.9337\n",
      "Epoch 328/350\n",
      "111/111 [==============================] - 0s 926us/step - loss: 0.1850 - accuracy: 0.9281\n",
      "Epoch 329/350\n",
      "111/111 [==============================] - 0s 902us/step - loss: 0.1812 - accuracy: 0.9269\n",
      "Epoch 330/350\n",
      "111/111 [==============================] - 0s 834us/step - loss: 0.1732 - accuracy: 0.9333\n",
      "Epoch 331/350\n",
      "111/111 [==============================] - 0s 942us/step - loss: 0.1749 - accuracy: 0.9310\n",
      "Epoch 332/350\n",
      "111/111 [==============================] - 0s 873us/step - loss: 0.1729 - accuracy: 0.9344\n",
      "Epoch 333/350\n",
      "111/111 [==============================] - 0s 856us/step - loss: 0.1785 - accuracy: 0.9303\n",
      "Epoch 334/350\n",
      "111/111 [==============================] - 0s 938us/step - loss: 0.1707 - accuracy: 0.9292\n",
      "Epoch 335/350\n",
      "111/111 [==============================] - 0s 849us/step - loss: 0.1713 - accuracy: 0.9326\n",
      "Epoch 336/350\n",
      "111/111 [==============================] - 0s 862us/step - loss: 0.1766 - accuracy: 0.9317\n",
      "Epoch 337/350\n",
      "111/111 [==============================] - 0s 858us/step - loss: 0.1728 - accuracy: 0.9299\n",
      "Epoch 338/350\n",
      "111/111 [==============================] - 0s 903us/step - loss: 0.1801 - accuracy: 0.9303\n",
      "Epoch 339/350\n",
      "111/111 [==============================] - 0s 800us/step - loss: 0.1714 - accuracy: 0.9328\n",
      "Epoch 340/350\n",
      "111/111 [==============================] - 0s 979us/step - loss: 0.1736 - accuracy: 0.9324\n",
      "Epoch 341/350\n",
      "111/111 [==============================] - 0s 878us/step - loss: 0.1751 - accuracy: 0.9319\n",
      "Epoch 342/350\n",
      "111/111 [==============================] - 0s 789us/step - loss: 0.1741 - accuracy: 0.9326\n",
      "Epoch 343/350\n",
      "111/111 [==============================] - 0s 876us/step - loss: 0.1705 - accuracy: 0.9337\n",
      "Epoch 344/350\n",
      "111/111 [==============================] - 0s 877us/step - loss: 0.1698 - accuracy: 0.9344\n",
      "Epoch 345/350\n",
      "111/111 [==============================] - 0s 872us/step - loss: 0.1708 - accuracy: 0.9328\n",
      "Epoch 346/350\n",
      "111/111 [==============================] - 0s 854us/step - loss: 0.1696 - accuracy: 0.9357\n",
      "Epoch 347/350\n",
      "111/111 [==============================] - 0s 814us/step - loss: 0.1678 - accuracy: 0.9378\n",
      "Epoch 348/350\n",
      "111/111 [==============================] - 0s 891us/step - loss: 0.1673 - accuracy: 0.9335\n",
      "Epoch 349/350\n",
      "111/111 [==============================] - 0s 848us/step - loss: 0.1678 - accuracy: 0.9342\n",
      "Epoch 350/350\n",
      "111/111 [==============================] - 0s 890us/step - loss: 0.1698 - accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "# Set grid search parameters\n",
    "param_grid = dict(epochs=[300, 350, 400], batch_size=[40,50,60])\n",
    "grid = GridSearchCV(estimator=modelo, param_grid=param_grid, n_jobs=-1, cv=10)\n",
    "grid_result = grid.fit(X_trn_scaled, y_trn_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8bef77ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 40, 'epochs': 350}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "32a0cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579611778259277"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "800f49ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8974553091185433, 0.937767744064331)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(grid_result.best_estimator_.model.history.history['accuracy']), max(grid_result.best_estimator_.model.history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a34de8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.857961 using {'batch_size': 40, 'epochs': 350}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "    #print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "20a99e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 701us/step - loss: 0.2741 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27409273386001587, 0.8999999761581421]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_.model.evaluate(scaler.transform(X_test), enc.transform(y_test.reshape(-1,1)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1af3bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([56.24861321, 64.36048489, 60.57246938, 42.5437993 , 52.98535657,\n",
       "        60.41846099, 35.27427649, 40.8893455 , 67.4784328 ]),\n",
       " 'std_fit_time': array([13.14371865, 15.42406399,  3.70558941,  0.59993382, 15.29722387,\n",
       "        18.54836781,  6.66976495,  2.03972572, 19.48062645]),\n",
       " 'mean_score_time': array([0.39819913, 0.23898735, 0.3438087 , 0.40139656, 0.32555408,\n",
       "        0.27125497, 0.34570761, 0.44886274, 0.26565518]),\n",
       " 'std_score_time': array([0.13411262, 0.07360778, 0.12108703, 0.11008736, 0.07049034,\n",
       "        0.10319552, 0.09303471, 0.11655359, 0.09310975]),\n",
       " 'param_batch_size': masked_array(data=[40, 40, 40, 50, 50, 50, 60, 60, 60],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[300, 350, 400, 300, 350, 400, 300, 350, 400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 40, 'epochs': 300},\n",
       "  {'batch_size': 40, 'epochs': 350},\n",
       "  {'batch_size': 40, 'epochs': 400},\n",
       "  {'batch_size': 50, 'epochs': 300},\n",
       "  {'batch_size': 50, 'epochs': 350},\n",
       "  {'batch_size': 50, 'epochs': 400},\n",
       "  {'batch_size': 60, 'epochs': 300},\n",
       "  {'batch_size': 60, 'epochs': 350},\n",
       "  {'batch_size': 60, 'epochs': 400}],\n",
       " 'split0_test_score': array([0.8207441 , 0.77903044, 0.82638109, 0.77339345, 0.74859077,\n",
       "        0.75197291, 0.82638109, 0.84892899, 0.85569334]),\n",
       " 'split1_test_score': array([0.82976323, 0.82187146, 0.82750845, 0.83765501, 0.82750845,\n",
       "        0.8207441 , 0.81736189, 0.83990979, 0.82299888]),\n",
       " 'split2_test_score': array([0.79932356, 0.76888388, 0.81059754, 0.76775646, 0.7666291 ,\n",
       "        0.81059754, 0.78015786, 0.80608791, 0.78015786]),\n",
       " 'split3_test_score': array([0.86809468, 0.89289743, 0.88951522, 0.87034947, 0.88049603,\n",
       "        0.88275087, 0.87260431, 0.86133033, 0.86696732]),\n",
       " 'split4_test_score': array([0.75986469, 0.80834275, 0.77226609, 0.79368657, 0.77113867,\n",
       "        0.7981962 , 0.72040588, 0.79706877, 0.77339345]),\n",
       " 'mean_test_score': array([0.81555805, 0.81420519, 0.82525368, 0.80856819, 0.7988726 ,\n",
       "        0.81285232, 0.80338221, 0.83066516, 0.81984217]),\n",
       " 'std_test_score': array([0.03564853, 0.04376504, 0.03783752, 0.03946465, 0.0486199 ,\n",
       "        0.04212903, 0.05087341, 0.02486822, 0.03807461]),\n",
       " 'rank_test_score': array([4, 5, 2, 7, 9, 6, 8, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46f088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
