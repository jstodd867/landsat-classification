{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ae22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982c652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat.trn sat.tst\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697588ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.loadtxt('data/sat.trn'), np.loadtxt('data/sat.tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259bcf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92., 115., 120., ..., 113.,  87.,   3.],\n",
       "       [ 84., 102., 106., ..., 104.,  79.,   3.],\n",
       "       [ 84., 102., 102., ..., 104.,  79.,   3.],\n",
       "       ...,\n",
       "       [ 68.,  75., 108., ..., 104.,  85.,   4.],\n",
       "       [ 71.,  87., 108., ..., 104.,  85.,   4.],\n",
       "       [ 71.,  91., 100., ..., 100.,  81.,   4.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf6ad4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80., 102., 102., ..., 113.,  87.,   3.],\n",
       "       [ 76., 102., 102., ..., 104.,  83.,   3.],\n",
       "       [ 80.,  98., 106., ...,  96.,  75.,   4.],\n",
       "       ...,\n",
       "       [ 56.,  68.,  91., ...,  92.,  74.,   5.],\n",
       "       [ 56.,  68.,  87., ...,  92.,  70.,   5.],\n",
       "       [ 60.,  71.,  91., ..., 108.,  92.,   5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2abcdab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 37) (2000, 37)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ceb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels into different vectors\n",
    "y_train, y_test = train[:,-1], test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8d8a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3., ..., 4., 4., 4.]), array([3., 3., 4., ..., 5., 5., 5.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242a72e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265363cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 3x3x4 pixel neighborhood samples into train and test feature samples\n",
    "X_train, X_test = train[:,:-1], test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dab80ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92., 115., 120., ..., 107., 113.,  87.],\n",
       "       [ 84., 102., 106., ...,  99., 104.,  79.],\n",
       "       [ 84., 102., 102., ...,  99., 104.,  79.],\n",
       "       ...,\n",
       "       [ 68.,  75., 108., ..., 100., 104.,  85.],\n",
       "       [ 71.,  87., 108., ...,  91., 104.,  85.],\n",
       "       [ 71.,  91., 100., ...,  91., 100.,  81.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d700c8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f6b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine class count for each label in training set\n",
    "def class_counts(y):\n",
    "    labels, labels_inverse, label_counts = np.unique(y, return_inverse=True, return_counts=True)\n",
    "    return labels, labels_inverse, label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27caae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, labels_inverse, label_counts = class_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d62daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-c8d4ec1e2b31>:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(['','1 - red soil', '2 - cotton crop', '3 - grey soil', '4 - damp grey soil', '5 - soil w/veg.', '6 - mixture', '7 - very damp grey soil'], rotation=45);\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.bar(labels, label_counts)\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "ax.set_title('Occurrences of Each Class in Training Set')\n",
    "ax.set_xticklabels(['','1 - red soil', '2 - cotton crop', '3 - grey soil', '4 - damp grey soil', '5 - soil w/veg.', '6 - mixture', '7 - very damp grey soil'], rotation=45);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs/train_class_count.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f746fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot mean spectral signature for each class\n",
    "means = []\n",
    "for idx,label in enumerate(labels):\n",
    "    means.append(np.mean(X_train[labels_inverse==idx,16:20], axis=0))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e64d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 62.8255597 ,  95.29384328, 108.12313433,  88.60074627]),\n",
       " array([ 48.83924843,  39.91440501, 113.88935282, 118.31106472]),\n",
       " array([ 87.47866805, 105.49843913, 110.5962539 ,  87.45681582]),\n",
       " array([77.40963855, 90.94457831, 95.61445783, 75.35421687]),\n",
       " array([59.5893617 , 62.26595745, 83.02340426, 69.95319149]),\n",
       " array([69.01252408, 77.42196532, 81.59248555, 64.12524085])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37b21861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity of mean vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "478ae517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Histogram of Pixel Neighborhood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "360561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Average intensity for neighborhood across each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbf9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of mean vectors for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d817dc",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ba997a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 115., 120.,  94.,  84., 102., 106.,  79.,  84., 102., 102.,\n",
       "        83., 101., 126., 133., 103.,  92., 112., 118.,  85.,  84., 103.,\n",
       "       104.,  81., 102., 126., 134., 104.,  88., 121., 128., 100.,  84.,\n",
       "       107., 113.,  87.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ac1e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 112., 118.,  85.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,16:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe89690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92., 115., 120.,  94.,  84., 102., 106.,  79.,  84., 102., 102.,\n",
       "        83., 101., 126., 133., 103.,  92., 112., 118.,  85.,  84., 103.,\n",
       "       104.,  81., 102., 126., 134., 104.,  88., 121., 128., 100.,  84.,\n",
       "       107., 113.,  87.,   3.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540df76",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b088f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each sample by closest distance to mean vector\n",
    "mean_dict = {label: means[i] for i,label in enumerate(labels)} # Create dictionary of mean spectral vector per class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "564bca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: array([ 62.8255597 ,  95.29384328, 108.12313433,  88.60074627]),\n",
       " 2.0: array([ 48.83924843,  39.91440501, 113.88935282, 118.31106472]),\n",
       " 3.0: array([ 87.47866805, 105.49843913, 110.5962539 ,  87.45681582]),\n",
       " 4.0: array([77.40963855, 90.94457831, 95.61445783, 75.35421687]),\n",
       " 5.0: array([59.5893617 , 62.26595745, 83.02340426, 69.95319149]),\n",
       " 7.0: array([69.01252408, 77.42196532, 81.59248555, 64.12524085])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae83991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a,b):\n",
    "    return np.sqrt(sum((a-b)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12517a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.776905414321906"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(train[-1,16:20], mean_dict[3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e19dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance_classifier(X, mean_dict,labels):\n",
    "    predicts = []\n",
    "    label_dict = {num:label for num,label in zip(np.arange(len(labels)), labels)}\n",
    "    for sample in X[:,16:20]:\n",
    "        mean_index = np.argmin([euclidean_distance(sample, mean_vector) for mean_vector in mean_dict.values()])\n",
    "        predicts.append(label_dict[mean_index])\n",
    "    return np.array(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4cb86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = min_distance_classifier(X_train, mean_dict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5289f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 4., 4., 4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26daf042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7641488162344983"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_predict == y_train)/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daea487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = min_distance_classifier(X_test, mean_dict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f538a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_test_predict == y_test)/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd695a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 5., 7., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edc6ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2027a7",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da4af1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b67daa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "enc.fit(y_train.reshape(-1,1))\n",
    "\n",
    "y_trn_1hot = enc.transform(y_train.reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75fff3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_trn_scaled = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7293d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "hidden_units = 100\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1532863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, n_classes, opt='Adam', hidden_units=100, drop_out=0, activ='softsign'):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_samples, n_feats = X.shape\n",
    "\n",
    "    model = Sequential() # sequence of layers\n",
    "\n",
    "    hidden_layer = Dense(units=hidden_units,\n",
    "                    input_dim=n_feats,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation=activ)\n",
    "\n",
    "    hidden_layer_2 = Dense(units=hidden_units,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation=activ)\n",
    "\n",
    "    outputlayer = Dense(units=n_classes,\n",
    "                    input_dim=hidden_units,\n",
    "                    kernel_initializer='uniform',\n",
    "                    activation='softmax')\n",
    "\n",
    "    model.add(hidden_layer)\n",
    "    model.add(Dropout(drop_out))\n",
    "    model.add(hidden_layer_2)\n",
    "    model.add(Dropout(drop_out))\n",
    "    model.add(hidden_layer_2)\n",
    "    model.add(Dropout(drop_out))\n",
    "    model.add(outputlayer)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "702aee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_trn_scaled, n_classes, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73bcdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "89/89 [==============================] - 0s 945us/step - loss: 1.4415 - accuracy: 0.3448\n",
      "Epoch 2/350\n",
      "89/89 [==============================] - 0s 978us/step - loss: 0.9531 - accuracy: 0.5831\n",
      "Epoch 3/350\n",
      "89/89 [==============================] - 0s 960us/step - loss: 0.8357 - accuracy: 0.6974\n",
      "Epoch 4/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.7921\n",
      "Epoch 5/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8201\n",
      "Epoch 6/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8372\n",
      "Epoch 7/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8397\n",
      "Epoch 8/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8489\n",
      "Epoch 9/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8474\n",
      "Epoch 10/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8537\n",
      "Epoch 11/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8521\n",
      "Epoch 12/350\n",
      "89/89 [==============================] - 0s 989us/step - loss: 0.3693 - accuracy: 0.8591\n",
      "Epoch 13/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8570\n",
      "Epoch 14/350\n",
      "89/89 [==============================] - 0s 973us/step - loss: 0.3657 - accuracy: 0.8555\n",
      "Epoch 15/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8566\n",
      "Epoch 16/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8589\n",
      "Epoch 17/350\n",
      "89/89 [==============================] - 0s 975us/step - loss: 0.3628 - accuracy: 0.8591\n",
      "Epoch 18/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.3457 - accuracy: 0.8627\n",
      "Epoch 19/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8643\n",
      "Epoch 20/350\n",
      "89/89 [==============================] - 0s 995us/step - loss: 0.3427 - accuracy: 0.8665\n",
      "Epoch 21/350\n",
      "89/89 [==============================] - 0s 959us/step - loss: 0.3450 - accuracy: 0.8634\n",
      "Epoch 22/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8703\n",
      "Epoch 23/350\n",
      "89/89 [==============================] - 0s 913us/step - loss: 0.3403 - accuracy: 0.8638\n",
      "Epoch 24/350\n",
      "89/89 [==============================] - 0s 894us/step - loss: 0.3358 - accuracy: 0.8656\n",
      "Epoch 25/350\n",
      "89/89 [==============================] - 0s 996us/step - loss: 0.3390 - accuracy: 0.8679\n",
      "Epoch 26/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8631\n",
      "Epoch 27/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8670\n",
      "Epoch 28/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.3289 - accuracy: 0.8690\n",
      "Epoch 29/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8679\n",
      "Epoch 30/350\n",
      "89/89 [==============================] - 0s 995us/step - loss: 0.3283 - accuracy: 0.8706\n",
      "Epoch 31/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8699\n",
      "Epoch 32/350\n",
      "89/89 [==============================] - 0s 981us/step - loss: 0.3235 - accuracy: 0.8715\n",
      "Epoch 33/350\n",
      "89/89 [==============================] - 0s 985us/step - loss: 0.3240 - accuracy: 0.8735\n",
      "Epoch 34/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8737\n",
      "Epoch 35/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.3172 - accuracy: 0.8755\n",
      "Epoch 36/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8685\n",
      "Epoch 37/350\n",
      "89/89 [==============================] - 0s 975us/step - loss: 0.3197 - accuracy: 0.8690\n",
      "Epoch 38/350\n",
      "89/89 [==============================] - 0s 907us/step - loss: 0.3230 - accuracy: 0.8751\n",
      "Epoch 39/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8703\n",
      "Epoch 40/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8771\n",
      "Epoch 41/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8728\n",
      "Epoch 42/350\n",
      "89/89 [==============================] - 0s 964us/step - loss: 0.3203 - accuracy: 0.8742\n",
      "Epoch 43/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8746\n",
      "Epoch 44/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.3178 - accuracy: 0.8746\n",
      "Epoch 45/350\n",
      "89/89 [==============================] - 0s 992us/step - loss: 0.3132 - accuracy: 0.8758\n",
      "Epoch 46/350\n",
      "89/89 [==============================] - 0s 873us/step - loss: 0.3134 - accuracy: 0.8791\n",
      "Epoch 47/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.3171 - accuracy: 0.8751\n",
      "Epoch 48/350\n",
      "89/89 [==============================] - 0s 989us/step - loss: 0.3143 - accuracy: 0.8760\n",
      "Epoch 49/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.3116 - accuracy: 0.8776\n",
      "Epoch 50/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8735\n",
      "Epoch 51/350\n",
      "89/89 [==============================] - 0s 844us/step - loss: 0.3177 - accuracy: 0.8767\n",
      "Epoch 52/350\n",
      "89/89 [==============================] - 0s 935us/step - loss: 0.3088 - accuracy: 0.8758\n",
      "Epoch 53/350\n",
      "89/89 [==============================] - 0s 981us/step - loss: 0.3072 - accuracy: 0.8798\n",
      "Epoch 54/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.3053 - accuracy: 0.8778\n",
      "Epoch 55/350\n",
      "89/89 [==============================] - 0s 977us/step - loss: 0.3105 - accuracy: 0.8767\n",
      "Epoch 56/350\n",
      "89/89 [==============================] - 0s 962us/step - loss: 0.3021 - accuracy: 0.8764\n",
      "Epoch 57/350\n",
      "89/89 [==============================] - 0s 991us/step - loss: 0.3046 - accuracy: 0.8787\n",
      "Epoch 58/350\n",
      "89/89 [==============================] - 0s 905us/step - loss: 0.3089 - accuracy: 0.8807\n",
      "Epoch 59/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.3061 - accuracy: 0.8796\n",
      "Epoch 60/350\n",
      "89/89 [==============================] - 0s 913us/step - loss: 0.3084 - accuracy: 0.8800\n",
      "Epoch 61/350\n",
      "89/89 [==============================] - 0s 977us/step - loss: 0.3033 - accuracy: 0.8814\n",
      "Epoch 62/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.8782\n",
      "Epoch 63/350\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.3000 - accuracy: 0.8798\n",
      "Epoch 64/350\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.3017 - accuracy: 0.8818\n",
      "Epoch 65/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2996 - accuracy: 0.8789\n",
      "Epoch 66/350\n",
      "89/89 [==============================] - 0s 852us/step - loss: 0.3075 - accuracy: 0.8800\n",
      "Epoch 67/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.3050 - accuracy: 0.8771\n",
      "Epoch 68/350\n",
      "89/89 [==============================] - 0s 966us/step - loss: 0.3057 - accuracy: 0.8794\n",
      "Epoch 69/350\n",
      "89/89 [==============================] - 0s 992us/step - loss: 0.3065 - accuracy: 0.8771\n",
      "Epoch 70/350\n",
      "89/89 [==============================] - 0s 952us/step - loss: 0.2980 - accuracy: 0.8809\n",
      "Epoch 71/350\n",
      "89/89 [==============================] - 0s 979us/step - loss: 0.2972 - accuracy: 0.8816\n",
      "Epoch 72/350\n",
      "89/89 [==============================] - 0s 900us/step - loss: 0.2973 - accuracy: 0.8818\n",
      "Epoch 73/350\n",
      "89/89 [==============================] - 0s 973us/step - loss: 0.2955 - accuracy: 0.8816\n",
      "Epoch 74/350\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.2924 - accuracy: 0.8852\n",
      "Epoch 75/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.2954 - accuracy: 0.8837\n",
      "Epoch 76/350\n",
      "89/89 [==============================] - 0s 949us/step - loss: 0.2948 - accuracy: 0.8821\n",
      "Epoch 77/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.2955 - accuracy: 0.8818\n",
      "Epoch 78/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8814\n",
      "Epoch 79/350\n",
      "89/89 [==============================] - 0s 975us/step - loss: 0.2931 - accuracy: 0.8859\n",
      "Epoch 80/350\n",
      "89/89 [==============================] - 0s 997us/step - loss: 0.2924 - accuracy: 0.8848\n",
      "Epoch 81/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 905us/step - loss: 0.2924 - accuracy: 0.8823\n",
      "Epoch 82/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2886 - accuracy: 0.8816\n",
      "Epoch 83/350\n",
      "89/89 [==============================] - 0s 923us/step - loss: 0.2882 - accuracy: 0.8864\n",
      "Epoch 84/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.2877 - accuracy: 0.8875\n",
      "Epoch 85/350\n",
      "89/89 [==============================] - 0s 767us/step - loss: 0.2895 - accuracy: 0.8868\n",
      "Epoch 86/350\n",
      "89/89 [==============================] - 0s 945us/step - loss: 0.2877 - accuracy: 0.8850\n",
      "Epoch 87/350\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.2927 - accuracy: 0.8825\n",
      "Epoch 88/350\n",
      "89/89 [==============================] - 0s 907us/step - loss: 0.2870 - accuracy: 0.8843\n",
      "Epoch 89/350\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.2943 - accuracy: 0.8825\n",
      "Epoch 90/350\n",
      "89/89 [==============================] - 0s 983us/step - loss: 0.2899 - accuracy: 0.8873\n",
      "Epoch 91/350\n",
      "89/89 [==============================] - 0s 940us/step - loss: 0.2869 - accuracy: 0.8850\n",
      "Epoch 92/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.2852 - accuracy: 0.8891\n",
      "Epoch 93/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.2829 - accuracy: 0.8846\n",
      "Epoch 94/350\n",
      "89/89 [==============================] - 0s 938us/step - loss: 0.2833 - accuracy: 0.8915\n",
      "Epoch 95/350\n",
      "89/89 [==============================] - 0s 957us/step - loss: 0.2843 - accuracy: 0.8893\n",
      "Epoch 96/350\n",
      "89/89 [==============================] - 0s 934us/step - loss: 0.2851 - accuracy: 0.8870\n",
      "Epoch 97/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8868\n",
      "Epoch 98/350\n",
      "89/89 [==============================] - 0s 996us/step - loss: 0.2812 - accuracy: 0.8879\n",
      "Epoch 99/350\n",
      "89/89 [==============================] - 0s 937us/step - loss: 0.2805 - accuracy: 0.8891\n",
      "Epoch 100/350\n",
      "89/89 [==============================] - 0s 940us/step - loss: 0.2779 - accuracy: 0.8893\n",
      "Epoch 101/350\n",
      "89/89 [==============================] - 0s 978us/step - loss: 0.2799 - accuracy: 0.8904\n",
      "Epoch 102/350\n",
      "89/89 [==============================] - 0s 915us/step - loss: 0.2819 - accuracy: 0.8886\n",
      "Epoch 103/350\n",
      "89/89 [==============================] - 0s 968us/step - loss: 0.2809 - accuracy: 0.8879\n",
      "Epoch 104/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2768 - accuracy: 0.8893\n",
      "Epoch 105/350\n",
      "89/89 [==============================] - 0s 892us/step - loss: 0.2763 - accuracy: 0.8902\n",
      "Epoch 106/350\n",
      "89/89 [==============================] - 0s 951us/step - loss: 0.2779 - accuracy: 0.8927\n",
      "Epoch 107/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.2752 - accuracy: 0.8947\n",
      "Epoch 108/350\n",
      "89/89 [==============================] - 0s 934us/step - loss: 0.2763 - accuracy: 0.8938\n",
      "Epoch 109/350\n",
      "89/89 [==============================] - 0s 862us/step - loss: 0.2758 - accuracy: 0.8931\n",
      "Epoch 110/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.2738 - accuracy: 0.8938\n",
      "Epoch 111/350\n",
      "89/89 [==============================] - 0s 919us/step - loss: 0.2750 - accuracy: 0.8911\n",
      "Epoch 112/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.2751 - accuracy: 0.8918\n",
      "Epoch 113/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8900\n",
      "Epoch 114/350\n",
      "89/89 [==============================] - 0s 949us/step - loss: 0.2706 - accuracy: 0.8940\n",
      "Epoch 115/350\n",
      "89/89 [==============================] - 0s 952us/step - loss: 0.2768 - accuracy: 0.8909\n",
      "Epoch 116/350\n",
      "89/89 [==============================] - 0s 995us/step - loss: 0.2795 - accuracy: 0.8900\n",
      "Epoch 117/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2716 - accuracy: 0.8931\n",
      "Epoch 118/350\n",
      "89/89 [==============================] - 0s 953us/step - loss: 0.2733 - accuracy: 0.8938\n",
      "Epoch 119/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8920\n",
      "Epoch 120/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2691 - accuracy: 0.8949\n",
      "Epoch 121/350\n",
      "89/89 [==============================] - 0s 947us/step - loss: 0.2682 - accuracy: 0.8931\n",
      "Epoch 122/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.2696 - accuracy: 0.8949\n",
      "Epoch 123/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.8911\n",
      "Epoch 124/350\n",
      "89/89 [==============================] - 0s 973us/step - loss: 0.2670 - accuracy: 0.8938\n",
      "Epoch 125/350\n",
      "89/89 [==============================] - 0s 901us/step - loss: 0.2629 - accuracy: 0.8947\n",
      "Epoch 126/350\n",
      "89/89 [==============================] - 0s 963us/step - loss: 0.2645 - accuracy: 0.8956\n",
      "Epoch 127/350\n",
      "89/89 [==============================] - 0s 988us/step - loss: 0.2686 - accuracy: 0.8931\n",
      "Epoch 128/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.8940\n",
      "Epoch 129/350\n",
      "89/89 [==============================] - 0s 995us/step - loss: 0.2585 - accuracy: 0.8970\n",
      "Epoch 130/350\n",
      "89/89 [==============================] - 0s 992us/step - loss: 0.2682 - accuracy: 0.8904\n",
      "Epoch 131/350\n",
      "89/89 [==============================] - 0s 970us/step - loss: 0.2632 - accuracy: 0.8979\n",
      "Epoch 132/350\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.2632 - accuracy: 0.8945\n",
      "Epoch 133/350\n",
      "89/89 [==============================] - 0s 967us/step - loss: 0.2623 - accuracy: 0.8976\n",
      "Epoch 134/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2688 - accuracy: 0.8918\n",
      "Epoch 135/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8938\n",
      "Epoch 136/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.2619 - accuracy: 0.8956\n",
      "Epoch 137/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.8988\n",
      "Epoch 138/350\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.2555 - accuracy: 0.8974\n",
      "Epoch 139/350\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.2553 - accuracy: 0.8985\n",
      "Epoch 140/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.2542 - accuracy: 0.9019\n",
      "Epoch 141/350\n",
      "89/89 [==============================] - 0s 910us/step - loss: 0.2634 - accuracy: 0.8940\n",
      "Epoch 142/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.2574 - accuracy: 0.8956\n",
      "Epoch 143/350\n",
      "89/89 [==============================] - 0s 998us/step - loss: 0.2549 - accuracy: 0.8954\n",
      "Epoch 144/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.8997\n",
      "Epoch 145/350\n",
      "89/89 [==============================] - 0s 962us/step - loss: 0.2559 - accuracy: 0.8974\n",
      "Epoch 146/350\n",
      "89/89 [==============================] - 0s 994us/step - loss: 0.2545 - accuracy: 0.8979\n",
      "Epoch 147/350\n",
      "89/89 [==============================] - 0s 854us/step - loss: 0.2557 - accuracy: 0.8997\n",
      "Epoch 148/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.2595 - accuracy: 0.8979\n",
      "Epoch 149/350\n",
      "89/89 [==============================] - 0s 965us/step - loss: 0.2567 - accuracy: 0.8972\n",
      "Epoch 150/350\n",
      "89/89 [==============================] - 0s 974us/step - loss: 0.2490 - accuracy: 0.9006\n",
      "Epoch 151/350\n",
      "89/89 [==============================] - 0s 997us/step - loss: 0.2508 - accuracy: 0.8994\n",
      "Epoch 152/350\n",
      "89/89 [==============================] - 0s 914us/step - loss: 0.2466 - accuracy: 0.9039\n",
      "Epoch 153/350\n",
      "89/89 [==============================] - 0s 884us/step - loss: 0.2504 - accuracy: 0.9006\n",
      "Epoch 154/350\n",
      "89/89 [==============================] - 0s 921us/step - loss: 0.2476 - accuracy: 0.8999\n",
      "Epoch 155/350\n",
      "89/89 [==============================] - 0s 912us/step - loss: 0.2470 - accuracy: 0.9037\n",
      "Epoch 156/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9021\n",
      "Epoch 157/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.2512 - accuracy: 0.9003\n",
      "Epoch 158/350\n",
      "89/89 [==============================] - 0s 935us/step - loss: 0.2429 - accuracy: 0.9015\n",
      "Epoch 159/350\n",
      "89/89 [==============================] - 0s 938us/step - loss: 0.2433 - accuracy: 0.8994\n",
      "Epoch 160/350\n",
      "89/89 [==============================] - 0s 962us/step - loss: 0.2426 - accuracy: 0.9033\n",
      "Epoch 161/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 974us/step - loss: 0.2483 - accuracy: 0.9012\n",
      "Epoch 162/350\n",
      "89/89 [==============================] - 0s 904us/step - loss: 0.2492 - accuracy: 0.9008\n",
      "Epoch 163/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.2512 - accuracy: 0.9019\n",
      "Epoch 164/350\n",
      "89/89 [==============================] - 0s 951us/step - loss: 0.2442 - accuracy: 0.9028\n",
      "Epoch 165/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.2414 - accuracy: 0.9012\n",
      "Epoch 166/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.2413 - accuracy: 0.9062\n",
      "Epoch 167/350\n",
      "89/89 [==============================] - 0s 899us/step - loss: 0.2449 - accuracy: 0.9021\n",
      "Epoch 168/350\n",
      "89/89 [==============================] - 0s 972us/step - loss: 0.2399 - accuracy: 0.9019\n",
      "Epoch 169/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.2417 - accuracy: 0.9015\n",
      "Epoch 170/350\n",
      "89/89 [==============================] - 0s 976us/step - loss: 0.2358 - accuracy: 0.9035\n",
      "Epoch 171/350\n",
      "89/89 [==============================] - 0s 898us/step - loss: 0.2402 - accuracy: 0.8997\n",
      "Epoch 172/350\n",
      "89/89 [==============================] - 0s 980us/step - loss: 0.2385 - accuracy: 0.9062\n",
      "Epoch 173/350\n",
      "89/89 [==============================] - 0s 864us/step - loss: 0.2384 - accuracy: 0.9062\n",
      "Epoch 174/350\n",
      "89/89 [==============================] - 0s 940us/step - loss: 0.2358 - accuracy: 0.9078\n",
      "Epoch 175/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.2351 - accuracy: 0.9051\n",
      "Epoch 176/350\n",
      "89/89 [==============================] - 0s 905us/step - loss: 0.2407 - accuracy: 0.9046\n",
      "Epoch 177/350\n",
      "89/89 [==============================] - 0s 885us/step - loss: 0.2393 - accuracy: 0.9003\n",
      "Epoch 178/350\n",
      "89/89 [==============================] - 0s 929us/step - loss: 0.2336 - accuracy: 0.9048\n",
      "Epoch 179/350\n",
      "89/89 [==============================] - 0s 925us/step - loss: 0.2348 - accuracy: 0.9064\n",
      "Epoch 180/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2355 - accuracy: 0.9057\n",
      "Epoch 181/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2328 - accuracy: 0.9098\n",
      "Epoch 182/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2331 - accuracy: 0.9069\n",
      "Epoch 183/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2330 - accuracy: 0.9057\n",
      "Epoch 184/350\n",
      "89/89 [==============================] - 0s 951us/step - loss: 0.2390 - accuracy: 0.9042\n",
      "Epoch 185/350\n",
      "89/89 [==============================] - 0s 971us/step - loss: 0.2323 - accuracy: 0.9064\n",
      "Epoch 186/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9082\n",
      "Epoch 187/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.2281 - accuracy: 0.9100\n",
      "Epoch 188/350\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.2259 - accuracy: 0.9094\n",
      "Epoch 189/350\n",
      "89/89 [==============================] - 0s 927us/step - loss: 0.2330 - accuracy: 0.9085\n",
      "Epoch 190/350\n",
      "89/89 [==============================] - 0s 936us/step - loss: 0.2301 - accuracy: 0.9094\n",
      "Epoch 191/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.2273 - accuracy: 0.9094\n",
      "Epoch 192/350\n",
      "89/89 [==============================] - 0s 951us/step - loss: 0.2257 - accuracy: 0.9085\n",
      "Epoch 193/350\n",
      "89/89 [==============================] - 0s 857us/step - loss: 0.2304 - accuracy: 0.9080\n",
      "Epoch 194/350\n",
      "89/89 [==============================] - 0s 858us/step - loss: 0.2243 - accuracy: 0.9098\n",
      "Epoch 195/350\n",
      "89/89 [==============================] - 0s 945us/step - loss: 0.2285 - accuracy: 0.9080\n",
      "Epoch 196/350\n",
      "89/89 [==============================] - 0s 993us/step - loss: 0.2288 - accuracy: 0.9100\n",
      "Epoch 197/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9044\n",
      "Epoch 198/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.2318 - accuracy: 0.9076\n",
      "Epoch 199/350\n",
      "89/89 [==============================] - 0s 934us/step - loss: 0.2259 - accuracy: 0.9089\n",
      "Epoch 200/350\n",
      "89/89 [==============================] - 0s 998us/step - loss: 0.2260 - accuracy: 0.9078\n",
      "Epoch 201/350\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.2190 - accuracy: 0.9123\n",
      "Epoch 202/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9150\n",
      "Epoch 203/350\n",
      "89/89 [==============================] - 0s 960us/step - loss: 0.2205 - accuracy: 0.9121\n",
      "Epoch 204/350\n",
      "89/89 [==============================] - 0s 922us/step - loss: 0.2162 - accuracy: 0.9139\n",
      "Epoch 205/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2221 - accuracy: 0.9100\n",
      "Epoch 206/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9154\n",
      "Epoch 207/350\n",
      "89/89 [==============================] - 0s 975us/step - loss: 0.2201 - accuracy: 0.9134\n",
      "Epoch 208/350\n",
      "89/89 [==============================] - 0s 899us/step - loss: 0.2160 - accuracy: 0.9141\n",
      "Epoch 209/350\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.2193 - accuracy: 0.9163\n",
      "Epoch 210/350\n",
      "89/89 [==============================] - 0s 997us/step - loss: 0.2145 - accuracy: 0.9166\n",
      "Epoch 211/350\n",
      "89/89 [==============================] - 0s 977us/step - loss: 0.2224 - accuracy: 0.9118\n",
      "Epoch 212/350\n",
      "89/89 [==============================] - 0s 927us/step - loss: 0.2217 - accuracy: 0.9100\n",
      "Epoch 213/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.2154 - accuracy: 0.9175\n",
      "Epoch 214/350\n",
      "89/89 [==============================] - 0s 964us/step - loss: 0.2192 - accuracy: 0.9096\n",
      "Epoch 215/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.2152 - accuracy: 0.9127\n",
      "Epoch 216/350\n",
      "89/89 [==============================] - 0s 993us/step - loss: 0.2105 - accuracy: 0.9179\n",
      "Epoch 217/350\n",
      "89/89 [==============================] - 0s 982us/step - loss: 0.2116 - accuracy: 0.9175\n",
      "Epoch 218/350\n",
      "89/89 [==============================] - 0s 836us/step - loss: 0.2133 - accuracy: 0.9188\n",
      "Epoch 219/350\n",
      "89/89 [==============================] - 0s 990us/step - loss: 0.2086 - accuracy: 0.9154\n",
      "Epoch 220/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.2233 - accuracy: 0.9148\n",
      "Epoch 221/350\n",
      "89/89 [==============================] - 0s 996us/step - loss: 0.2123 - accuracy: 0.9145\n",
      "Epoch 222/350\n",
      "89/89 [==============================] - 0s 957us/step - loss: 0.2094 - accuracy: 0.9202\n",
      "Epoch 223/350\n",
      "89/89 [==============================] - 0s 918us/step - loss: 0.2117 - accuracy: 0.9157\n",
      "Epoch 224/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9157\n",
      "Epoch 225/350\n",
      "89/89 [==============================] - 0s 943us/step - loss: 0.2091 - accuracy: 0.9175\n",
      "Epoch 226/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.2056 - accuracy: 0.9179\n",
      "Epoch 227/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9177\n",
      "Epoch 228/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9186\n",
      "Epoch 229/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9179\n",
      "Epoch 230/350\n",
      "89/89 [==============================] - 0s 928us/step - loss: 0.2085 - accuracy: 0.9145\n",
      "Epoch 231/350\n",
      "89/89 [==============================] - 0s 963us/step - loss: 0.2069 - accuracy: 0.9191\n",
      "Epoch 232/350\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.2014 - accuracy: 0.9227\n",
      "Epoch 233/350\n",
      "89/89 [==============================] - 0s 982us/step - loss: 0.2134 - accuracy: 0.9145\n",
      "Epoch 234/350\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.2040 - accuracy: 0.9197\n",
      "Epoch 235/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.2006 - accuracy: 0.9215\n",
      "Epoch 236/350\n",
      "89/89 [==============================] - 0s 960us/step - loss: 0.2102 - accuracy: 0.9175\n",
      "Epoch 237/350\n",
      "89/89 [==============================] - 0s 957us/step - loss: 0.2071 - accuracy: 0.9175\n",
      "Epoch 238/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9211\n",
      "Epoch 239/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9211\n",
      "Epoch 240/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 844us/step - loss: 0.1998 - accuracy: 0.9215\n",
      "Epoch 241/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9200\n",
      "Epoch 242/350\n",
      "89/89 [==============================] - 0s 985us/step - loss: 0.2021 - accuracy: 0.9166\n",
      "Epoch 243/350\n",
      "89/89 [==============================] - 0s 926us/step - loss: 0.2035 - accuracy: 0.9197\n",
      "Epoch 244/350\n",
      "89/89 [==============================] - 0s 924us/step - loss: 0.1989 - accuracy: 0.9224\n",
      "Epoch 245/350\n",
      "89/89 [==============================] - 0s 894us/step - loss: 0.2015 - accuracy: 0.9227\n",
      "Epoch 246/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.2011 - accuracy: 0.9202\n",
      "Epoch 247/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.1981 - accuracy: 0.9220\n",
      "Epoch 248/350\n",
      "89/89 [==============================] - 0s 976us/step - loss: 0.1999 - accuracy: 0.9188\n",
      "Epoch 249/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9227\n",
      "Epoch 250/350\n",
      "89/89 [==============================] - 0s 834us/step - loss: 0.1962 - accuracy: 0.9222\n",
      "Epoch 251/350\n",
      "89/89 [==============================] - 0s 939us/step - loss: 0.2029 - accuracy: 0.9206\n",
      "Epoch 252/350\n",
      "89/89 [==============================] - 0s 965us/step - loss: 0.1966 - accuracy: 0.9249\n",
      "Epoch 253/350\n",
      "89/89 [==============================] - 0s 981us/step - loss: 0.2004 - accuracy: 0.9251\n",
      "Epoch 254/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9184\n",
      "Epoch 255/350\n",
      "89/89 [==============================] - 0s 935us/step - loss: 0.1941 - accuracy: 0.9256\n",
      "Epoch 256/350\n",
      "89/89 [==============================] - 0s 997us/step - loss: 0.1983 - accuracy: 0.9238\n",
      "Epoch 257/350\n",
      "89/89 [==============================] - 0s 981us/step - loss: 0.1931 - accuracy: 0.9274\n",
      "Epoch 258/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.1940 - accuracy: 0.9245\n",
      "Epoch 259/350\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.1936 - accuracy: 0.9233\n",
      "Epoch 260/350\n",
      "89/89 [==============================] - 0s 927us/step - loss: 0.1955 - accuracy: 0.9238\n",
      "Epoch 261/350\n",
      "89/89 [==============================] - 0s 984us/step - loss: 0.1922 - accuracy: 0.9276\n",
      "Epoch 262/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9218\n",
      "Epoch 263/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.1906 - accuracy: 0.9272\n",
      "Epoch 264/350\n",
      "89/89 [==============================] - 0s 952us/step - loss: 0.1919 - accuracy: 0.9256\n",
      "Epoch 265/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.1902 - accuracy: 0.9281\n",
      "Epoch 266/350\n",
      "89/89 [==============================] - 0s 905us/step - loss: 0.1920 - accuracy: 0.9267\n",
      "Epoch 267/350\n",
      "89/89 [==============================] - 0s 959us/step - loss: 0.1886 - accuracy: 0.9263\n",
      "Epoch 268/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9238\n",
      "Epoch 269/350\n",
      "89/89 [==============================] - 0s 949us/step - loss: 0.1882 - accuracy: 0.9274\n",
      "Epoch 270/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.1956 - accuracy: 0.9233\n",
      "Epoch 271/350\n",
      "89/89 [==============================] - 0s 981us/step - loss: 0.1936 - accuracy: 0.9224\n",
      "Epoch 272/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9200\n",
      "Epoch 273/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.1864 - accuracy: 0.9276\n",
      "Epoch 274/350\n",
      "89/89 [==============================] - 0s 962us/step - loss: 0.1880 - accuracy: 0.9265\n",
      "Epoch 275/350\n",
      "89/89 [==============================] - 0s 959us/step - loss: 0.1894 - accuracy: 0.9247\n",
      "Epoch 276/350\n",
      "89/89 [==============================] - 0s 859us/step - loss: 0.1867 - accuracy: 0.9267\n",
      "Epoch 277/350\n",
      "89/89 [==============================] - 0s 881us/step - loss: 0.1928 - accuracy: 0.9227\n",
      "Epoch 278/350\n",
      "89/89 [==============================] - 0s 917us/step - loss: 0.1874 - accuracy: 0.9245\n",
      "Epoch 279/350\n",
      "89/89 [==============================] - 0s 937us/step - loss: 0.1856 - accuracy: 0.9278\n",
      "Epoch 280/350\n",
      "89/89 [==============================] - 0s 945us/step - loss: 0.1845 - accuracy: 0.9267\n",
      "Epoch 281/350\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.1922 - accuracy: 0.9249\n",
      "Epoch 282/350\n",
      "89/89 [==============================] - 0s 937us/step - loss: 0.1853 - accuracy: 0.9274\n",
      "Epoch 283/350\n",
      "89/89 [==============================] - 0s 854us/step - loss: 0.1828 - accuracy: 0.9265\n",
      "Epoch 284/350\n",
      "89/89 [==============================] - 0s 912us/step - loss: 0.1852 - accuracy: 0.9292\n",
      "Epoch 285/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.1867 - accuracy: 0.9283\n",
      "Epoch 286/350\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.1897 - accuracy: 0.9245\n",
      "Epoch 287/350\n",
      "89/89 [==============================] - 0s 944us/step - loss: 0.1830 - accuracy: 0.9294\n",
      "Epoch 288/350\n",
      "89/89 [==============================] - 0s 959us/step - loss: 0.1846 - accuracy: 0.9267\n",
      "Epoch 289/350\n",
      "89/89 [==============================] - 0s 989us/step - loss: 0.1816 - accuracy: 0.9308\n",
      "Epoch 290/350\n",
      "89/89 [==============================] - 0s 986us/step - loss: 0.1782 - accuracy: 0.9315\n",
      "Epoch 291/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.1831 - accuracy: 0.9299\n",
      "Epoch 292/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.1788 - accuracy: 0.9278\n",
      "Epoch 293/350\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.1875 - accuracy: 0.9238\n",
      "Epoch 294/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.1794 - accuracy: 0.9272\n",
      "Epoch 295/350\n",
      "89/89 [==============================] - 0s 961us/step - loss: 0.1800 - accuracy: 0.9260\n",
      "Epoch 296/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.1831 - accuracy: 0.9287\n",
      "Epoch 297/350\n",
      "89/89 [==============================] - 0s 926us/step - loss: 0.1786 - accuracy: 0.9254\n",
      "Epoch 298/350\n",
      "89/89 [==============================] - 0s 959us/step - loss: 0.1764 - accuracy: 0.9285\n",
      "Epoch 299/350\n",
      "89/89 [==============================] - 0s 917us/step - loss: 0.1922 - accuracy: 0.9236\n",
      "Epoch 300/350\n",
      "89/89 [==============================] - 0s 969us/step - loss: 0.1774 - accuracy: 0.9312\n",
      "Epoch 301/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9308\n",
      "Epoch 302/350\n",
      "89/89 [==============================] - 0s 945us/step - loss: 0.1800 - accuracy: 0.9299\n",
      "Epoch 303/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.1799 - accuracy: 0.9281\n",
      "Epoch 304/350\n",
      "89/89 [==============================] - 0s 898us/step - loss: 0.1758 - accuracy: 0.9312\n",
      "Epoch 305/350\n",
      "89/89 [==============================] - 0s 947us/step - loss: 0.1746 - accuracy: 0.9321\n",
      "Epoch 306/350\n",
      "89/89 [==============================] - 0s 965us/step - loss: 0.1769 - accuracy: 0.9281\n",
      "Epoch 307/350\n",
      "89/89 [==============================] - 0s 949us/step - loss: 0.1796 - accuracy: 0.9287\n",
      "Epoch 308/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9303\n",
      "Epoch 309/350\n",
      "89/89 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9294\n",
      "Epoch 310/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.1686 - accuracy: 0.9353\n",
      "Epoch 311/350\n",
      "89/89 [==============================] - 0s 998us/step - loss: 0.1792 - accuracy: 0.9292\n",
      "Epoch 312/350\n",
      "89/89 [==============================] - 0s 974us/step - loss: 0.1747 - accuracy: 0.9303\n",
      "Epoch 313/350\n",
      "89/89 [==============================] - 0s 915us/step - loss: 0.1738 - accuracy: 0.9308\n",
      "Epoch 314/350\n",
      "89/89 [==============================] - 0s 940us/step - loss: 0.1792 - accuracy: 0.9290\n",
      "Epoch 315/350\n",
      "89/89 [==============================] - 0s 862us/step - loss: 0.1735 - accuracy: 0.9292\n",
      "Epoch 316/350\n",
      "89/89 [==============================] - 0s 876us/step - loss: 0.1722 - accuracy: 0.9297\n",
      "Epoch 317/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.1788 - accuracy: 0.9312\n",
      "Epoch 318/350\n",
      "89/89 [==============================] - 0s 995us/step - loss: 0.1773 - accuracy: 0.9299\n",
      "Epoch 319/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 836us/step - loss: 0.1743 - accuracy: 0.9317\n",
      "Epoch 320/350\n",
      "89/89 [==============================] - 0s 929us/step - loss: 0.1727 - accuracy: 0.9324\n",
      "Epoch 321/350\n",
      "89/89 [==============================] - 0s 958us/step - loss: 0.1729 - accuracy: 0.9299\n",
      "Epoch 322/350\n",
      "89/89 [==============================] - 0s 938us/step - loss: 0.1821 - accuracy: 0.9290\n",
      "Epoch 323/350\n",
      "89/89 [==============================] - 0s 924us/step - loss: 0.1790 - accuracy: 0.9299\n",
      "Epoch 324/350\n",
      "89/89 [==============================] - 0s 948us/step - loss: 0.1710 - accuracy: 0.9317\n",
      "Epoch 325/350\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.1670 - accuracy: 0.9366\n",
      "Epoch 326/350\n",
      "89/89 [==============================] - 0s 845us/step - loss: 0.1716 - accuracy: 0.9326\n",
      "Epoch 327/350\n",
      "89/89 [==============================] - 0s 950us/step - loss: 0.1705 - accuracy: 0.9330\n",
      "Epoch 328/350\n",
      "89/89 [==============================] - 0s 867us/step - loss: 0.1693 - accuracy: 0.9353\n",
      "Epoch 329/350\n",
      "89/89 [==============================] - 0s 935us/step - loss: 0.1672 - accuracy: 0.9360\n",
      "Epoch 330/350\n",
      "89/89 [==============================] - 0s 957us/step - loss: 0.1686 - accuracy: 0.9324\n",
      "Epoch 331/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.1733 - accuracy: 0.9294\n",
      "Epoch 332/350\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.1726 - accuracy: 0.9310\n",
      "Epoch 333/350\n",
      "89/89 [==============================] - 0s 960us/step - loss: 0.1697 - accuracy: 0.9319\n",
      "Epoch 334/350\n",
      "89/89 [==============================] - 0s 954us/step - loss: 0.1655 - accuracy: 0.9371\n",
      "Epoch 335/350\n",
      "89/89 [==============================] - 0s 930us/step - loss: 0.1716 - accuracy: 0.9337\n",
      "Epoch 336/350\n",
      "89/89 [==============================] - 0s 920us/step - loss: 0.1738 - accuracy: 0.9287\n",
      "Epoch 337/350\n",
      "89/89 [==============================] - 0s 935us/step - loss: 0.1679 - accuracy: 0.9339\n",
      "Epoch 338/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.1662 - accuracy: 0.9351\n",
      "Epoch 339/350\n",
      "89/89 [==============================] - 0s 946us/step - loss: 0.1694 - accuracy: 0.9315\n",
      "Epoch 340/350\n",
      "89/89 [==============================] - 0s 874us/step - loss: 0.1692 - accuracy: 0.9348\n",
      "Epoch 341/350\n",
      "89/89 [==============================] - 0s 865us/step - loss: 0.1692 - accuracy: 0.9317\n",
      "Epoch 342/350\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.1637 - accuracy: 0.9337\n",
      "Epoch 343/350\n",
      "89/89 [==============================] - 0s 952us/step - loss: 0.1704 - accuracy: 0.9339\n",
      "Epoch 344/350\n",
      "89/89 [==============================] - 0s 949us/step - loss: 0.1663 - accuracy: 0.9355\n",
      "Epoch 345/350\n",
      "89/89 [==============================] - 0s 993us/step - loss: 0.1649 - accuracy: 0.9389\n",
      "Epoch 346/350\n",
      "89/89 [==============================] - 0s 955us/step - loss: 0.1639 - accuracy: 0.9355\n",
      "Epoch 347/350\n",
      "89/89 [==============================] - 0s 901us/step - loss: 0.1644 - accuracy: 0.9330\n",
      "Epoch 348/350\n",
      "89/89 [==============================] - 0s 898us/step - loss: 0.1645 - accuracy: 0.9326\n",
      "Epoch 349/350\n",
      "89/89 [==============================] - 0s 941us/step - loss: 0.1596 - accuracy: 0.9378\n",
      "Epoch 350/350\n",
      "89/89 [==============================] - 0s 928us/step - loss: 0.1623 - accuracy: 0.9355\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trn_scaled, y_trn_1hot, epochs=350, batch_size=50, verbose=1, validation_split=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e54478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.6951053142547607,\n",
       "  1.3588849306106567,\n",
       "  1.2700804471969604,\n",
       "  1.059291958808899,\n",
       "  0.8675603866577148,\n",
       "  0.7963805198669434,\n",
       "  0.6951545476913452,\n",
       "  0.6210228800773621,\n",
       "  0.5538510084152222,\n",
       "  0.49651074409484863,\n",
       "  0.46549513936042786,\n",
       "  0.4305870532989502,\n",
       "  0.4167126715183258,\n",
       "  0.4001719355583191,\n",
       "  0.3997628092765808,\n",
       "  0.383284330368042,\n",
       "  0.37782421708106995,\n",
       "  0.3907758295536041,\n",
       "  0.3788404166698456,\n",
       "  0.3682679831981659,\n",
       "  0.36314570903778076,\n",
       "  0.3595249056816101,\n",
       "  0.35912224650382996,\n",
       "  0.35271915793418884,\n",
       "  0.3526783883571625,\n",
       "  0.3461886942386627,\n",
       "  0.3477564752101898,\n",
       "  0.3431975543498993,\n",
       "  0.35237157344818115,\n",
       "  0.34340760111808777,\n",
       "  0.33696186542510986,\n",
       "  0.33773529529571533,\n",
       "  0.33733081817626953,\n",
       "  0.3376091420650482,\n",
       "  0.34914812445640564,\n",
       "  0.3354492485523224,\n",
       "  0.3315467834472656,\n",
       "  0.3278590738773346,\n",
       "  0.32779914140701294,\n",
       "  0.3275933563709259,\n",
       "  0.3240963816642761,\n",
       "  0.33801570534706116,\n",
       "  0.3314921259880066,\n",
       "  0.32358086109161377,\n",
       "  0.3241511285305023,\n",
       "  0.32357048988342285,\n",
       "  0.3228992521762848,\n",
       "  0.3244606554508209,\n",
       "  0.3242926001548767,\n",
       "  0.32159098982810974,\n",
       "  0.3274424374103546,\n",
       "  0.321678102016449,\n",
       "  0.3141374886035919,\n",
       "  0.3194977939128876,\n",
       "  0.3171670436859131,\n",
       "  0.3202168941497803,\n",
       "  0.3116260766983032,\n",
       "  0.3172453045845032,\n",
       "  0.3175036311149597,\n",
       "  0.30948182940483093,\n",
       "  0.3138720691204071,\n",
       "  0.31518036127090454,\n",
       "  0.31365954875946045,\n",
       "  0.31210795044898987,\n",
       "  0.3153418004512787,\n",
       "  0.30592384934425354,\n",
       "  0.31447774171829224,\n",
       "  0.30469658970832825,\n",
       "  0.3068779706954956,\n",
       "  0.3076324760913849,\n",
       "  0.3098980784416199,\n",
       "  0.31136494874954224,\n",
       "  0.31059786677360535,\n",
       "  0.30494561791419983,\n",
       "  0.30894050002098083,\n",
       "  0.30378517508506775,\n",
       "  0.302679181098938,\n",
       "  0.3060826361179352,\n",
       "  0.3033273220062256,\n",
       "  0.3018554151058197,\n",
       "  0.3036844730377197,\n",
       "  0.30453670024871826,\n",
       "  0.30040669441223145,\n",
       "  0.30455872416496277,\n",
       "  0.29907235503196716,\n",
       "  0.29575175046920776,\n",
       "  0.29844310879707336,\n",
       "  0.2941349744796753,\n",
       "  0.2993946373462677,\n",
       "  0.2987566590309143,\n",
       "  0.2966713309288025,\n",
       "  0.29439881443977356,\n",
       "  0.2962751090526581,\n",
       "  0.2919139564037323,\n",
       "  0.29177558422088623,\n",
       "  0.2924136519432068,\n",
       "  0.29022136330604553,\n",
       "  0.29358309507369995,\n",
       "  0.2958707809448242,\n",
       "  0.2883419692516327,\n",
       "  0.29105544090270996,\n",
       "  0.2894267141819,\n",
       "  0.29727718234062195,\n",
       "  0.28919416666030884,\n",
       "  0.2883002758026123,\n",
       "  0.2897495627403259,\n",
       "  0.2839174270629883,\n",
       "  0.28881049156188965,\n",
       "  0.2875267267227173,\n",
       "  0.28329750895500183,\n",
       "  0.2867676615715027,\n",
       "  0.2837636172771454,\n",
       "  0.2914678752422333,\n",
       "  0.28125590085983276,\n",
       "  0.28377681970596313,\n",
       "  0.2766677439212799,\n",
       "  0.2838011682033539,\n",
       "  0.2835923731327057,\n",
       "  0.28308984637260437,\n",
       "  0.28104284405708313,\n",
       "  0.28014543652534485,\n",
       "  0.2842751443386078,\n",
       "  0.27805936336517334,\n",
       "  0.2799854278564453,\n",
       "  0.2816464900970459,\n",
       "  0.2807513475418091,\n",
       "  0.2747008502483368,\n",
       "  0.2758796811103821,\n",
       "  0.2772766053676605,\n",
       "  0.2720843255519867,\n",
       "  0.2878514528274536,\n",
       "  0.27218329906463623,\n",
       "  0.2754254937171936,\n",
       "  0.26957210898399353,\n",
       "  0.2757243812084198,\n",
       "  0.2853192687034607,\n",
       "  0.2731560468673706,\n",
       "  0.2688658833503723,\n",
       "  0.26883664727211,\n",
       "  0.27301880717277527,\n",
       "  0.2679421305656433,\n",
       "  0.2688676416873932,\n",
       "  0.2667698562145233,\n",
       "  0.26560261845588684,\n",
       "  0.25890272855758667,\n",
       "  0.264435350894928,\n",
       "  0.2660548985004425,\n",
       "  0.261306494474411,\n",
       "  0.2603518068790436,\n",
       "  0.2641986012458801,\n",
       "  0.2660346031188965,\n",
       "  0.25611403584480286,\n",
       "  0.2578558325767517,\n",
       "  0.2584208846092224,\n",
       "  0.25809597969055176,\n",
       "  0.2543525695800781,\n",
       "  0.2564602494239807,\n",
       "  0.2570112347602844,\n",
       "  0.2564536929130554,\n",
       "  0.2570255398750305,\n",
       "  0.26123690605163574,\n",
       "  0.24832837283611298,\n",
       "  0.25302326679229736,\n",
       "  0.25416281819343567,\n",
       "  0.25301283597946167,\n",
       "  0.2542168200016022,\n",
       "  0.24999187886714935,\n",
       "  0.25162774324417114,\n",
       "  0.25049901008605957,\n",
       "  0.2482381910085678,\n",
       "  0.2519962787628174,\n",
       "  0.2546461224555969,\n",
       "  0.24875301122665405,\n",
       "  0.2487703561782837,\n",
       "  0.24936053156852722,\n",
       "  0.2486133575439453,\n",
       "  0.24812738597393036,\n",
       "  0.2483445256948471,\n",
       "  0.24303381145000458,\n",
       "  0.245028555393219,\n",
       "  0.2471914440393448,\n",
       "  0.2505904734134674,\n",
       "  0.24426107108592987,\n",
       "  0.25251486897468567,\n",
       "  0.2480209767818451,\n",
       "  0.24223530292510986,\n",
       "  0.2421044111251831,\n",
       "  0.24078480899333954,\n",
       "  0.233428955078125,\n",
       "  0.23878857493400574,\n",
       "  0.23400381207466125,\n",
       "  0.23490461707115173,\n",
       "  0.2435619831085205,\n",
       "  0.24178346991539001,\n",
       "  0.23013588786125183,\n",
       "  0.2352961003780365,\n",
       "  0.22725051641464233,\n",
       "  0.2339295744895935,\n",
       "  0.24781198799610138,\n",
       "  0.23316770792007446,\n",
       "  0.23082217574119568,\n",
       "  0.2382137030363083,\n",
       "  0.23268897831439972,\n",
       "  0.2320237010717392,\n",
       "  0.23316290974617004,\n",
       "  0.2264179289340973,\n",
       "  0.22956305742263794,\n",
       "  0.22687047719955444,\n",
       "  0.22491100430488586,\n",
       "  0.2253362089395523,\n",
       "  0.22568736970424652,\n",
       "  0.22870920598506927,\n",
       "  0.22892668843269348,\n",
       "  0.22264541685581207,\n",
       "  0.2228202521800995,\n",
       "  0.22609843313694,\n",
       "  0.22398917376995087,\n",
       "  0.21904590725898743,\n",
       "  0.2236379235982895,\n",
       "  0.22594036161899567,\n",
       "  0.22955051064491272,\n",
       "  0.22508515417575836,\n",
       "  0.21919497847557068,\n",
       "  0.22401590645313263,\n",
       "  0.22293953597545624,\n",
       "  0.2218339443206787,\n",
       "  0.2156447023153305,\n",
       "  0.22089260816574097,\n",
       "  0.21167579293251038,\n",
       "  0.2216772884130478,\n",
       "  0.2196500152349472,\n",
       "  0.2236672043800354,\n",
       "  0.2163228839635849,\n",
       "  0.219618558883667,\n",
       "  0.2121874988079071,\n",
       "  0.21261973679065704,\n",
       "  0.21297353506088257,\n",
       "  0.21222442388534546,\n",
       "  0.2144269198179245,\n",
       "  0.21592611074447632,\n",
       "  0.21091653406620026,\n",
       "  0.20576585829257965,\n",
       "  0.21345357596874237,\n",
       "  0.2120591700077057,\n",
       "  0.2137199193239212,\n",
       "  0.208079993724823,\n",
       "  0.20908354222774506,\n",
       "  0.2122577279806137,\n",
       "  0.20672038197517395,\n",
       "  0.21671542525291443,\n",
       "  0.211089089512825,\n",
       "  0.20962883532047272,\n",
       "  0.2044987678527832,\n",
       "  0.2102198302745819,\n",
       "  0.20989342033863068,\n",
       "  0.20335005223751068,\n",
       "  0.201446533203125,\n",
       "  0.20582585036754608,\n",
       "  0.2088078260421753,\n",
       "  0.20529355108737946,\n",
       "  0.20374810695648193,\n",
       "  0.20672394335269928,\n",
       "  0.2039191573858261,\n",
       "  0.20054227113723755,\n",
       "  0.20738567411899567,\n",
       "  0.20235948264598846,\n",
       "  0.20760294795036316,\n",
       "  0.20613859593868256,\n",
       "  0.20318952202796936,\n",
       "  0.20024465024471283,\n",
       "  0.20597095787525177,\n",
       "  0.20905010402202606,\n",
       "  0.20133492350578308,\n",
       "  0.19597227871418,\n",
       "  0.19601485133171082,\n",
       "  0.20116214454174042,\n",
       "  0.19916915893554688,\n",
       "  0.1947009116411209,\n",
       "  0.2029927521944046,\n",
       "  0.20197266340255737,\n",
       "  0.19751638174057007,\n",
       "  0.19816738367080688,\n",
       "  0.20430566370487213,\n",
       "  0.19771729409694672,\n",
       "  0.19322550296783447,\n",
       "  0.19368109107017517,\n",
       "  0.19489730894565582,\n",
       "  0.193856880068779,\n",
       "  0.2008313536643982,\n",
       "  0.199236199259758,\n",
       "  0.19744917750358582,\n",
       "  0.20229899883270264,\n",
       "  0.1968374401330948,\n",
       "  0.1958150565624237,\n",
       "  0.19579461216926575,\n",
       "  0.18944986164569855,\n",
       "  0.19106565415859222,\n",
       "  0.19205011427402496,\n",
       "  0.1951887458562851,\n",
       "  0.1921030431985855,\n",
       "  0.19043610990047455,\n",
       "  0.18956612050533295,\n",
       "  0.1920786052942276,\n",
       "  0.18902644515037537,\n",
       "  0.19228555262088776,\n",
       "  0.19253018498420715,\n",
       "  0.19289381802082062,\n",
       "  0.1957637518644333,\n",
       "  0.18772700428962708,\n",
       "  0.18710853159427643,\n",
       "  0.19072435796260834,\n",
       "  0.19231654703617096,\n",
       "  0.18241040408611298,\n",
       "  0.18121831119060516,\n",
       "  0.19940482079982758,\n",
       "  0.1884482204914093,\n",
       "  0.18275922536849976,\n",
       "  0.18361563980579376,\n",
       "  0.18845701217651367,\n",
       "  0.1806894987821579,\n",
       "  0.18549014627933502,\n",
       "  0.18726089596748352,\n",
       "  0.1850694864988327,\n",
       "  0.20026633143424988,\n",
       "  0.1839306503534317,\n",
       "  0.17790190875530243,\n",
       "  0.18519772589206696,\n",
       "  0.18767543137073517,\n",
       "  0.19190087914466858,\n",
       "  0.1831350475549698,\n",
       "  0.18270207941532135,\n",
       "  0.18454216420650482,\n",
       "  0.1809219866991043,\n",
       "  0.17875364422798157,\n",
       "  0.18014392256736755,\n",
       "  0.1786901354789734,\n",
       "  0.18357841670513153,\n",
       "  0.18120943009853363,\n",
       "  0.17890891432762146,\n",
       "  0.17681804299354553,\n",
       "  0.1776914745569229,\n",
       "  0.1811731457710266,\n",
       "  0.17947639524936676,\n",
       "  0.17298419773578644,\n",
       "  0.17469696700572968,\n",
       "  0.17834237217903137,\n",
       "  0.17707139253616333,\n",
       "  0.1774446666240692,\n",
       "  0.17620953917503357,\n",
       "  0.17590223252773285],\n",
       " 'accuracy': [0.25231117010116577,\n",
       "  0.3499436378479004,\n",
       "  0.42660653591156006,\n",
       "  0.5758737325668335,\n",
       "  0.6340473294258118,\n",
       "  0.6994363069534302,\n",
       "  0.7747463583946228,\n",
       "  0.7839909791946411,\n",
       "  0.8101465702056885,\n",
       "  0.8198421597480774,\n",
       "  0.8268319964408875,\n",
       "  0.8347237706184387,\n",
       "  0.8435174822807312,\n",
       "  0.8473505973815918,\n",
       "  0.8466742038726807,\n",
       "  0.850281834602356,\n",
       "  0.8500563502311707,\n",
       "  0.8487035036087036,\n",
       "  0.8507328033447266,\n",
       "  0.8552423715591431,\n",
       "  0.8547914028167725,\n",
       "  0.8579481244087219,\n",
       "  0.8581736087799072,\n",
       "  0.8581736087799072,\n",
       "  0.8638105988502502,\n",
       "  0.8620067834854126,\n",
       "  0.8640360832214355,\n",
       "  0.8622322678565979,\n",
       "  0.8588500618934631,\n",
       "  0.861555814743042,\n",
       "  0.8653889298439026,\n",
       "  0.8651634454727173,\n",
       "  0.8635851144790649,\n",
       "  0.8606538772583008,\n",
       "  0.8597519993782043,\n",
       "  0.8676437139511108,\n",
       "  0.8651634454727173,\n",
       "  0.8676437139511108,\n",
       "  0.8719278573989868,\n",
       "  0.8696730732917786,\n",
       "  0.8710259199142456,\n",
       "  0.8653889298439026,\n",
       "  0.8687711358070374,\n",
       "  0.8717023730278015,\n",
       "  0.8732807040214539,\n",
       "  0.8739571571350098,\n",
       "  0.8687711358070374,\n",
       "  0.8708004355430603,\n",
       "  0.8696730732917786,\n",
       "  0.874859094619751,\n",
       "  0.8687711358070374,\n",
       "  0.8719278573989868,\n",
       "  0.8732807040214539,\n",
       "  0.8732807040214539,\n",
       "  0.8735061883926392,\n",
       "  0.8730552196502686,\n",
       "  0.878241240978241,\n",
       "  0.8735061883926392,\n",
       "  0.8735061883926392,\n",
       "  0.8804960250854492,\n",
       "  0.8755354881286621,\n",
       "  0.8757609724998474,\n",
       "  0.8741826415061951,\n",
       "  0.8735061883926392,\n",
       "  0.8732807040214539,\n",
       "  0.8813979625701904,\n",
       "  0.8750845789909363,\n",
       "  0.8771138787269592,\n",
       "  0.8780157566070557,\n",
       "  0.8807215094566345,\n",
       "  0.8784667253494263,\n",
       "  0.8780157566070557,\n",
       "  0.874859094619751,\n",
       "  0.8764374256134033,\n",
       "  0.8750845789909363,\n",
       "  0.8791431784629822,\n",
       "  0.8766629099845886,\n",
       "  0.8791431784629822,\n",
       "  0.8816234469413757,\n",
       "  0.8804960250854492,\n",
       "  0.8789176940917969,\n",
       "  0.8750845789909363,\n",
       "  0.8816234469413757,\n",
       "  0.878241240978241,\n",
       "  0.8791431784629822,\n",
       "  0.8822999000549316,\n",
       "  0.8816234469413757,\n",
       "  0.8829763531684875,\n",
       "  0.8795941472053528,\n",
       "  0.8843291997909546,\n",
       "  0.8832017779350281,\n",
       "  0.8807215094566345,\n",
       "  0.8832017779350281,\n",
       "  0.8847801685333252,\n",
       "  0.883878231048584,\n",
       "  0.883878231048584,\n",
       "  0.8834272623062134,\n",
       "  0.8847801685333252,\n",
       "  0.8793686628341675,\n",
       "  0.8879368901252747,\n",
       "  0.8834272623062134,\n",
       "  0.883878231048584,\n",
       "  0.8789176940917969,\n",
       "  0.8856820464134216,\n",
       "  0.8825253844261169,\n",
       "  0.8829763531684875,\n",
       "  0.8870349526405334,\n",
       "  0.8834272623062134,\n",
       "  0.8832017779350281,\n",
       "  0.8852311372756958,\n",
       "  0.8834272623062134,\n",
       "  0.8861330151557922,\n",
       "  0.8829763531684875,\n",
       "  0.8868094682693481,\n",
       "  0.8865839838981628,\n",
       "  0.8888387680053711,\n",
       "  0.8847801685333252,\n",
       "  0.887485921382904,\n",
       "  0.887485921382904,\n",
       "  0.889515221118927,\n",
       "  0.8879368901252747,\n",
       "  0.8852311372756958,\n",
       "  0.8870349526405334,\n",
       "  0.8868094682693481,\n",
       "  0.8863584995269775,\n",
       "  0.8863584995269775,\n",
       "  0.8897407054901123,\n",
       "  0.8890642523765564,\n",
       "  0.88816237449646,\n",
       "  0.8883877992630005,\n",
       "  0.8829763531684875,\n",
       "  0.8924464583396912,\n",
       "  0.8886132836341858,\n",
       "  0.8933483362197876,\n",
       "  0.8897407054901123,\n",
       "  0.887485921382904,\n",
       "  0.8897407054901123,\n",
       "  0.8949267268180847,\n",
       "  0.8910935521125793,\n",
       "  0.8890642523765564,\n",
       "  0.8924464583396912,\n",
       "  0.890868067741394,\n",
       "  0.8935738205909729,\n",
       "  0.89154452085495,\n",
       "  0.8949267268180847,\n",
       "  0.8926719427108765,\n",
       "  0.89154452085495,\n",
       "  0.8989853262901306,\n",
       "  0.8949267268180847,\n",
       "  0.8960540890693665,\n",
       "  0.8904171586036682,\n",
       "  0.8976324796676636,\n",
       "  0.8962795734405518,\n",
       "  0.8949267268180847,\n",
       "  0.8958286643028259,\n",
       "  0.8962795734405518,\n",
       "  0.8980834484100342,\n",
       "  0.8974069952964783,\n",
       "  0.8980834484100342,\n",
       "  0.89853435754776,\n",
       "  0.8924464583396912,\n",
       "  0.8994362950325012,\n",
       "  0.8965050578117371,\n",
       "  0.8980834484100342,\n",
       "  0.8956031799316406,\n",
       "  0.8942502737045288,\n",
       "  0.9021420478820801,\n",
       "  0.8965050578117371,\n",
       "  0.9001127481460571,\n",
       "  0.8980834484100342,\n",
       "  0.8976324796676636,\n",
       "  0.8926719427108765,\n",
       "  0.900789201259613,\n",
       "  0.904171347618103,\n",
       "  0.9012401103973389,\n",
       "  0.900789201259613,\n",
       "  0.9010146856307983,\n",
       "  0.9043968319892883,\n",
       "  0.9066516160964966,\n",
       "  0.9043968319892883,\n",
       "  0.9023675322532654,\n",
       "  0.8987598419189453,\n",
       "  0.9012401103973389,\n",
       "  0.8996617794036865,\n",
       "  0.8989853262901306,\n",
       "  0.900789201259613,\n",
       "  0.9021420478820801,\n",
       "  0.9039458632469177,\n",
       "  0.9080045223236084,\n",
       "  0.9057497382164001,\n",
       "  0.9037203788757324,\n",
       "  0.9082300066947937,\n",
       "  0.9019165635108948,\n",
       "  0.9010146856307983,\n",
       "  0.9066516160964966,\n",
       "  0.9080045223236084,\n",
       "  0.9102593064308167,\n",
       "  0.9064261317253113,\n",
       "  0.902818500995636,\n",
       "  0.9064261317253113,\n",
       "  0.9093573689460754,\n",
       "  0.9093573689460754,\n",
       "  0.9120631217956543,\n",
       "  0.9122886061668396,\n",
       "  0.9080045223236084,\n",
       "  0.911837637424469,\n",
       "  0.9131905436515808,\n",
       "  0.9086809754371643,\n",
       "  0.9125140905380249,\n",
       "  0.9066516160964966,\n",
       "  0.9136415123939514,\n",
       "  0.9102593064308167,\n",
       "  0.908455491065979,\n",
       "  0.909808337688446,\n",
       "  0.9120631217956543,\n",
       "  0.9102593064308167,\n",
       "  0.909808337688446,\n",
       "  0.9179255962371826,\n",
       "  0.9102593064308167,\n",
       "  0.906200647354126,\n",
       "  0.9120631217956543,\n",
       "  0.9109357595443726,\n",
       "  0.9147688746452332,\n",
       "  0.9089064002037048,\n",
       "  0.9109357595443726,\n",
       "  0.9120631217956543,\n",
       "  0.9183765649795532,\n",
       "  0.9109357595443726,\n",
       "  0.9186020493507385,\n",
       "  0.916121780872345,\n",
       "  0.9129650592803955,\n",
       "  0.9109357595443726,\n",
       "  0.9149943590164185,\n",
       "  0.9147688746452332,\n",
       "  0.9163472652435303,\n",
       "  0.9143179059028625,\n",
       "  0.9138669967651367,\n",
       "  0.917474627494812,\n",
       "  0.9170236587524414,\n",
       "  0.9136415123939514,\n",
       "  0.9163472652435303,\n",
       "  0.9179255962371826,\n",
       "  0.9147688746452332,\n",
       "  0.9163472652435303,\n",
       "  0.9129650592803955,\n",
       "  0.9181510806083679,\n",
       "  0.9179255962371826,\n",
       "  0.9165726900100708,\n",
       "  0.9204058647155762,\n",
       "  0.9109357595443726,\n",
       "  0.9167981743812561,\n",
       "  0.9181510806083679,\n",
       "  0.9179255962371826,\n",
       "  0.9188275337219238,\n",
       "  0.9138669967651367,\n",
       "  0.9213078022003174,\n",
       "  0.9213078022003174,\n",
       "  0.9149943590164185,\n",
       "  0.9181510806083679,\n",
       "  0.9190529584884644,\n",
       "  0.9197294116020203,\n",
       "  0.9206313490867615,\n",
       "  0.9181510806083679,\n",
       "  0.9206313490867615,\n",
       "  0.916121780872345,\n",
       "  0.9186020493507385,\n",
       "  0.9165726900100708,\n",
       "  0.917474627494812,\n",
       "  0.9172491431236267,\n",
       "  0.9179255962371826,\n",
       "  0.9219841957092285,\n",
       "  0.9197294116020203,\n",
       "  0.9204058647155762,\n",
       "  0.9237880706787109,\n",
       "  0.9206313490867615,\n",
       "  0.9213078022003174,\n",
       "  0.9210823178291321,\n",
       "  0.9213078022003174,\n",
       "  0.9235625863075256,\n",
       "  0.9201803803443909,\n",
       "  0.9201803803443909,\n",
       "  0.9208568334579468,\n",
       "  0.9224351644515991,\n",
       "  0.9224351644515991,\n",
       "  0.9267193078994751,\n",
       "  0.925140917301178,\n",
       "  0.9240135550498962,\n",
       "  0.9246899485588074,\n",
       "  0.9217587113380432,\n",
       "  0.9199548959732056,\n",
       "  0.9228861331939697,\n",
       "  0.9204058647155762,\n",
       "  0.9206313490867615,\n",
       "  0.9224351644515991,\n",
       "  0.9260428547859192,\n",
       "  0.9271702170372009,\n",
       "  0.9269447326660156,\n",
       "  0.9235625863075256,\n",
       "  0.9233371019363403,\n",
       "  0.9260428547859192,\n",
       "  0.9273957014083862,\n",
       "  0.9249154329299927,\n",
       "  0.9253664016723633,\n",
       "  0.9280721545219421,\n",
       "  0.9242389798164368,\n",
       "  0.9253664016723633,\n",
       "  0.9217587113380432,\n",
       "  0.925140917301178,\n",
       "  0.9249154329299927,\n",
       "  0.9271702170372009,\n",
       "  0.9301014542579651,\n",
       "  0.923111617565155,\n",
       "  0.9282976388931274,\n",
       "  0.9278466701507568,\n",
       "  0.9226606488227844,\n",
       "  0.9264938235282898,\n",
       "  0.9278466701507568,\n",
       "  0.9285231232643127,\n",
       "  0.9278466701507568,\n",
       "  0.9291995763778687,\n",
       "  0.9291995763778687,\n",
       "  0.928748607635498,\n",
       "  0.9269447326660156,\n",
       "  0.9208568334579468,\n",
       "  0.9280721545219421,\n",
       "  0.9316798448562622,\n",
       "  0.9294250011444092,\n",
       "  0.9271702170372009,\n",
       "  0.925140917301178,\n",
       "  0.928748607635498,\n",
       "  0.9289740920066833,\n",
       "  0.9310033917427063,\n",
       "  0.9316798448562622,\n",
       "  0.9269447326660156,\n",
       "  0.9296504855155945,\n",
       "  0.9314543604850769,\n",
       "  0.9298759698867798,\n",
       "  0.9310033917427063,\n",
       "  0.9316798448562622,\n",
       "  0.9312288761138916,\n",
       "  0.9314543604850769,\n",
       "  0.9325817227363586,\n",
       "  0.9301014542579651,\n",
       "  0.9303269386291504,\n",
       "  0.9291995763778687,\n",
       "  0.930777907371521,\n",
       "  0.932130753993988,\n",
       "  0.9296504855155945,\n",
       "  0.932807207107544,\n",
       "  0.9334836602210999]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87ef9488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5c6dd6580>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.epoch, history.history['accuracy'], label = '3 hidden layers - train')\n",
    "#ax.plot(history.epoch, history.history['val_accuracy'], label = '3 hidden layers - val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy per Epoch')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6170870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 690us/step - loss: 0.2550 - accuracy: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2550421357154846, 0.8974999785423279]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaler.transform(X_test), enc.transform(y_test.reshape(-1,1)).toarray())  # Calculate performance metrics on unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cdb72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat_trn = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, yhat_trn))\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aeccb536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.7641488162344983\n"
     ]
    }
   ],
   "source": [
    "#print(y_train.shape, y_predict.shape)\n",
    "print(f'Baseline Model Accuracy: {accuracy_score(y_train,y_predict)}') # Baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "857fd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9713641488162345\n",
      "Test Accuracy: 0.903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_trn_rf = clf.predict(X_train)\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, y_trn_rf)}')\n",
    "y_rf = clf.predict(X_test)\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, y_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe6633",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e29e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, X=X_trn_scaled, n_classes=6, opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccd426a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "823c47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.7138 - accuracy: 0.2379\n",
      "Epoch 2/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.4908 - accuracy: 0.4187\n",
      "Epoch 3/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.1525 - accuracy: 0.5707\n",
      "Epoch 4/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.5790\n",
      "Epoch 5/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9761 - accuracy: 0.5766\n",
      "Epoch 6/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9539 - accuracy: 0.5862\n",
      "Epoch 7/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9397 - accuracy: 0.5944\n",
      "Epoch 8/350\n",
      "111/111 [==============================] - 0s 997us/step - loss: 0.9380 - accuracy: 0.6005\n",
      "Epoch 9/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9288 - accuracy: 0.6072\n",
      "Epoch 10/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9284 - accuracy: 0.6162\n",
      "Epoch 11/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.9068 - accuracy: 0.6455\n",
      "Epoch 12/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.6636\n",
      "Epoch 13/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.8687 - accuracy: 0.6952\n",
      "Epoch 14/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.8406 - accuracy: 0.7141\n",
      "Epoch 15/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.8163 - accuracy: 0.7233\n",
      "Epoch 16/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.7371\n",
      "Epoch 17/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.7599\n",
      "Epoch 18/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.7770\n",
      "Epoch 19/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.7835\n",
      "Epoch 20/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.7912\n",
      "Epoch 21/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.7885\n",
      "Epoch 22/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7953\n",
      "Epoch 23/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7959\n",
      "Epoch 24/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7986\n",
      "Epoch 25/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.8018\n",
      "Epoch 26/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8018\n",
      "Epoch 27/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.8038\n",
      "Epoch 28/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.8050\n",
      "Epoch 29/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.8088\n",
      "Epoch 30/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.8129\n",
      "Epoch 31/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8110\n",
      "Epoch 32/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.8120\n",
      "Epoch 33/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8115\n",
      "Epoch 34/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8162\n",
      "Epoch 35/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8160\n",
      "Epoch 36/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8167\n",
      "Epoch 37/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8169\n",
      "Epoch 38/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.8169\n",
      "Epoch 39/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8162\n",
      "Epoch 40/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8153\n",
      "Epoch 41/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8180\n",
      "Epoch 42/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8162\n",
      "Epoch 43/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8194\n",
      "Epoch 44/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.8214\n",
      "Epoch 45/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8221\n",
      "Epoch 46/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8174\n",
      "Epoch 47/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.8244\n",
      "Epoch 48/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8205\n",
      "Epoch 49/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.8275\n",
      "Epoch 50/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.8264\n",
      "Epoch 51/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8221\n",
      "Epoch 52/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8223\n",
      "Epoch 53/350\n",
      "111/111 [==============================] - 0s 965us/step - loss: 0.4649 - accuracy: 0.8198\n",
      "Epoch 54/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8212\n",
      "Epoch 55/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.8282\n",
      "Epoch 56/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8277\n",
      "Epoch 57/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.8271\n",
      "Epoch 58/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8259\n",
      "Epoch 59/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.8284\n",
      "Epoch 60/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8309\n",
      "Epoch 61/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8307\n",
      "Epoch 62/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8336\n",
      "Epoch 63/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8293\n",
      "Epoch 64/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8277\n",
      "Epoch 65/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8304\n",
      "Epoch 66/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8298\n",
      "Epoch 67/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8354\n",
      "Epoch 68/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.8334\n",
      "Epoch 69/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8334\n",
      "Epoch 70/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.8309\n",
      "Epoch 71/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8280\n",
      "Epoch 72/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8282\n",
      "Epoch 73/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8334\n",
      "Epoch 74/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.8298\n",
      "Epoch 75/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8347\n",
      "Epoch 76/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8300\n",
      "Epoch 77/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8347\n",
      "Epoch 78/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8368\n",
      "Epoch 79/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8388\n",
      "Epoch 80/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.8361\n",
      "Epoch 81/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8356\n",
      "Epoch 82/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.8359\n",
      "Epoch 83/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8316\n",
      "Epoch 84/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8365\n",
      "Epoch 85/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8374\n",
      "Epoch 86/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8372\n",
      "Epoch 87/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8331\n",
      "Epoch 88/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8377\n",
      "Epoch 89/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.8386\n",
      "Epoch 90/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8372\n",
      "Epoch 91/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8363\n",
      "Epoch 92/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8343\n",
      "Epoch 93/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8388\n",
      "Epoch 94/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8336\n",
      "Epoch 95/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8428\n",
      "Epoch 96/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8386\n",
      "Epoch 97/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8345\n",
      "Epoch 98/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8349\n",
      "Epoch 99/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8404\n",
      "Epoch 100/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8410\n",
      "Epoch 101/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8388\n",
      "Epoch 102/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8410\n",
      "Epoch 103/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8390\n",
      "Epoch 104/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8437\n",
      "Epoch 105/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8428\n",
      "Epoch 106/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8397\n",
      "Epoch 107/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8474\n",
      "Epoch 108/350\n",
      "111/111 [==============================] - 0s 986us/step - loss: 0.4070 - accuracy: 0.8444\n",
      "Epoch 109/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8399\n",
      "Epoch 110/350\n",
      "111/111 [==============================] - 0s 978us/step - loss: 0.3925 - accuracy: 0.8444\n",
      "Epoch 111/350\n",
      "111/111 [==============================] - 0s 992us/step - loss: 0.3988 - accuracy: 0.8446\n",
      "Epoch 112/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8410\n",
      "Epoch 113/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8474\n",
      "Epoch 114/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8433\n",
      "Epoch 115/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8426\n",
      "Epoch 116/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8469\n",
      "Epoch 117/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8453\n",
      "Epoch 118/350\n",
      "111/111 [==============================] - 0s 960us/step - loss: 0.3962 - accuracy: 0.8474\n",
      "Epoch 119/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8496\n",
      "Epoch 120/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8516\n",
      "Epoch 121/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8440\n",
      "Epoch 122/350\n",
      "111/111 [==============================] - 0s 967us/step - loss: 0.3844 - accuracy: 0.8501\n",
      "Epoch 123/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8489\n",
      "Epoch 124/350\n",
      "111/111 [==============================] - 0s 976us/step - loss: 0.3960 - accuracy: 0.8483\n",
      "Epoch 125/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8478\n",
      "Epoch 126/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8507\n",
      "Epoch 127/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8406\n",
      "Epoch 128/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8476\n",
      "Epoch 129/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8523\n",
      "Epoch 130/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8476\n",
      "Epoch 131/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8471\n",
      "Epoch 132/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8483\n",
      "Epoch 133/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8507\n",
      "Epoch 134/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8546\n",
      "Epoch 135/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8496\n",
      "Epoch 136/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8561\n",
      "Epoch 137/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8489\n",
      "Epoch 138/350\n",
      "111/111 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.85 - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8503\n",
      "Epoch 139/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8496\n",
      "Epoch 140/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8478\n",
      "Epoch 141/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8424\n",
      "Epoch 142/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8528\n",
      "Epoch 143/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8559\n",
      "Epoch 144/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8458\n",
      "Epoch 145/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8521\n",
      "Epoch 146/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8552\n",
      "Epoch 147/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8584\n",
      "Epoch 148/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8561\n",
      "Epoch 149/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8464\n",
      "Epoch 150/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8494\n",
      "Epoch 151/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8530\n",
      "Epoch 152/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8541\n",
      "Epoch 153/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8586\n",
      "Epoch 154/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8559\n",
      "Epoch 155/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8516\n",
      "Epoch 156/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8516\n",
      "Epoch 157/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8586\n",
      "Epoch 158/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8570\n",
      "Epoch 159/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8564\n",
      "Epoch 160/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8530\n",
      "Epoch 161/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8593\n",
      "Epoch 162/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8591\n",
      "Epoch 163/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8543\n",
      "Epoch 164/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8570\n",
      "Epoch 165/350\n",
      "111/111 [==============================] - 0s 940us/step - loss: 0.3598 - accuracy: 0.8541\n",
      "Epoch 166/350\n",
      "111/111 [==============================] - 0s 963us/step - loss: 0.3630 - accuracy: 0.8552\n",
      "Epoch 167/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8595\n",
      "Epoch 168/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8604\n",
      "Epoch 169/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8537\n",
      "Epoch 170/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8598\n",
      "Epoch 171/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8559\n",
      "Epoch 172/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8570\n",
      "Epoch 173/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8523\n",
      "Epoch 174/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8593\n",
      "Epoch 175/350\n",
      "111/111 [==============================] - 0s 992us/step - loss: 0.3581 - accuracy: 0.8548\n",
      "Epoch 176/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8552\n",
      "Epoch 177/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8561\n",
      "Epoch 178/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8616\n",
      "Epoch 179/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8557\n",
      "Epoch 180/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8564\n",
      "Epoch 181/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8602\n",
      "Epoch 182/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8600\n",
      "Epoch 183/350\n",
      "111/111 [==============================] - 0s 973us/step - loss: 0.3566 - accuracy: 0.8595\n",
      "Epoch 184/350\n",
      "111/111 [==============================] - 0s 982us/step - loss: 0.3524 - accuracy: 0.8582\n",
      "Epoch 185/350\n",
      "111/111 [==============================] - 0s 978us/step - loss: 0.3599 - accuracy: 0.8609\n",
      "Epoch 186/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8564\n",
      "Epoch 187/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8559\n",
      "Epoch 188/350\n",
      "111/111 [==============================] - 0s 994us/step - loss: 0.3498 - accuracy: 0.8629\n",
      "Epoch 189/350\n",
      "111/111 [==============================] - 0s 988us/step - loss: 0.3563 - accuracy: 0.8634\n",
      "Epoch 190/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8604\n",
      "Epoch 191/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8591\n",
      "Epoch 192/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8627\n",
      "Epoch 193/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8573\n",
      "Epoch 194/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8629\n",
      "Epoch 195/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8591\n",
      "Epoch 196/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8607\n",
      "Epoch 197/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8593\n",
      "Epoch 198/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8611\n",
      "Epoch 199/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8598\n",
      "Epoch 200/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8658\n",
      "Epoch 201/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8647\n",
      "Epoch 202/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8667\n",
      "Epoch 203/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8600\n",
      "Epoch 204/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8598\n",
      "Epoch 205/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8579\n",
      "Epoch 206/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8631\n",
      "Epoch 207/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8613\n",
      "Epoch 208/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8604\n",
      "Epoch 209/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8638\n",
      "Epoch 210/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8611\n",
      "Epoch 211/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8647\n",
      "Epoch 212/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8537\n",
      "Epoch 213/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8604\n",
      "Epoch 214/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8629\n",
      "Epoch 215/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8582\n",
      "Epoch 216/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8625\n",
      "Epoch 217/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8634\n",
      "Epoch 218/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8602\n",
      "Epoch 219/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8607\n",
      "Epoch 220/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8602\n",
      "Epoch 221/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8629\n",
      "Epoch 222/350\n",
      "111/111 [==============================] - 0s 956us/step - loss: 0.3384 - accuracy: 0.8667\n",
      "Epoch 223/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8607\n",
      "Epoch 224/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8694\n",
      "Epoch 225/350\n",
      "111/111 [==============================] - 0s 989us/step - loss: 0.3429 - accuracy: 0.8584\n",
      "Epoch 226/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8645\n",
      "Epoch 227/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8643\n",
      "Epoch 228/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8640\n",
      "Epoch 229/350\n",
      "111/111 [==============================] - 0s 966us/step - loss: 0.3419 - accuracy: 0.8631\n",
      "Epoch 230/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8652\n",
      "Epoch 231/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8697\n",
      "Epoch 232/350\n",
      "111/111 [==============================] - 0s 972us/step - loss: 0.3367 - accuracy: 0.8647\n",
      "Epoch 233/350\n",
      "111/111 [==============================] - 0s 976us/step - loss: 0.3321 - accuracy: 0.8647\n",
      "Epoch 234/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.8636\n",
      "Epoch 235/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8667\n",
      "Epoch 236/350\n",
      "111/111 [==============================] - 0s 987us/step - loss: 0.3372 - accuracy: 0.8649\n",
      "Epoch 237/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8647\n",
      "Epoch 238/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8611\n",
      "Epoch 239/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8647\n",
      "Epoch 240/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8670\n",
      "Epoch 241/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8672\n",
      "Epoch 242/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8652\n",
      "Epoch 243/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8647\n",
      "Epoch 244/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8656\n",
      "Epoch 245/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8620\n",
      "Epoch 246/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8674\n",
      "Epoch 247/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8649\n",
      "Epoch 248/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8661\n",
      "Epoch 249/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8656\n",
      "Epoch 250/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8640\n",
      "Epoch 251/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8674\n",
      "Epoch 252/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8602\n",
      "Epoch 253/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8661\n",
      "Epoch 254/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8674\n",
      "Epoch 255/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8634\n",
      "Epoch 256/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8683\n",
      "Epoch 257/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8649\n",
      "Epoch 258/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8645\n",
      "Epoch 259/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8679\n",
      "Epoch 260/350\n",
      "111/111 [==============================] - 0s 988us/step - loss: 0.3272 - accuracy: 0.8665\n",
      "Epoch 261/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8638\n",
      "Epoch 262/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8661\n",
      "Epoch 263/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8694\n",
      "Epoch 264/350\n",
      "111/111 [==============================] - 0s 980us/step - loss: 0.3256 - accuracy: 0.8737\n",
      "Epoch 265/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8713\n",
      "Epoch 266/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8649\n",
      "Epoch 267/350\n",
      "111/111 [==============================] - 0s 984us/step - loss: 0.3255 - accuracy: 0.8674\n",
      "Epoch 268/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8613\n",
      "Epoch 269/350\n",
      "111/111 [==============================] - 0s 999us/step - loss: 0.3332 - accuracy: 0.8634\n",
      "Epoch 270/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8694\n",
      "Epoch 271/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8663\n",
      "Epoch 272/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8724\n",
      "Epoch 273/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8701\n",
      "Epoch 274/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8663\n",
      "Epoch 275/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8661\n",
      "Epoch 276/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8683\n",
      "Epoch 277/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8658\n",
      "Epoch 278/350\n",
      "111/111 [==============================] - 0s 999us/step - loss: 0.3289 - accuracy: 0.8697\n",
      "Epoch 279/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8733\n",
      "Epoch 280/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8688\n",
      "Epoch 281/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8661\n",
      "Epoch 282/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8674\n",
      "Epoch 283/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8690\n",
      "Epoch 284/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8688\n",
      "Epoch 285/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8683\n",
      "Epoch 286/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8658\n",
      "Epoch 287/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8692\n",
      "Epoch 288/350\n",
      "111/111 [==============================] - 0s 967us/step - loss: 0.3281 - accuracy: 0.8667\n",
      "Epoch 289/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8670\n",
      "Epoch 290/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8676\n",
      "Epoch 291/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8726\n",
      "Epoch 292/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8685\n",
      "Epoch 293/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8663\n",
      "Epoch 294/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8706\n",
      "Epoch 295/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8665\n",
      "Epoch 296/350\n",
      "111/111 [==============================] - 0s 991us/step - loss: 0.3257 - accuracy: 0.8683\n",
      "Epoch 297/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8690\n",
      "Epoch 298/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8683\n",
      "Epoch 299/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8710\n",
      "Epoch 300/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8735\n",
      "Epoch 301/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8715\n",
      "Epoch 302/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8703\n",
      "Epoch 303/350\n",
      "111/111 [==============================] - 0s 937us/step - loss: 0.3187 - accuracy: 0.8728\n",
      "Epoch 304/350\n",
      "111/111 [==============================] - 0s 996us/step - loss: 0.3222 - accuracy: 0.8717\n",
      "Epoch 305/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8703\n",
      "Epoch 306/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8719\n",
      "Epoch 307/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8706\n",
      "Epoch 308/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8728\n",
      "Epoch 309/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8733\n",
      "Epoch 310/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8674\n",
      "Epoch 311/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8636\n",
      "Epoch 312/350\n",
      "111/111 [==============================] - 0s 988us/step - loss: 0.3258 - accuracy: 0.8674\n",
      "Epoch 313/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8679\n",
      "Epoch 314/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8706\n",
      "Epoch 315/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8708\n",
      "Epoch 316/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8726\n",
      "Epoch 317/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8685\n",
      "Epoch 318/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8742\n",
      "Epoch 319/350\n",
      "111/111 [==============================] - 0s 992us/step - loss: 0.3186 - accuracy: 0.8685\n",
      "Epoch 320/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8701\n",
      "Epoch 321/350\n",
      "111/111 [==============================] - 0s 991us/step - loss: 0.3150 - accuracy: 0.8744\n",
      "Epoch 322/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8692\n",
      "Epoch 323/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8697\n",
      "Epoch 324/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8724\n",
      "Epoch 325/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8724\n",
      "Epoch 326/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8764\n",
      "Epoch 327/350\n",
      "111/111 [==============================] - 0s 922us/step - loss: 0.3169 - accuracy: 0.8749\n",
      "Epoch 328/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8773\n",
      "Epoch 329/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8706\n",
      "Epoch 330/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8740\n",
      "Epoch 331/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8719\n",
      "Epoch 332/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8717\n",
      "Epoch 333/350\n",
      "111/111 [==============================] - 0s 996us/step - loss: 0.3236 - accuracy: 0.8701\n",
      "Epoch 334/350\n",
      "111/111 [==============================] - 0s 968us/step - loss: 0.3177 - accuracy: 0.8726\n",
      "Epoch 335/350\n",
      "111/111 [==============================] - 0s 925us/step - loss: 0.3106 - accuracy: 0.8728\n",
      "Epoch 336/350\n",
      "111/111 [==============================] - 0s 981us/step - loss: 0.3194 - accuracy: 0.8767\n",
      "Epoch 337/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8694\n",
      "Epoch 338/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8724\n",
      "Epoch 339/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8760\n",
      "Epoch 340/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8733\n",
      "Epoch 341/350\n",
      "111/111 [==============================] - 0s 960us/step - loss: 0.3129 - accuracy: 0.8762\n",
      "Epoch 342/350\n",
      "111/111 [==============================] - 0s 989us/step - loss: 0.3163 - accuracy: 0.8719\n",
      "Epoch 343/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8713\n",
      "Epoch 344/350\n",
      "111/111 [==============================] - 0s 941us/step - loss: 0.3131 - accuracy: 0.8724\n",
      "Epoch 345/350\n",
      "111/111 [==============================] - 0s 925us/step - loss: 0.3128 - accuracy: 0.8706\n",
      "Epoch 346/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8726\n",
      "Epoch 347/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8780\n",
      "Epoch 348/350\n",
      "111/111 [==============================] - 0s 991us/step - loss: 0.3111 - accuracy: 0.8722\n",
      "Epoch 349/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8764\n",
      "Epoch 350/350\n",
      "111/111 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8703\n"
     ]
    }
   ],
   "source": [
    "# Set grid search parameters\n",
    "param_grid = dict(epochs=[350, 400], batch_size=[40], drop_out = [0,0.05,0.1], activ=activation)\n",
    "grid = GridSearchCV(estimator=modelo, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(X_trn_scaled, y_trn_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bef77ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activ': 'sigmoid', 'batch_size': 40, 'drop_out': 0.1, 'epochs': 350}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32a0cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444193959236145"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "800f49ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8403060079472405, 0.8780157566070557)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(grid_result.best_estimator_.model.history.history['accuracy']), max(grid_result.best_estimator_.model.history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a34de8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.857961 using {'batch_size': 40, 'epochs': 350}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "    #print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20a99e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 976us/step - loss: 0.3237 - accuracy: 0.8615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3237186372280121, 0.8615000247955322]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_.model.evaluate(scaler.transform(X_test), enc.transform(y_test.reshape(-1,1)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1af3bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([56.24861321, 64.36048489, 60.57246938, 42.5437993 , 52.98535657,\n",
       "        60.41846099, 35.27427649, 40.8893455 , 67.4784328 ]),\n",
       " 'std_fit_time': array([13.14371865, 15.42406399,  3.70558941,  0.59993382, 15.29722387,\n",
       "        18.54836781,  6.66976495,  2.03972572, 19.48062645]),\n",
       " 'mean_score_time': array([0.39819913, 0.23898735, 0.3438087 , 0.40139656, 0.32555408,\n",
       "        0.27125497, 0.34570761, 0.44886274, 0.26565518]),\n",
       " 'std_score_time': array([0.13411262, 0.07360778, 0.12108703, 0.11008736, 0.07049034,\n",
       "        0.10319552, 0.09303471, 0.11655359, 0.09310975]),\n",
       " 'param_batch_size': masked_array(data=[40, 40, 40, 50, 50, 50, 60, 60, 60],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[300, 350, 400, 300, 350, 400, 300, 350, 400],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 40, 'epochs': 300},\n",
       "  {'batch_size': 40, 'epochs': 350},\n",
       "  {'batch_size': 40, 'epochs': 400},\n",
       "  {'batch_size': 50, 'epochs': 300},\n",
       "  {'batch_size': 50, 'epochs': 350},\n",
       "  {'batch_size': 50, 'epochs': 400},\n",
       "  {'batch_size': 60, 'epochs': 300},\n",
       "  {'batch_size': 60, 'epochs': 350},\n",
       "  {'batch_size': 60, 'epochs': 400}],\n",
       " 'split0_test_score': array([0.8207441 , 0.77903044, 0.82638109, 0.77339345, 0.74859077,\n",
       "        0.75197291, 0.82638109, 0.84892899, 0.85569334]),\n",
       " 'split1_test_score': array([0.82976323, 0.82187146, 0.82750845, 0.83765501, 0.82750845,\n",
       "        0.8207441 , 0.81736189, 0.83990979, 0.82299888]),\n",
       " 'split2_test_score': array([0.79932356, 0.76888388, 0.81059754, 0.76775646, 0.7666291 ,\n",
       "        0.81059754, 0.78015786, 0.80608791, 0.78015786]),\n",
       " 'split3_test_score': array([0.86809468, 0.89289743, 0.88951522, 0.87034947, 0.88049603,\n",
       "        0.88275087, 0.87260431, 0.86133033, 0.86696732]),\n",
       " 'split4_test_score': array([0.75986469, 0.80834275, 0.77226609, 0.79368657, 0.77113867,\n",
       "        0.7981962 , 0.72040588, 0.79706877, 0.77339345]),\n",
       " 'mean_test_score': array([0.81555805, 0.81420519, 0.82525368, 0.80856819, 0.7988726 ,\n",
       "        0.81285232, 0.80338221, 0.83066516, 0.81984217]),\n",
       " 'std_test_score': array([0.03564853, 0.04376504, 0.03783752, 0.03946465, 0.0486199 ,\n",
       "        0.04212903, 0.05087341, 0.02486822, 0.03807461]),\n",
       " 'rank_test_score': array([4, 5, 2, 7, 9, 6, 8, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46f088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
